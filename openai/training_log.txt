x2024-08-05 14:39:04 The job has successfully completed
2024-08-05 14:38:57 New fine-tuned model created: ft:gpt-3.5-turbo-0125:personal:xchange:9sler4Sm
2024-08-05 14:38:57 Checkpoint created at step 1509 with Snapshot ID: ft:gpt-3.5-turbo-0125:personal:xchange:9slerK0k:ckpt-step-1509
2024-08-05 14:38:57 Checkpoint created at step 1006 with Snapshot ID: ft:gpt-3.5-turbo-0125:personal:xchange:9sleqUyI:ckpt-step-1006
2024-08-05 14:38:40 Step 1512/1512: training loss=0.00
2024-08-05 14:38:31 Step 1511/1512: training loss=0.00
2024-08-05 14:38:08 Step 1510/1512: training loss=0.01
2024-08-05 14:38:03 Step 1509/1512: training loss=0.00, full validation loss=0.15
2024-08-05 14:37:34 Step 1508/1512: training loss=0.31
2024-08-05 14:37:31 Step 1507/1512: training loss=0.00
2024-08-05 14:37:31 Step 1506/1512: training loss=0.00
2024-08-05 14:37:27 Step 1505/1512: training loss=0.00
2024-08-05 14:37:26 Step 1504/1512: training loss=0.00
2024-08-05 14:37:23 Step 1503/1512: training loss=0.45
2024-08-05 14:37:23 Step 1502/1512: training loss=0.00
2024-08-05 14:37:19 Step 1501/1512: training loss=0.00
2024-08-05 14:37:17 Step 1500/1512: training loss=0.00, validation loss=0.41
2024-08-05 14:37:14 Step 1499/1512: training loss=0.00
2024-08-05 14:37:10 Step 1498/1512: training loss=0.00
2024-08-05 14:37:10 Step 1497/1512: training loss=0.00
2024-08-05 14:37:09 Step 1496/1512: training loss=0.00
2024-08-05 14:37:04 Step 1495/1512: training loss=0.00
2024-08-05 14:37:03 Step 1494/1512: training loss=0.00
2024-08-05 14:37:00 Step 1493/1512: training loss=0.26
2024-08-05 14:37:00 Step 1492/1512: training loss=0.00
2024-08-05 14:36:56 Step 1491/1512: training loss=0.00
2024-08-05 14:36:54 Step 1490/1512: training loss=0.00
2024-08-05 14:36:51 Step 1489/1512: training loss=0.00
2024-08-05 14:36:51 Step 1488/1512: training loss=0.00
2024-08-05 14:36:46 Step 1487/1512: training loss=0.00
2024-08-05 14:36:43 Step 1486/1512: training loss=0.37
2024-08-05 14:36:43 Step 1485/1512: training loss=0.00
2024-08-05 14:36:39 Step 1484/1512: training loss=0.00
2024-08-05 14:36:39 Step 1483/1512: training loss=0.00
2024-08-05 14:36:38 Step 1482/1512: training loss=0.00
2024-08-05 14:36:33 Step 1481/1512: training loss=0.00
2024-08-05 14:36:32 Step 1480/1512: training loss=0.31
2024-08-05 14:36:27 Step 1479/1512: training loss=0.00
2024-08-05 14:36:24 Step 1478/1512: training loss=0.00
2024-08-05 14:36:24 Step 1477/1512: training loss=0.00
2024-08-05 14:36:20 Step 1476/1512: training loss=0.37
2024-08-05 14:36:19 Step 1475/1512: training loss=0.00
2024-08-05 14:36:16 Step 1474/1512: training loss=0.31
2024-08-05 14:36:16 Step 1473/1512: training loss=0.00
2024-08-05 14:36:13 Step 1472/1512: training loss=0.00
2024-08-05 14:36:11 Step 1471/1512: training loss=0.00
2024-08-05 14:36:07 Step 1470/1512: training loss=0.00
2024-08-05 14:36:07 Step 1469/1512: training loss=0.00
2024-08-05 14:36:04 Step 1468/1512: training loss=0.00
2024-08-05 14:36:02 Step 1467/1512: training loss=0.00
2024-08-05 14:35:57 Step 1466/1512: training loss=0.00
2024-08-05 14:35:57 Step 1465/1512: training loss=0.33
2024-08-05 14:35:54 Step 1464/1512: training loss=0.00
2024-08-05 14:35:53 Step 1463/1512: training loss=0.00
2024-08-05 14:35:49 Step 1462/1512: training loss=0.00
2024-08-05 14:35:49 Step 1461/1512: training loss=0.00
2024-08-05 14:35:45 Step 1460/1512: training loss=0.40
2024-08-05 14:35:44 Step 1459/1512: training loss=0.00
2024-08-05 14:35:40 Step 1458/1512: training loss=0.00
2024-08-05 14:35:40 Step 1457/1512: training loss=0.35
2024-08-05 14:35:36 Step 1456/1512: training loss=0.00
2024-08-05 14:35:32 Step 1455/1512: training loss=0.00
2024-08-05 14:35:32 Step 1454/1512: training loss=0.00
2024-08-05 14:35:29 Step 1453/1512: training loss=0.00
2024-08-05 14:35:29 Step 1452/1512: training loss=0.00
2024-08-05 14:35:28 Step 1451/1512: training loss=0.00
2024-08-05 14:35:22 Step 1450/1512: training loss=0.00
2024-08-05 14:35:21 Step 1449/1512: training loss=0.00
2024-08-05 14:35:17 Step 1448/1512: training loss=0.00
2024-08-05 14:35:17 Step 1447/1512: training loss=0.00
2024-08-05 14:35:13 Step 1446/1512: training loss=0.00
2024-08-05 14:35:09 Step 1445/1512: training loss=0.00
2024-08-05 14:35:09 Step 1444/1512: training loss=0.00
2024-08-05 14:35:06 Step 1443/1512: training loss=0.00
2024-08-05 14:35:05 Step 1442/1512: training loss=0.00
2024-08-05 14:35:01 Step 1441/1512: training loss=0.00
2024-08-05 14:35:00 Step 1440/1512: training loss=0.00
2024-08-05 14:34:57 Step 1439/1512: training loss=0.00
2024-08-05 14:34:57 Step 1438/1512: training loss=0.00
2024-08-05 14:34:56 Step 1437/1512: training loss=0.00
2024-08-05 14:34:50 Step 1436/1512: training loss=0.00
2024-08-05 14:34:50 Step 1435/1512: training loss=0.00
2024-08-05 14:34:45 Step 1434/1512: training loss=0.49
2024-08-05 14:34:42 Step 1433/1512: training loss=0.29
2024-08-05 14:34:42 Step 1432/1512: training loss=0.00
2024-08-05 14:34:42 Step 1431/1512: training loss=0.00
2024-08-05 14:34:36 Step 1430/1512: training loss=0.00
2024-08-05 14:34:33 Step 1429/1512: training loss=0.00
2024-08-05 14:34:33 Step 1428/1512: training loss=0.00
2024-08-05 14:34:29 Step 1427/1512: training loss=0.00
2024-08-05 14:34:28 Step 1426/1512: training loss=0.00
2024-08-05 14:34:25 Step 1425/1512: training loss=0.00
2024-08-05 14:34:25 Step 1424/1512: training loss=0.00
2024-08-05 14:34:21 Step 1423/1512: training loss=0.38
2024-08-05 14:34:21 Step 1422/1512: training loss=0.00
2024-08-05 14:34:20 Step 1421/1512: training loss=0.00
2024-08-05 14:34:14 Step 1420/1512: training loss=0.00
2024-08-05 14:34:13 Step 1419/1512: training loss=0.00
2024-08-05 14:34:10 Step 1418/1512: training loss=0.00
2024-08-05 14:34:10 Step 1417/1512: training loss=0.00
2024-08-05 14:34:06 Step 1416/1512: training loss=0.00
2024-08-05 14:34:04 Step 1415/1512: training loss=0.31
2024-08-05 14:34:01 Step 1414/1512: training loss=0.00
2024-08-05 14:34:01 Step 1413/1512: training loss=0.00
2024-08-05 14:33:57 Step 1412/1512: training loss=0.38
2024-08-05 14:33:56 Step 1411/1512: training loss=0.00
2024-08-05 14:33:52 Step 1410/1512: training loss=0.00
2024-08-05 14:33:52 Step 1409/1512: training loss=0.00
2024-08-05 14:33:48 Step 1408/1512: training loss=0.00
2024-08-05 14:33:47 Step 1407/1512: training loss=0.00
2024-08-05 14:33:42 Step 1406/1512: training loss=0.00
2024-08-05 14:33:42 Step 1405/1512: training loss=0.00
2024-08-05 14:33:39 Step 1404/1512: training loss=0.00
2024-08-05 14:33:38 Step 1403/1512: training loss=0.00
2024-08-05 14:33:34 Step 1402/1512: training loss=0.00
2024-08-05 14:33:34 Step 1401/1512: training loss=0.27
2024-08-05 14:33:30 Step 1400/1512: training loss=0.00, validation loss=0.34
2024-08-05 14:33:29 Step 1399/1512: training loss=0.21
2024-08-05 14:33:25 Step 1398/1512: training loss=0.00
2024-08-05 14:33:22 Step 1397/1512: training loss=0.42
2024-08-05 14:33:21 Step 1396/1512: training loss=0.00
2024-08-05 14:33:17 Step 1395/1512: training loss=0.00
2024-08-05 14:33:17 Step 1394/1512: training loss=0.00
2024-08-05 14:33:14 Step 1393/1512: training loss=0.00
2024-08-05 14:33:14 Step 1392/1512: training loss=0.13
2024-08-05 14:33:13 Step 1391/1512: training loss=0.00
2024-08-05 14:33:07 Step 1390/1512: training loss=0.00
2024-08-05 14:33:03 Step 1389/1512: training loss=0.00
2024-08-05 14:33:02 Step 1388/1512: training loss=0.38
2024-08-05 14:32:59 Step 1387/1512: training loss=0.00
2024-08-05 14:32:59 Step 1386/1512: training loss=0.00
2024-08-05 14:32:54 Step 1385/1512: training loss=0.00
2024-08-05 14:32:51 Step 1384/1512: training loss=0.00
2024-08-05 14:32:51 Step 1383/1512: training loss=0.00
2024-08-05 14:32:51 Step 1382/1512: training loss=0.00
2024-08-05 14:32:47 Step 1381/1512: training loss=0.00
2024-08-05 14:32:45 Step 1380/1512: training loss=0.00
2024-08-05 14:32:42 Step 1379/1512: training loss=0.21
2024-08-05 14:32:42 Step 1378/1512: training loss=0.00
2024-08-05 14:32:38 Step 1377/1512: training loss=0.00
2024-08-05 14:32:37 Step 1376/1512: training loss=0.00
2024-08-05 14:32:32 Step 1375/1512: training loss=0.00
2024-08-05 14:32:31 Step 1374/1512: training loss=0.35
2024-08-05 14:32:27 Step 1373/1512: training loss=0.00
2024-08-05 14:32:27 Step 1372/1512: training loss=0.65
2024-08-05 14:32:24 Step 1371/1512: training loss=0.00
2024-08-05 14:32:22 Step 1370/1512: training loss=0.38
2024-08-05 14:32:18 Step 1369/1512: training loss=0.00
2024-08-05 14:32:18 Step 1368/1512: training loss=0.00
2024-08-05 14:32:14 Step 1367/1512: training loss=0.00
2024-08-05 14:32:10 Step 1366/1512: training loss=0.00
2024-08-05 14:32:10 Step 1365/1512: training loss=0.00
2024-08-05 14:32:07 Step 1364/1512: training loss=0.00
2024-08-05 14:32:07 Step 1363/1512: training loss=0.29
2024-08-05 14:32:06 Step 1362/1512: training loss=0.30
2024-08-05 14:32:01 Step 1361/1512: training loss=0.00
2024-08-05 14:32:00 Step 1360/1512: training loss=0.00
2024-08-05 14:31:55 Step 1359/1512: training loss=0.00
2024-08-05 14:31:52 Step 1358/1512: training loss=0.45
2024-08-05 14:31:52 Step 1357/1512: training loss=0.00
2024-08-05 14:31:48 Step 1356/1512: training loss=0.00
2024-08-05 14:31:47 Step 1355/1512: training loss=0.00
2024-08-05 14:31:44 Step 1354/1512: training loss=0.00
2024-08-05 14:31:44 Step 1353/1512: training loss=0.00
2024-08-05 14:31:40 Step 1352/1512: training loss=0.00
2024-08-05 14:31:39 Step 1351/1512: training loss=0.00
2024-08-05 14:31:35 Step 1350/1512: training loss=0.00
2024-08-05 14:31:35 Step 1349/1512: training loss=0.03
2024-08-05 14:31:31 Step 1348/1512: training loss=0.00
2024-08-05 14:31:30 Step 1347/1512: training loss=1.26
2024-08-05 14:31:25 Step 1346/1512: training loss=0.40
2024-08-05 14:31:25 Step 1345/1512: training loss=0.46
2024-08-05 14:31:22 Step 1344/1512: training loss=0.00
2024-08-05 14:31:21 Step 1343/1512: training loss=0.00
2024-08-05 14:31:17 Step 1342/1512: training loss=0.00
2024-08-05 14:31:17 Step 1341/1512: training loss=0.00
2024-08-05 14:31:13 Step 1340/1512: training loss=0.00
2024-08-05 14:31:12 Step 1339/1512: training loss=0.00
2024-08-05 14:31:08 Step 1338/1512: training loss=0.00
2024-08-05 14:31:08 Step 1337/1512: training loss=0.00
2024-08-05 14:31:04 Step 1336/1512: training loss=0.00
2024-08-05 14:31:00 Step 1335/1512: training loss=0.00
2024-08-05 14:31:00 Step 1334/1512: training loss=0.40
2024-08-05 14:30:57 Step 1333/1512: training loss=0.00
2024-08-05 14:30:57 Step 1332/1512: training loss=0.00
2024-08-05 14:30:56 Step 1331/1512: training loss=0.00
2024-08-05 14:30:50 Step 1330/1512: training loss=0.00
2024-08-05 14:30:49 Step 1329/1512: training loss=0.00
2024-08-05 14:30:45 Step 1328/1512: training loss=0.00
2024-08-05 14:30:45 Step 1327/1512: training loss=0.00
2024-08-05 14:30:41 Step 1326/1512: training loss=0.44
2024-08-05 14:30:37 Step 1325/1512: training loss=0.00
2024-08-05 14:30:37 Step 1324/1512: training loss=0.00
2024-08-05 14:30:34 Step 1323/1512: training loss=0.00
2024-08-05 14:30:33 Step 1322/1512: training loss=0.59
2024-08-05 14:30:29 Step 1321/1512: training loss=0.00
2024-08-05 14:30:28 Step 1320/1512: training loss=0.00
2024-08-05 14:30:25 Step 1319/1512: training loss=0.00
2024-08-05 14:30:25 Step 1318/1512: training loss=0.00
2024-08-05 14:30:24 Step 1317/1512: training loss=0.39
2024-08-05 14:30:19 Step 1316/1512: training loss=0.00
2024-08-05 14:30:19 Step 1315/1512: training loss=0.00
2024-08-05 14:30:14 Step 1314/1512: training loss=0.00
2024-08-05 14:30:11 Step 1313/1512: training loss=0.00
2024-08-05 14:30:11 Step 1312/1512: training loss=0.00
2024-08-05 14:30:11 Step 1311/1512: training loss=0.33
2024-08-05 14:30:05 Step 1310/1512: training loss=0.00
2024-08-05 14:30:02 Step 1309/1512: training loss=0.00
2024-08-05 14:30:02 Step 1308/1512: training loss=0.00
2024-08-05 14:29:58 Step 1307/1512: training loss=0.00
2024-08-05 14:29:57 Step 1306/1512: training loss=0.00
2024-08-05 14:29:54 Step 1305/1512: training loss=0.00
2024-08-05 14:29:54 Step 1304/1512: training loss=0.41
2024-08-05 14:29:50 Step 1303/1512: training loss=0.00
2024-08-05 14:29:50 Step 1302/1512: training loss=0.00
2024-08-05 14:29:49 Step 1301/1512: training loss=0.16
2024-08-05 14:29:43 Step 1300/1512: training loss=0.00, validation loss=0.00
2024-08-05 14:29:43 Step 1299/1512: training loss=0.00
2024-08-05 14:29:38 Step 1298/1512: training loss=0.00
2024-08-05 14:29:35 Step 1297/1512: training loss=0.32
2024-08-05 14:29:35 Step 1296/1512: training loss=0.00
2024-08-05 14:29:30 Step 1295/1512: training loss=0.00
2024-08-05 14:29:27 Step 1294/1512: training loss=0.36
2024-08-05 14:29:27 Step 1293/1512: training loss=0.00
2024-08-05 14:29:24 Step 1292/1512: training loss=0.00
2024-08-05 14:29:23 Step 1291/1512: training loss=0.00
2024-08-05 14:29:18 Step 1290/1512: training loss=0.00
2024-08-05 14:29:18 Step 1289/1512: training loss=0.00
2024-08-05 14:29:15 Step 1288/1512: training loss=0.00
2024-08-05 14:29:15 Step 1287/1512: training loss=0.00
2024-08-05 14:29:13 Step 1286/1512: training loss=0.28
2024-08-05 14:29:08 Step 1285/1512: training loss=0.00
2024-08-05 14:29:07 Step 1284/1512: training loss=0.00
2024-08-05 14:29:04 Step 1283/1512: training loss=0.00
2024-08-05 14:29:04 Step 1282/1512: training loss=0.00
2024-08-05 14:29:00 Step 1281/1512: training loss=0.39
2024-08-05 14:28:58 Step 1280/1512: training loss=0.00
2024-08-05 14:28:55 Step 1279/1512: training loss=0.00
2024-08-05 14:28:51 Step 1278/1512: training loss=0.35
2024-08-05 14:28:50 Step 1277/1512: training loss=0.24
2024-08-05 14:28:47 Step 1276/1512: training loss=0.00
2024-08-05 14:28:47 Step 1275/1512: training loss=0.00
2024-08-05 14:28:43 Step 1274/1512: training loss=0.69
2024-08-05 14:28:43 Step 1273/1512: training loss=0.00
2024-08-05 14:28:42 Step 1272/1512: training loss=0.00
2024-08-05 14:28:37 Step 1271/1512: training loss=0.00
2024-08-05 14:28:36 Step 1270/1512: training loss=0.00
2024-08-05 14:28:32 Step 1269/1512: training loss=0.00
2024-08-05 14:28:28 Step 1268/1512: training loss=0.00
2024-08-05 14:28:28 Step 1267/1512: training loss=0.24
2024-08-05 14:28:25 Step 1266/1512: training loss=0.00
2024-08-05 14:28:24 Step 1265/1512: training loss=0.00
2024-08-05 14:28:20 Step 1264/1512: training loss=0.00
2024-08-05 14:28:20 Step 1263/1512: training loss=0.00
2024-08-05 14:28:17 Step 1262/1512: training loss=0.00
2024-08-05 14:28:16 Step 1261/1512: training loss=0.28
2024-08-05 14:28:11 Step 1260/1512: training loss=0.00
2024-08-05 14:28:11 Step 1259/1512: training loss=0.00
2024-08-05 14:28:08 Step 1258/1512: training loss=0.00
2024-08-05 14:28:07 Step 1257/1512: training loss=0.00
2024-08-05 14:28:02 Step 1256/1512: training loss=0.00
2024-08-05 14:28:02 Step 1255/1512: training loss=0.00
2024-08-05 14:27:57 Step 1254/1512: training loss=0.00
2024-08-05 14:27:54 Step 1253/1512: training loss=0.00
2024-08-05 14:27:54 Step 1252/1512: training loss=0.00
2024-08-05 14:27:54 Step 1251/1512: training loss=0.00
2024-08-05 14:27:49 Step 1250/1512: training loss=0.71
2024-08-05 14:27:48 Step 1249/1512: training loss=0.32
2024-08-05 14:27:45 Step 1248/1512: training loss=0.32
2024-08-05 14:27:45 Step 1247/1512: training loss=0.00
2024-08-05 14:27:40 Step 1246/1512: training loss=0.00
2024-08-05 14:27:37 Step 1245/1512: training loss=0.00
2024-08-05 14:27:37 Step 1244/1512: training loss=0.00
2024-08-05 14:27:33 Step 1243/1512: training loss=0.00
2024-08-05 14:27:33 Step 1242/1512: training loss=0.00
2024-08-05 14:27:32 Step 1241/1512: training loss=0.23
2024-08-05 14:27:26 Step 1240/1512: training loss=0.00
2024-08-05 14:27:26 Step 1239/1512: training loss=0.00
2024-08-05 14:27:22 Step 1238/1512: training loss=0.00
2024-08-05 14:27:18 Step 1237/1512: training loss=0.45
2024-08-05 14:27:18 Step 1236/1512: training loss=0.00
2024-08-05 14:27:15 Step 1235/1512: training loss=0.96
2024-08-05 14:27:14 Step 1234/1512: training loss=0.00
2024-08-05 14:27:10 Step 1233/1512: training loss=0.45
2024-08-05 14:27:10 Step 1232/1512: training loss=0.42
2024-08-05 14:27:07 Step 1231/1512: training loss=0.30
2024-08-05 14:27:05 Step 1230/1512: training loss=0.00
2024-08-05 14:27:01 Step 1229/1512: training loss=0.00
2024-08-05 14:27:01 Step 1228/1512: training loss=0.31
2024-08-05 14:26:58 Step 1227/1512: training loss=0.25
2024-08-05 14:26:57 Step 1226/1512: training loss=0.39
2024-08-05 14:26:38 Step 1225/1512: training loss=0.00
2024-08-05 14:26:38 Step 1224/1512: training loss=0.00
2024-08-05 14:26:38 Step 1223/1512: training loss=0.42
2024-08-05 14:26:33 Step 1222/1512: training loss=0.00
2024-08-05 14:26:30 Step 1221/1512: training loss=0.00
2024-08-05 14:26:29 Step 1220/1512: training loss=0.00
2024-08-05 14:26:29 Step 1219/1512: training loss=0.00
2024-08-05 14:26:25 Step 1218/1512: training loss=0.00
2024-08-05 14:26:24 Step 1217/1512: training loss=0.00
2024-08-05 14:26:19 Step 1216/1512: training loss=0.00
2024-08-05 14:26:19 Step 1215/1512: training loss=0.00
2024-08-05 14:26:15 Step 1214/1512: training loss=0.00
2024-08-05 14:26:11 Step 1213/1512: training loss=0.00
2024-08-05 14:26:11 Step 1212/1512: training loss=0.00
2024-08-05 14:26:11 Step 1211/1512: training loss=0.00
2024-08-05 14:26:06 Step 1210/1512: training loss=0.00
2024-08-05 14:26:02 Step 1209/1512: training loss=0.00
2024-08-05 14:26:02 Step 1208/1512: training loss=0.00
2024-08-05 14:25:59 Step 1207/1512: training loss=0.00
2024-08-05 14:25:58 Step 1206/1512: training loss=0.00
2024-08-05 14:25:54 Step 1205/1512: training loss=0.00
2024-08-05 14:25:54 Step 1204/1512: training loss=0.00
2024-08-05 14:25:51 Step 1203/1512: training loss=0.00
2024-08-05 14:25:51 Step 1202/1512: training loss=0.00
2024-08-05 14:25:50 Step 1201/1512: training loss=0.00
2024-08-05 14:25:43 Step 1200/1512: training loss=0.00, validation loss=0.00
2024-08-05 14:25:43 Step 1199/1512: training loss=0.00
2024-08-05 14:25:39 Step 1198/1512: training loss=0.00
2024-08-05 14:25:35 Step 1197/1512: training loss=0.32
2024-08-05 14:25:35 Step 1196/1512: training loss=0.00
2024-08-05 14:25:31 Step 1195/1512: training loss=0.00
2024-08-05 14:25:28 Step 1194/1512: training loss=0.00
2024-08-05 14:25:28 Step 1193/1512: training loss=0.00
2024-08-05 14:25:24 Step 1192/1512: training loss=0.59
2024-08-05 14:25:23 Step 1191/1512: training loss=0.00
2024-08-05 14:25:18 Step 1190/1512: training loss=0.00
2024-08-05 14:25:18 Step 1189/1512: training loss=0.00
2024-08-05 14:25:15 Step 1188/1512: training loss=0.23
2024-08-05 14:25:15 Step 1187/1512: training loss=0.00
2024-08-05 14:25:14 Step 1186/1512: training loss=0.00
2024-08-05 14:25:09 Step 1185/1512: training loss=0.47
2024-08-05 14:25:08 Step 1184/1512: training loss=0.00
2024-08-05 14:25:04 Step 1183/1512: training loss=0.41
2024-08-05 14:25:04 Step 1182/1512: training loss=0.33
2024-08-05 14:25:01 Step 1181/1512: training loss=0.00
2024-08-05 14:24:59 Step 1180/1512: training loss=0.39
2024-08-05 14:24:55 Step 1179/1512: training loss=0.00
2024-08-05 14:24:55 Step 1178/1512: training loss=0.00
2024-08-05 14:24:52 Step 1177/1512: training loss=0.00
2024-08-05 14:24:51 Step 1176/1512: training loss=0.00
2024-08-05 14:24:46 Step 1175/1512: training loss=0.00
2024-08-05 14:24:46 Step 1174/1512: training loss=0.30
2024-08-05 14:24:43 Step 1173/1512: training loss=0.00
2024-08-05 14:24:43 Step 1172/1512: training loss=0.00
2024-08-05 14:24:42 Step 1171/1512: training loss=0.00
2024-08-05 14:24:36 Step 1170/1512: training loss=0.00
2024-08-05 14:24:35 Step 1169/1512: training loss=0.00
2024-08-05 14:24:31 Step 1168/1512: training loss=0.30
2024-08-05 14:24:31 Step 1167/1512: training loss=0.00
2024-08-05 14:24:27 Step 1166/1512: training loss=0.00
2024-08-05 14:24:23 Step 1165/1512: training loss=0.00
2024-08-05 14:24:23 Step 1164/1512: training loss=0.40
2024-08-05 14:24:20 Step 1163/1512: training loss=0.53
2024-08-05 14:24:19 Step 1162/1512: training loss=0.00
2024-08-05 14:24:15 Step 1161/1512: training loss=0.33
2024-08-05 14:24:14 Step 1160/1512: training loss=0.06
2024-08-05 14:24:11 Step 1159/1512: training loss=0.00
2024-08-05 14:24:11 Step 1158/1512: training loss=0.00
2024-08-05 14:24:10 Step 1157/1512: training loss=0.00
2024-08-05 14:24:04 Step 1156/1512: training loss=0.00
2024-08-05 14:24:04 Step 1155/1512: training loss=0.00
2024-08-05 14:23:59 Step 1154/1512: training loss=0.00
2024-08-05 14:23:56 Step 1153/1512: training loss=0.00
2024-08-05 14:23:56 Step 1152/1512: training loss=0.00
2024-08-05 14:23:56 Step 1151/1512: training loss=0.00
2024-08-05 14:23:50 Step 1150/1512: training loss=0.00
2024-08-05 14:23:47 Step 1149/1512: training loss=0.00
2024-08-05 14:23:47 Step 1148/1512: training loss=0.00
2024-08-05 14:23:43 Step 1147/1512: training loss=0.00
2024-08-05 14:23:42 Step 1146/1512: training loss=0.00
2024-08-05 14:23:39 Step 1145/1512: training loss=0.00
2024-08-05 14:23:39 Step 1144/1512: training loss=0.00
2024-08-05 14:23:35 Step 1143/1512: training loss=0.00
2024-08-05 14:23:34 Step 1142/1512: training loss=0.27
2024-08-05 14:23:05 Step 1141/1512: training loss=0.26
2024-08-05 14:23:04 Step 1140/1512: training loss=0.00
2024-08-05 14:23:00 Step 1139/1512: training loss=0.74
2024-08-05 14:23:00 Step 1138/1512: training loss=0.00
2024-08-05 14:22:59 Step 1137/1512: training loss=0.00
2024-08-05 14:22:54 Step 1136/1512: training loss=0.00
2024-08-05 14:22:54 Step 1135/1512: training loss=0.00
2024-08-05 14:22:50 Step 1134/1512: training loss=0.34
2024-08-05 14:22:46 Step 1133/1512: training loss=0.33
2024-08-05 14:22:46 Step 1132/1512: training loss=0.00
2024-08-05 14:22:46 Step 1131/1512: training loss=0.00
2024-08-05 14:22:40 Step 1130/1512: training loss=0.00
2024-08-05 14:22:37 Step 1129/1512: training loss=0.77
2024-08-05 14:22:37 Step 1128/1512: training loss=0.29
2024-08-05 14:22:34 Step 1127/1512: training loss=0.16
2024-08-05 14:22:32 Step 1126/1512: training loss=0.48
2024-08-05 14:22:29 Step 1125/1512: training loss=0.00
2024-08-05 14:22:29 Step 1124/1512: training loss=0.00
2024-08-05 14:22:25 Step 1123/1512: training loss=0.00
2024-08-05 14:22:25 Step 1122/1512: training loss=0.00
2024-08-05 14:22:24 Step 1121/1512: training loss=0.00
2024-08-05 14:22:18 Step 1120/1512: training loss=0.00
2024-08-05 14:22:17 Step 1119/1512: training loss=0.00
2024-08-05 14:22:14 Step 1118/1512: training loss=0.29
2024-08-05 14:22:14 Step 1117/1512: training loss=0.00
2024-08-05 14:22:09 Step 1116/1512: training loss=0.00
2024-08-05 14:22:06 Step 1115/1512: training loss=0.34
2024-08-05 14:22:06 Step 1114/1512: training loss=0.00
2024-08-05 14:22:02 Step 1113/1512: training loss=0.00
2024-08-05 14:22:01 Step 1112/1512: training loss=0.00
2024-08-05 14:21:58 Step 1111/1512: training loss=0.00
2024-08-05 14:21:57 Step 1110/1512: training loss=0.00
2024-08-05 14:21:57 Step 1109/1512: training loss=0.00
2024-08-05 14:21:53 Step 1108/1512: training loss=0.00
2024-08-05 14:21:52 Step 1107/1512: training loss=0.00
2024-08-05 14:21:47 Step 1106/1512: training loss=0.00
2024-08-05 14:21:47 Step 1105/1512: training loss=0.00
2024-08-05 14:21:43 Step 1104/1512: training loss=0.28
2024-08-05 14:21:42 Step 1103/1512: training loss=0.39
2024-08-05 14:21:39 Step 1102/1512: training loss=0.00
2024-08-05 14:21:39 Step 1101/1512: training loss=0.32
2024-08-05 14:21:34 Step 1100/1512: training loss=0.33, validation loss=0.19
2024-08-05 14:21:33 Step 1099/1512: training loss=0.28
2024-08-05 14:21:30 Step 1098/1512: training loss=0.37
2024-08-05 14:21:26 Step 1097/1512: training loss=0.00
2024-08-05 14:21:25 Step 1096/1512: training loss=0.21
2024-08-05 14:21:22 Step 1095/1512: training loss=0.29
2024-08-05 14:21:22 Step 1094/1512: training loss=0.00
2024-08-05 14:21:18 Step 1093/1512: training loss=0.00
2024-08-05 14:21:18 Step 1092/1512: training loss=0.30
2024-08-05 14:21:17 Step 1091/1512: training loss=0.00
2024-08-05 14:21:11 Step 1090/1512: training loss=0.00
2024-08-05 14:21:10 Step 1089/1512: training loss=0.00
2024-08-05 14:21:07 Step 1088/1512: training loss=0.00
2024-08-05 14:21:07 Step 1087/1512: training loss=0.00
2024-08-05 14:21:02 Step 1086/1512: training loss=0.00
2024-08-05 14:20:59 Step 1085/1512: training loss=0.38
2024-08-05 14:20:59 Step 1084/1512: training loss=0.00
2024-08-05 14:20:55 Step 1083/1512: training loss=0.33
2024-08-05 14:20:54 Step 1082/1512: training loss=0.00
2024-08-05 14:20:51 Step 1081/1512: training loss=0.42
2024-08-05 14:20:50 Step 1080/1512: training loss=0.00
2024-08-05 14:20:46 Step 1079/1512: training loss=0.00
2024-08-05 14:20:45 Step 1078/1512: training loss=0.00
2024-08-05 14:20:40 Step 1077/1512: training loss=0.00
2024-08-05 14:20:40 Step 1076/1512: training loss=0.00
2024-08-05 14:20:36 Step 1075/1512: training loss=0.00
2024-08-05 14:20:35 Step 1074/1512: training loss=0.00
2024-08-05 14:20:32 Step 1073/1512: training loss=0.44
2024-08-05 14:20:32 Step 1072/1512: training loss=0.00
2024-08-05 14:20:28 Step 1071/1512: training loss=0.10
2024-08-05 14:20:26 Step 1070/1512: training loss=0.00
2024-08-05 14:20:19 Step 1069/1512: training loss=0.00
2024-08-05 14:20:18 Step 1068/1512: training loss=0.00
2024-08-05 14:20:15 Step 1067/1512: training loss=0.00
2024-08-05 14:20:15 Step 1066/1512: training loss=0.36
2024-08-05 14:20:11 Step 1065/1512: training loss=0.48
2024-08-05 14:20:11 Step 1064/1512: training loss=0.00
2024-08-05 14:20:10 Step 1063/1512: training loss=0.00
2024-08-05 14:20:05 Step 1062/1512: training loss=0.00
2024-08-05 14:20:04 Step 1061/1512: training loss=0.20
2024-08-05 14:20:00 Step 1060/1512: training loss=0.00
2024-08-05 14:20:00 Step 1059/1512: training loss=0.00
2024-08-05 14:19:56 Step 1058/1512: training loss=0.00
2024-08-05 14:19:55 Step 1057/1512: training loss=0.00
2024-08-05 14:19:51 Step 1056/1512: training loss=0.00
2024-08-05 14:19:51 Step 1055/1512: training loss=0.36
2024-08-05 14:19:47 Step 1054/1512: training loss=0.00
2024-08-05 14:19:44 Step 1053/1512: training loss=0.00
2024-08-05 14:19:44 Step 1052/1512: training loss=0.00
2024-08-05 14:19:44 Step 1051/1512: training loss=0.00
2024-08-05 14:19:39 Step 1050/1512: training loss=0.00
2024-08-05 14:19:38 Step 1049/1512: training loss=0.43
2024-08-05 14:19:33 Step 1048/1512: training loss=0.23
2024-08-05 14:19:33 Step 1047/1512: training loss=0.00
2024-08-05 14:19:28 Step 1046/1512: training loss=0.00
2024-08-05 14:19:25 Step 1045/1512: training loss=0.00
2024-08-05 14:19:25 Step 1044/1512: training loss=0.00
2024-08-05 14:19:21 Step 1043/1512: training loss=0.00
2024-08-05 14:19:20 Step 1042/1512: training loss=0.00
2024-08-05 14:19:17 Step 1041/1512: training loss=0.00
2024-08-05 14:19:16 Step 1040/1512: training loss=0.00
2024-08-05 14:19:12 Step 1039/1512: training loss=0.00
2024-08-05 14:19:11 Step 1038/1512: training loss=0.00
2024-08-05 14:19:08 Step 1037/1512: training loss=0.00
2024-08-05 14:19:08 Step 1036/1512: training loss=0.00
2024-08-05 14:19:04 Step 1035/1512: training loss=0.82
2024-08-05 14:19:04 Step 1034/1512: training loss=0.42
2024-08-05 14:19:03 Step 1033/1512: training loss=0.00
2024-08-05 14:18:58 Step 1032/1512: training loss=0.00
2024-08-05 14:18:57 Step 1031/1512: training loss=0.00
2024-08-05 14:18:52 Step 1030/1512: training loss=0.00
2024-08-05 14:18:52 Step 1029/1512: training loss=0.00
2024-08-05 14:18:48 Step 1028/1512: training loss=0.00
2024-08-05 14:18:44 Step 1027/1512: training loss=0.00
2024-08-05 14:18:44 Step 1026/1512: training loss=0.00
2024-08-05 14:18:41 Step 1025/1512: training loss=0.00
2024-08-05 14:18:40 Step 1024/1512: training loss=0.56
2024-08-05 14:18:36 Step 1023/1512: training loss=0.00
2024-08-05 14:18:36 Step 1022/1512: training loss=0.00
2024-08-05 14:18:33 Step 1021/1512: training loss=0.00
2024-08-05 14:18:32 Step 1020/1512: training loss=0.00
2024-08-05 14:18:31 Step 1019/1512: training loss=0.00
2024-08-05 14:18:26 Step 1018/1512: training loss=0.00
2024-08-05 14:18:25 Step 1017/1512: training loss=0.00
2024-08-05 14:18:21 Step 1016/1512: training loss=0.31
2024-08-05 14:18:21 Step 1015/1512: training loss=0.32
2024-08-05 14:18:17 Step 1014/1512: training loss=0.00
2024-08-05 14:18:13 Step 1013/1512: training loss=0.30
2024-08-05 14:18:13 Step 1012/1512: training loss=0.00
2024-08-05 14:18:13 Step 1011/1512: training loss=0.00
2024-08-05 14:18:07 Step 1010/1512: training loss=0.00
2024-08-05 14:18:04 Step 1009/1512: training loss=0.00
2024-08-05 14:18:04 Step 1008/1512: training loss=0.03
2024-08-05 14:18:01 Step 1007/1512: training loss=0.54
2024-08-05 14:17:59 Step 1006/1512: training loss=0.00, full validation loss=0.13
2024-08-05 14:17:35 Step 1005/1512: training loss=0.00
2024-08-05 14:17:32 Step 1004/1512: training loss=0.00
2024-08-05 14:17:30 Step 1003/1512: training loss=0.00
2024-08-05 14:17:27 Step 1002/1512: training loss=0.00
2024-08-05 14:17:27 Step 1001/1512: training loss=0.01
2024-08-05 14:17:22 Step 1000/1512: training loss=0.00, validation loss=0.00
2024-08-05 14:17:21 Step 999/1512: training loss=0.70
2024-08-05 14:17:16 Step 998/1512: training loss=0.39
2024-08-05 14:17:16 Step 997/1512: training loss=0.39
2024-08-05 14:17:13 Step 996/1512: training loss=0.44
2024-08-05 14:17:12 Step 995/1512: training loss=0.33
2024-08-05 14:17:08 Step 994/1512: training loss=0.00
2024-08-05 14:17:08 Step 993/1512: training loss=0.00
2024-08-05 14:17:05 Step 992/1512: training loss=0.00
2024-08-05 14:17:04 Step 991/1512: training loss=0.00
2024-08-05 14:16:59 Step 990/1512: training loss=0.00
2024-08-05 14:16:59 Step 989/1512: training loss=0.00
2024-08-05 14:16:55 Step 988/1512: training loss=0.39
2024-08-05 14:16:51 Step 987/1512: training loss=0.24
2024-08-05 14:16:51 Step 986/1512: training loss=0.00
2024-08-05 14:16:48 Step 985/1512: training loss=0.00
2024-08-05 14:16:48 Step 984/1512: training loss=0.45
2024-08-05 14:16:47 Step 983/1512: training loss=0.00
2024-08-05 14:16:41 Step 982/1512: training loss=0.00
2024-08-05 14:16:40 Step 981/1512: training loss=0.00
2024-08-05 14:16:36 Step 980/1512: training loss=0.21
2024-08-05 14:16:36 Step 979/1512: training loss=0.00
2024-08-05 14:16:32 Step 978/1512: training loss=0.00
2024-08-05 14:16:31 Step 977/1512: training loss=0.00
2024-08-05 14:16:28 Step 976/1512: training loss=0.28
2024-08-05 14:16:28 Step 975/1512: training loss=0.00
2024-08-05 14:16:23 Step 974/1512: training loss=0.00
2024-08-05 14:16:20 Step 973/1512: training loss=0.00
2024-08-05 14:16:20 Step 972/1512: training loss=0.00
2024-08-05 14:16:20 Step 971/1512: training loss=0.34
2024-08-05 14:16:15 Step 970/1512: training loss=0.00
2024-08-05 14:16:14 Step 969/1512: training loss=0.00
2024-08-05 14:16:09 Step 968/1512: training loss=0.22
2024-08-05 14:16:09 Step 967/1512: training loss=0.24
2024-08-05 14:16:05 Step 966/1512: training loss=0.15
2024-08-05 14:16:01 Step 965/1512: training loss=0.00
2024-08-05 14:16:01 Step 964/1512: training loss=0.00
2024-08-05 14:15:58 Step 963/1512: training loss=0.36
2024-08-05 14:15:57 Step 962/1512: training loss=0.00
2024-08-05 14:15:53 Step 961/1512: training loss=0.12
2024-08-05 14:15:52 Step 960/1512: training loss=0.00
2024-08-05 14:15:49 Step 959/1512: training loss=0.64
2024-08-05 14:15:48 Step 958/1512: training loss=0.00
2024-08-05 14:15:44 Step 957/1512: training loss=0.00
2024-08-05 14:15:44 Step 956/1512: training loss=0.00
2024-08-05 14:15:41 Step 955/1512: training loss=0.33
2024-08-05 14:15:41 Step 954/1512: training loss=0.00
2024-08-05 14:15:40 Step 953/1512: training loss=0.30
2024-08-05 14:15:34 Step 952/1512: training loss=0.06
2024-08-05 14:15:33 Step 951/1512: training loss=0.60
2024-08-05 14:15:29 Step 950/1512: training loss=0.00
2024-08-05 14:15:29 Step 949/1512: training loss=0.41
2024-08-05 14:15:24 Step 948/1512: training loss=0.72
2024-08-05 14:15:21 Step 947/1512: training loss=0.00
2024-08-05 14:15:21 Step 946/1512: training loss=0.00
2024-08-05 14:15:17 Step 945/1512: training loss=0.00
2024-08-05 14:15:16 Step 944/1512: training loss=0.00
2024-08-05 14:15:13 Step 943/1512: training loss=0.00
2024-08-05 14:15:13 Step 942/1512: training loss=0.00
2024-08-05 14:15:09 Step 941/1512: training loss=0.00
2024-08-05 14:15:08 Step 940/1512: training loss=0.40
2024-08-05 14:15:07 Step 939/1512: training loss=0.00
2024-08-05 14:15:02 Step 938/1512: training loss=0.71
2024-08-05 14:15:02 Step 937/1512: training loss=0.65
2024-08-05 14:14:58 Step 936/1512: training loss=0.63
2024-08-05 14:14:54 Step 935/1512: training loss=0.00
2024-08-05 14:14:54 Step 934/1512: training loss=0.00
2024-08-05 14:14:51 Step 933/1512: training loss=0.32
2024-08-05 14:14:51 Step 932/1512: training loss=0.00
2024-08-05 14:14:50 Step 931/1512: training loss=0.00
2024-08-05 14:14:44 Step 930/1512: training loss=0.00
2024-08-05 14:14:43 Step 929/1512: training loss=0.00
2024-08-05 14:14:40 Step 928/1512: training loss=0.27
2024-08-05 14:14:40 Step 927/1512: training loss=0.00
2024-08-05 14:14:36 Step 926/1512: training loss=0.00
2024-08-05 14:14:36 Step 925/1512: training loss=0.09
2024-08-05 14:14:35 Step 924/1512: training loss=0.45
2024-08-05 14:14:29 Step 923/1512: training loss=0.00
2024-08-05 14:14:25 Step 922/1512: training loss=0.20
2024-08-05 14:14:25 Step 921/1512: training loss=0.35
2024-08-05 14:14:20 Step 920/1512: training loss=0.00
2024-08-05 14:14:16 Step 919/1512: training loss=0.72
2024-08-05 14:14:16 Step 918/1512: training loss=0.00
2024-08-05 14:14:12 Step 917/1512: training loss=0.00
2024-08-05 14:14:08 Step 916/1512: training loss=0.26
2024-08-05 14:14:08 Step 915/1512: training loss=0.30
2024-08-05 14:14:08 Step 914/1512: training loss=0.44
2024-08-05 14:14:04 Step 913/1512: training loss=0.00
2024-08-05 14:14:04 Step 912/1512: training loss=0.00
2024-08-05 14:14:03 Step 911/1512: training loss=0.32
2024-08-05 14:13:56 Step 910/1512: training loss=0.40
2024-08-05 14:13:56 Step 909/1512: training loss=0.03
2024-08-05 14:13:52 Step 908/1512: training loss=0.00
2024-08-05 14:13:48 Step 907/1512: training loss=0.00
2024-08-05 14:13:48 Step 906/1512: training loss=0.00
2024-08-05 14:13:45 Step 905/1512: training loss=0.41
2024-08-05 14:13:44 Step 904/1512: training loss=0.00
2024-08-05 14:13:40 Step 903/1512: training loss=0.00
2024-08-05 14:13:40 Step 902/1512: training loss=0.00
2024-08-05 14:13:37 Step 901/1512: training loss=0.00
2024-08-05 14:13:35 Step 900/1512: training loss=0.00, validation loss=0.00
2024-08-05 14:13:31 Step 899/1512: training loss=0.00
2024-08-05 14:13:31 Step 898/1512: training loss=0.00
2024-08-05 14:13:28 Step 897/1512: training loss=0.24
2024-08-05 14:13:27 Step 896/1512: training loss=0.00
2024-08-05 14:13:22 Step 895/1512: training loss=0.00
2024-08-05 14:13:20 Step 894/1512: training loss=0.00
2024-08-05 14:13:17 Step 893/1512: training loss=0.00
2024-08-05 14:13:17 Step 892/1512: training loss=0.41
2024-08-05 14:13:13 Step 891/1512: training loss=0.00
2024-08-05 14:13:11 Step 890/1512: training loss=0.00
2024-08-05 14:13:08 Step 889/1512: training loss=0.00
2024-08-05 14:13:08 Step 888/1512: training loss=0.78
2024-08-05 14:13:04 Step 887/1512: training loss=0.37
2024-08-05 14:13:03 Step 886/1512: training loss=0.00
2024-08-05 14:13:00 Step 885/1512: training loss=0.33
2024-08-05 14:13:00 Step 884/1512: training loss=0.00
2024-08-05 14:12:56 Step 883/1512: training loss=0.00
2024-08-05 14:12:55 Step 882/1512: training loss=0.00
2024-08-05 14:12:50 Step 881/1512: training loss=0.00
2024-08-05 14:12:49 Step 880/1512: training loss=0.33
2024-08-05 14:12:46 Step 879/1512: training loss=0.49
2024-08-05 14:12:44 Step 878/1512: training loss=0.00
2024-08-05 14:12:41 Step 877/1512: training loss=0.00
2024-08-05 14:12:41 Step 876/1512: training loss=0.00
2024-08-05 14:12:36 Step 875/1512: training loss=0.00
2024-08-05 14:12:33 Step 874/1512: training loss=0.22
2024-08-05 14:12:33 Step 873/1512: training loss=0.00
2024-08-05 14:12:29 Step 872/1512: training loss=0.00
2024-08-05 14:12:28 Step 871/1512: training loss=0.00
2024-08-05 14:12:24 Step 870/1512: training loss=0.31
2024-08-05 14:12:24 Step 869/1512: training loss=0.00
2024-08-05 14:12:20 Step 868/1512: training loss=0.00
2024-08-05 14:12:20 Step 867/1512: training loss=0.00
2024-08-05 14:12:19 Step 866/1512: training loss=0.31
2024-08-05 14:12:14 Step 865/1512: training loss=0.00
2024-08-05 14:12:13 Step 864/1512: training loss=0.00
2024-08-05 14:12:10 Step 863/1512: training loss=0.00
2024-08-05 14:12:10 Step 862/1512: training loss=0.42
2024-08-05 14:12:06 Step 861/1512: training loss=0.88
2024-08-05 14:12:04 Step 860/1512: training loss=0.33
2024-08-05 14:12:00 Step 859/1512: training loss=0.00
2024-08-05 14:12:00 Step 858/1512: training loss=0.00
2024-08-05 14:11:56 Step 857/1512: training loss=0.00
2024-08-05 14:11:52 Step 856/1512: training loss=0.47
2024-08-05 14:11:52 Step 855/1512: training loss=0.00
2024-08-05 14:11:49 Step 854/1512: training loss=0.42
2024-08-05 14:11:49 Step 853/1512: training loss=0.42
2024-08-05 14:11:48 Step 852/1512: training loss=0.47
2024-08-05 14:11:43 Step 851/1512: training loss=0.00
2024-08-05 14:11:42 Step 850/1512: training loss=0.00
2024-08-05 14:11:38 Step 849/1512: training loss=0.00
2024-08-05 14:11:37 Step 848/1512: training loss=0.00
2024-08-05 14:11:34 Step 847/1512: training loss=0.49
2024-08-05 14:11:34 Step 846/1512: training loss=0.00
2024-08-05 14:11:29 Step 845/1512: training loss=0.00
2024-08-05 14:11:25 Step 844/1512: training loss=0.45
2024-08-05 14:11:25 Step 843/1512: training loss=0.00
2024-08-05 14:11:22 Step 842/1512: training loss=0.00
2024-08-05 14:11:21 Step 841/1512: training loss=0.00
2024-08-05 14:11:16 Step 840/1512: training loss=0.00
2024-08-05 14:11:16 Step 839/1512: training loss=0.00
2024-08-05 14:11:13 Step 838/1512: training loss=0.00
2024-08-05 14:11:13 Step 837/1512: training loss=0.00
2024-08-05 14:11:12 Step 836/1512: training loss=0.00
2024-08-05 14:11:07 Step 835/1512: training loss=0.00
2024-08-05 14:11:06 Step 834/1512: training loss=0.00
2024-08-05 14:11:02 Step 833/1512: training loss=0.00
2024-08-05 14:11:02 Step 832/1512: training loss=0.00
2024-08-05 14:10:59 Step 831/1512: training loss=0.00
2024-08-05 14:10:56 Step 830/1512: training loss=0.13
2024-08-05 14:10:53 Step 829/1512: training loss=0.00
2024-08-05 14:10:53 Step 828/1512: training loss=0.00
2024-08-05 14:10:48 Step 827/1512: training loss=0.00
2024-08-05 14:10:45 Step 826/1512: training loss=0.00
2024-08-05 14:10:45 Step 825/1512: training loss=0.00
2024-08-05 14:10:41 Step 824/1512: training loss=0.00
2024-08-05 14:10:41 Step 823/1512: training loss=0.00
2024-08-05 14:10:40 Step 822/1512: training loss=0.00
2024-08-05 14:10:35 Step 821/1512: training loss=0.00
2024-08-05 14:10:34 Step 820/1512: training loss=0.00
2024-08-05 14:10:31 Step 819/1512: training loss=0.00
2024-08-05 14:10:30 Step 818/1512: training loss=0.00
2024-08-05 14:10:26 Step 817/1512: training loss=0.26
2024-08-05 14:10:26 Step 816/1512: training loss=0.33
2024-08-05 14:10:22 Step 815/1512: training loss=0.00
2024-08-05 14:10:18 Step 814/1512: training loss=0.00
2024-08-05 14:10:18 Step 813/1512: training loss=0.00
2024-08-05 14:10:15 Step 812/1512: training loss=0.00
2024-08-05 14:10:13 Step 811/1512: training loss=0.33
2024-08-05 14:10:09 Step 810/1512: training loss=0.00
2024-08-05 14:10:09 Step 809/1512: training loss=0.00
2024-08-05 14:10:05 Step 808/1512: training loss=0.24
2024-08-05 14:10:05 Step 807/1512: training loss=0.00
2024-08-05 14:10:04 Step 806/1512: training loss=0.32
2024-08-05 14:09:59 Step 805/1512: training loss=0.34
2024-08-05 14:09:58 Step 804/1512: training loss=0.39
2024-08-05 14:09:55 Step 803/1512: training loss=0.00
2024-08-05 14:09:55 Step 802/1512: training loss=0.00
2024-08-05 14:09:51 Step 801/1512: training loss=0.00
2024-08-05 14:09:49 Step 800/1512: training loss=0.00, validation loss=0.35
2024-08-05 14:09:46 Step 799/1512: training loss=0.00
2024-08-05 14:09:46 Step 798/1512: training loss=0.00
2024-08-05 14:09:41 Step 797/1512: training loss=0.00
2024-08-05 14:09:37 Step 796/1512: training loss=0.15
2024-08-05 14:09:37 Step 795/1512: training loss=0.00
2024-08-05 14:09:34 Step 794/1512: training loss=0.00
2024-08-05 14:09:34 Step 793/1512: training loss=0.00
2024-08-05 14:09:33 Step 792/1512: training loss=0.00
2024-08-05 14:09:28 Step 791/1512: training loss=0.00
2024-08-05 14:09:27 Step 790/1512: training loss=0.00
2024-08-05 14:09:23 Step 789/1512: training loss=0.23
2024-08-05 14:09:22 Step 788/1512: training loss=0.30
2024-08-05 14:09:19 Step 787/1512: training loss=0.28
2024-08-05 14:09:19 Step 786/1512: training loss=0.00
2024-08-05 14:09:14 Step 785/1512: training loss=0.00
2024-08-05 14:09:11 Step 784/1512: training loss=0.39
2024-08-05 14:09:11 Step 783/1512: training loss=0.00
2024-08-05 14:09:07 Step 782/1512: training loss=0.00
2024-08-05 14:09:06 Step 781/1512: training loss=0.34
2024-08-05 14:09:02 Step 780/1512: training loss=0.37
2024-08-05 14:09:02 Step 779/1512: training loss=0.34
2024-08-05 14:08:58 Step 778/1512: training loss=0.00
2024-08-05 14:08:58 Step 777/1512: training loss=0.00
2024-08-05 14:08:57 Step 776/1512: training loss=0.50
2024-08-05 14:08:52 Step 775/1512: training loss=0.78
2024-08-05 14:08:52 Step 774/1512: training loss=0.00
2024-08-05 14:08:48 Step 773/1512: training loss=0.00
2024-08-05 14:08:47 Step 772/1512: training loss=0.00
2024-08-05 14:08:44 Step 771/1512: training loss=0.00
2024-08-05 14:08:43 Step 770/1512: training loss=0.00
2024-08-05 14:08:38 Step 769/1512: training loss=0.00
2024-08-05 14:08:35 Step 768/1512: training loss=0.00
2024-08-05 14:08:35 Step 767/1512: training loss=0.00
2024-08-05 14:08:30 Step 766/1512: training loss=0.00
2024-08-05 14:08:04 Step 765/1512: training loss=0.00
2024-08-05 14:08:04 Step 764/1512: training loss=0.33
2024-08-05 14:08:00 Step 763/1512: training loss=0.40
2024-08-05 14:07:59 Step 762/1512: training loss=0.00
2024-08-05 14:07:56 Step 761/1512: training loss=0.00
2024-08-05 14:07:55 Step 760/1512: training loss=0.00
2024-08-05 14:07:51 Step 759/1512: training loss=0.00
2024-08-05 14:07:50 Step 758/1512: training loss=0.00
2024-08-05 14:07:45 Step 757/1512: training loss=0.00
2024-08-05 14:07:45 Step 756/1512: training loss=0.26
2024-08-05 14:07:45 Step 755/1512: training loss=0.00
2024-08-05 14:07:41 Step 754/1512: training loss=0.27
2024-08-05 14:07:37 Step 753/1512: training loss=0.30
2024-08-05 14:07:37 Step 752/1512: training loss=0.14
2024-08-05 14:07:37 Step 751/1512: training loss=0.09
2024-08-05 14:07:31 Step 750/1512: training loss=0.00
2024-08-05 14:07:28 Step 749/1512: training loss=0.00
2024-08-05 14:07:28 Step 748/1512: training loss=0.27
2024-08-05 14:07:24 Step 747/1512: training loss=0.00
2024-08-05 14:07:23 Step 746/1512: training loss=0.31
2024-08-05 14:07:20 Step 745/1512: training loss=0.36
2024-08-05 14:07:20 Step 744/1512: training loss=0.00
2024-08-05 14:07:16 Step 743/1512: training loss=0.39
2024-08-05 14:07:16 Step 742/1512: training loss=0.70
2024-08-05 14:07:15 Step 741/1512: training loss=0.00
2024-08-05 14:07:08 Step 740/1512: training loss=0.00
2024-08-05 14:07:05 Step 739/1512: training loss=0.40
2024-08-05 14:07:05 Step 738/1512: training loss=0.42
2024-08-05 14:07:01 Step 737/1512: training loss=0.00
2024-08-05 14:07:00 Step 736/1512: training loss=0.03
2024-08-05 14:06:57 Step 735/1512: training loss=0.00
2024-08-05 14:06:57 Step 734/1512: training loss=0.00
2024-08-05 14:06:53 Step 733/1512: training loss=0.41
2024-08-05 14:06:52 Step 732/1512: training loss=0.00
2024-08-05 14:06:48 Step 731/1512: training loss=0.40
2024-08-05 14:06:47 Step 730/1512: training loss=0.00
2024-08-05 14:06:44 Step 729/1512: training loss=0.26
2024-08-05 14:06:43 Step 728/1512: training loss=0.00
2024-08-05 14:06:38 Step 727/1512: training loss=0.00
2024-08-05 14:06:38 Step 726/1512: training loss=0.01
2024-08-05 14:06:34 Step 725/1512: training loss=0.37
2024-08-05 14:06:33 Step 724/1512: training loss=0.00
2024-08-05 14:06:30 Step 723/1512: training loss=0.00
2024-08-05 14:06:30 Step 722/1512: training loss=0.00
2024-08-05 14:06:26 Step 721/1512: training loss=0.00
2024-08-05 14:06:24 Step 720/1512: training loss=0.00
2024-08-05 14:06:21 Step 719/1512: training loss=0.00
2024-08-05 14:06:21 Step 718/1512: training loss=0.31
2024-08-05 14:06:17 Step 717/1512: training loss=0.00
2024-08-05 14:06:16 Step 716/1512: training loss=0.00
2024-08-05 14:06:12 Step 715/1512: training loss=0.00
2024-08-05 14:06:12 Step 714/1512: training loss=0.00
2024-08-05 14:06:09 Step 713/1512: training loss=0.31
2024-08-05 14:06:09 Step 712/1512: training loss=0.36
2024-08-05 14:06:08 Step 711/1512: training loss=0.00
2024-08-05 14:06:01 Step 710/1512: training loss=0.32
2024-08-05 14:05:57 Step 709/1512: training loss=0.00
2024-08-05 14:05:57 Step 708/1512: training loss=0.00
2024-08-05 14:05:57 Step 707/1512: training loss=0.00
2024-08-05 14:05:53 Step 706/1512: training loss=0.00
2024-08-05 14:05:49 Step 705/1512: training loss=0.00
2024-08-05 14:05:49 Step 704/1512: training loss=0.61
2024-08-05 14:05:46 Step 703/1512: training loss=0.23
2024-08-05 14:05:45 Step 702/1512: training loss=0.00
2024-08-05 14:05:41 Step 701/1512: training loss=0.00
2024-08-05 14:05:40 Step 700/1512: training loss=0.11, validation loss=0.33
2024-08-05 14:05:36 Step 699/1512: training loss=0.00
2024-08-05 14:05:35 Step 698/1512: training loss=0.20
2024-08-05 14:05:30 Step 697/1512: training loss=0.26
2024-08-05 14:05:30 Step 696/1512: training loss=0.36
2024-08-05 14:05:27 Step 695/1512: training loss=0.00
2024-08-05 14:05:26 Step 694/1512: training loss=0.00
2024-08-05 14:05:22 Step 693/1512: training loss=0.06
2024-08-05 14:05:22 Step 692/1512: training loss=0.00
2024-08-05 14:05:19 Step 691/1512: training loss=0.00
2024-08-05 14:05:17 Step 690/1512: training loss=0.00
2024-08-05 14:05:13 Step 689/1512: training loss=0.36
2024-08-05 14:05:13 Step 688/1512: training loss=0.32
2024-08-05 14:05:10 Step 687/1512: training loss=0.00
2024-08-05 14:05:09 Step 686/1512: training loss=0.00
2024-08-05 14:05:05 Step 685/1512: training loss=0.84
2024-08-05 14:05:05 Step 684/1512: training loss=0.00
2024-08-05 14:05:02 Step 683/1512: training loss=0.00
2024-08-05 14:05:02 Step 682/1512: training loss=0.44
2024-08-05 14:05:00 Step 681/1512: training loss=0.37
2024-08-05 14:04:53 Step 680/1512: training loss=0.00
2024-08-05 14:04:50 Step 679/1512: training loss=0.00
2024-08-05 14:04:50 Step 678/1512: training loss=0.00
2024-08-05 14:04:50 Step 677/1512: training loss=0.00
2024-08-05 14:04:46 Step 676/1512: training loss=0.00
2024-08-05 14:04:44 Step 675/1512: training loss=0.00
2024-08-05 14:04:41 Step 674/1512: training loss=0.00
2024-08-05 14:04:41 Step 673/1512: training loss=0.37
2024-08-05 14:04:37 Step 672/1512: training loss=0.37
2024-08-05 14:04:36 Step 671/1512: training loss=0.00
2024-08-05 14:04:32 Step 670/1512: training loss=0.01
2024-08-05 14:04:32 Step 669/1512: training loss=0.00
2024-08-05 14:04:28 Step 668/1512: training loss=0.70
2024-08-05 14:04:27 Step 667/1512: training loss=0.00
2024-08-05 14:04:22 Step 666/1512: training loss=0.00
2024-08-05 14:04:21 Step 665/1512: training loss=0.01
2024-08-05 14:04:17 Step 664/1512: training loss=0.02
2024-08-05 14:04:17 Step 663/1512: training loss=0.00
2024-08-05 14:04:14 Step 662/1512: training loss=0.00
2024-08-05 14:04:13 Step 661/1512: training loss=0.00
2024-08-05 14:04:08 Step 660/1512: training loss=0.00
2024-08-05 14:04:08 Step 659/1512: training loss=0.00
2024-08-05 14:04:05 Step 658/1512: training loss=0.53
2024-08-05 14:04:03 Step 657/1512: training loss=0.00
2024-08-05 14:03:59 Step 656/1512: training loss=0.00
2024-08-05 14:03:59 Step 655/1512: training loss=0.16
2024-08-05 14:03:56 Step 654/1512: training loss=0.00
2024-08-05 14:03:56 Step 653/1512: training loss=0.00
2024-08-05 14:03:55 Step 652/1512: training loss=0.28
2024-08-05 14:03:50 Step 651/1512: training loss=0.00
2024-08-05 14:03:47 Step 650/1512: training loss=0.00
2024-08-05 14:03:44 Step 649/1512: training loss=0.32
2024-08-05 14:03:44 Step 648/1512: training loss=0.72
2024-08-05 14:03:39 Step 647/1512: training loss=0.00
2024-08-05 14:03:36 Step 646/1512: training loss=0.00
2024-08-05 14:03:36 Step 645/1512: training loss=0.00
2024-08-05 14:03:33 Step 644/1512: training loss=0.35
2024-08-05 14:03:31 Step 643/1512: training loss=0.35
2024-08-05 14:03:28 Step 642/1512: training loss=0.57
2024-08-05 14:03:28 Step 641/1512: training loss=0.30
2024-08-05 14:03:27 Step 640/1512: training loss=0.00
2024-08-05 14:03:23 Step 639/1512: training loss=0.64
2024-08-05 14:03:22 Step 638/1512: training loss=0.37
2024-08-05 14:03:17 Step 637/1512: training loss=0.00
2024-08-05 14:03:17 Step 636/1512: training loss=0.36
2024-08-05 14:03:13 Step 635/1512: training loss=0.00
2024-08-05 14:03:09 Step 634/1512: training loss=0.00
2024-08-05 14:03:09 Step 633/1512: training loss=0.00
2024-08-05 14:03:06 Step 632/1512: training loss=0.00
2024-08-05 14:03:05 Step 631/1512: training loss=0.87
2024-08-05 14:03:00 Step 630/1512: training loss=0.43
2024-08-05 14:03:00 Step 629/1512: training loss=0.00
2024-08-05 14:02:57 Step 628/1512: training loss=0.29
2024-08-05 14:02:56 Step 627/1512: training loss=0.42
2024-08-05 14:02:52 Step 626/1512: training loss=0.00
2024-08-05 14:02:52 Step 625/1512: training loss=0.00
2024-08-05 14:02:49 Step 624/1512: training loss=0.46
2024-08-05 14:02:48 Step 623/1512: training loss=0.00
2024-08-05 14:02:32 Step 622/1512: training loss=0.00
2024-08-05 14:02:31 Step 621/1512: training loss=0.00
2024-08-05 14:02:26 Step 620/1512: training loss=0.00
2024-08-05 14:02:26 Step 619/1512: training loss=0.00
2024-08-05 14:02:22 Step 618/1512: training loss=0.00
2024-08-05 14:02:18 Step 617/1512: training loss=0.00
2024-08-05 14:02:18 Step 616/1512: training loss=0.00
2024-08-05 14:02:15 Step 615/1512: training loss=0.39
2024-08-05 14:02:14 Step 614/1512: training loss=0.00
2024-08-05 14:02:09 Step 613/1512: training loss=0.00
2024-08-05 14:02:09 Step 612/1512: training loss=0.00
2024-08-05 14:02:09 Step 611/1512: training loss=0.00
2024-08-05 14:02:04 Step 610/1512: training loss=0.00
2024-08-05 14:02:03 Step 609/1512: training loss=0.02
2024-08-05 14:02:00 Step 608/1512: training loss=0.37
2024-08-05 14:02:00 Step 607/1512: training loss=0.36
2024-08-05 14:01:55 Step 606/1512: training loss=0.00
2024-08-05 14:01:52 Step 605/1512: training loss=0.02
2024-08-05 14:01:52 Step 604/1512: training loss=0.00
2024-08-05 14:01:48 Step 603/1512: training loss=0.09
2024-08-05 14:01:47 Step 602/1512: training loss=0.00
2024-08-05 14:01:38 Step 601/1512: training loss=0.00
2024-08-05 14:01:37 Step 600/1512: training loss=0.00, validation loss=0.77
2024-08-05 14:01:33 Step 599/1512: training loss=0.00
2024-08-05 14:01:29 Step 598/1512: training loss=0.00
2024-08-05 14:01:29 Step 597/1512: training loss=0.42
2024-08-05 14:01:26 Step 596/1512: training loss=0.13
2024-08-05 14:01:25 Step 595/1512: training loss=0.00
2024-08-05 14:01:21 Step 594/1512: training loss=0.00
2024-08-05 14:01:21 Step 593/1512: training loss=0.42
2024-08-05 14:01:18 Step 592/1512: training loss=0.30
2024-08-05 14:01:17 Step 591/1512: training loss=0.00
2024-08-05 14:01:12 Step 590/1512: training loss=0.00
2024-08-05 14:01:12 Step 589/1512: training loss=0.00
2024-08-05 14:01:09 Step 588/1512: training loss=0.00
2024-08-05 14:01:08 Step 587/1512: training loss=0.13
2024-08-05 14:01:03 Step 586/1512: training loss=0.00
2024-08-05 14:01:03 Step 585/1512: training loss=0.21
2024-08-05 14:00:59 Step 584/1512: training loss=0.00
2024-08-05 14:00:58 Step 583/1512: training loss=0.31
2024-08-05 14:00:55 Step 582/1512: training loss=0.00
2024-08-05 14:00:55 Step 581/1512: training loss=0.30
2024-08-05 14:00:50 Step 580/1512: training loss=0.00
2024-08-05 14:00:49 Step 579/1512: training loss=0.00
2024-08-05 14:00:46 Step 578/1512: training loss=0.29
2024-08-05 14:00:46 Step 577/1512: training loss=0.04
2024-08-05 14:00:41 Step 576/1512: training loss=0.00
2024-08-05 14:00:38 Step 575/1512: training loss=0.00
2024-08-05 14:00:38 Step 574/1512: training loss=0.35
2024-08-05 14:00:34 Step 573/1512: training loss=0.28
2024-08-05 14:00:34 Step 572/1512: training loss=0.23
2024-08-05 14:00:33 Step 571/1512: training loss=0.30
2024-08-05 14:00:27 Step 570/1512: training loss=0.00
2024-08-05 14:00:27 Step 569/1512: training loss=0.40
2024-08-05 14:00:23 Step 568/1512: training loss=0.00
2024-08-05 14:00:22 Step 567/1512: training loss=0.41
2024-08-05 14:00:19 Step 566/1512: training loss=0.42
2024-08-05 14:00:19 Step 565/1512: training loss=0.00
2024-08-05 14:00:14 Step 564/1512: training loss=0.21
2024-08-05 14:00:11 Step 563/1512: training loss=0.00
2024-08-05 14:00:11 Step 562/1512: training loss=0.00
2024-08-05 14:00:11 Step 561/1512: training loss=0.00
2024-08-05 14:00:05 Step 560/1512: training loss=0.27
2024-08-05 14:00:02 Step 559/1512: training loss=0.00
2024-08-05 14:00:02 Step 558/1512: training loss=0.00
2024-08-05 13:59:58 Step 557/1512: training loss=0.00
2024-08-05 13:59:58 Step 556/1512: training loss=0.82
2024-08-05 13:59:57 Step 555/1512: training loss=0.00
2024-08-05 13:59:52 Step 554/1512: training loss=0.35
2024-08-05 13:59:51 Step 553/1512: training loss=0.00
2024-08-05 13:59:47 Step 552/1512: training loss=0.00
2024-08-05 13:59:47 Step 551/1512: training loss=0.28
2024-08-05 13:59:43 Step 550/1512: training loss=0.00
2024-08-05 13:59:42 Step 549/1512: training loss=0.00
2024-08-05 13:59:38 Step 548/1512: training loss=0.32
2024-08-05 13:59:38 Step 547/1512: training loss=0.00
2024-08-05 13:59:35 Step 546/1512: training loss=0.00
2024-08-05 13:59:34 Step 545/1512: training loss=0.00
2024-08-05 13:59:30 Step 544/1512: training loss=0.50
2024-08-05 13:59:30 Step 543/1512: training loss=0.00
2024-08-05 13:59:27 Step 542/1512: training loss=0.50
2024-08-05 13:59:27 Step 541/1512: training loss=0.00
2024-08-05 13:59:25 Step 540/1512: training loss=0.00
2024-08-05 13:59:18 Step 539/1512: training loss=0.00
2024-08-05 13:59:15 Step 538/1512: training loss=0.00
2024-08-05 13:59:15 Step 537/1512: training loss=0.19
2024-08-05 13:59:12 Step 536/1512: training loss=0.26
2024-08-05 13:59:10 Step 535/1512: training loss=0.00
2024-08-05 13:59:07 Step 534/1512: training loss=0.00
2024-08-05 13:59:07 Step 533/1512: training loss=0.31
2024-08-05 13:59:03 Step 532/1512: training loss=0.35
2024-08-05 13:59:02 Step 531/1512: training loss=0.00
2024-08-05 13:58:58 Step 530/1512: training loss=0.00
2024-08-05 13:58:58 Step 529/1512: training loss=0.35
2024-08-05 13:58:54 Step 528/1512: training loss=0.34
2024-08-05 13:58:54 Step 527/1512: training loss=0.46
2024-08-05 13:58:53 Step 526/1512: training loss=0.00
2024-08-05 13:58:47 Step 525/1512: training loss=0.00
2024-08-05 13:58:44 Step 524/1512: training loss=0.00
2024-08-05 13:58:44 Step 523/1512: training loss=0.00
2024-08-05 13:58:40 Step 522/1512: training loss=0.29
2024-08-05 13:58:39 Step 521/1512: training loss=0.00
2024-08-05 13:58:35 Step 520/1512: training loss=0.36
2024-08-05 13:58:35 Step 519/1512: training loss=0.26
2024-08-05 13:58:31 Step 518/1512: training loss=0.29
2024-08-05 13:58:30 Step 517/1512: training loss=0.00
2024-08-05 13:58:27 Step 516/1512: training loss=0.00
2024-08-05 13:58:27 Step 515/1512: training loss=0.33
2024-08-05 13:58:23 Step 514/1512: training loss=0.00
2024-08-05 13:58:23 Step 513/1512: training loss=0.00
2024-08-05 13:58:22 Step 512/1512: training loss=0.00
2024-08-05 13:58:19 Step 511/1512: training loss=0.34
2024-08-05 13:58:15 Step 510/1512: training loss=0.00
2024-08-05 13:58:11 Step 509/1512: training loss=0.42
2024-08-05 13:58:11 Step 508/1512: training loss=0.00
2024-08-05 13:58:07 Step 507/1512: training loss=0.90
2024-08-05 13:58:03 Step 506/1512: training loss=0.00
2024-08-05 13:58:03 Step 505/1512: training loss=0.00
2024-08-05 13:58:00 Step 504/1512: training loss=0.00
2024-08-05 13:57:59 Step 503/1512: training loss=0.00, full validation loss=0.32
2024-08-05 13:57:34 Step 502/1512: training loss=0.48
2024-08-05 13:57:34 Step 501/1512: training loss=0.00
2024-08-05 13:57:29 Step 500/1512: training loss=0.00, validation loss=0.55
2024-08-05 13:57:25 Step 499/1512: training loss=0.52
2024-08-05 13:57:25 Step 498/1512: training loss=0.52
2024-08-05 13:57:21 Step 497/1512: training loss=0.00
2024-08-05 13:57:17 Step 496/1512: training loss=0.00
2024-08-05 13:57:17 Step 495/1512: training loss=0.00
2024-08-05 13:57:17 Step 494/1512: training loss=0.00
2024-08-05 13:57:14 Step 493/1512: training loss=0.38
2024-08-05 13:57:14 Step 492/1512: training loss=0.00
2024-08-05 13:57:13 Step 491/1512: training loss=0.00
2024-08-05 13:57:05 Step 490/1512: training loss=0.00
2024-08-05 13:57:02 Step 489/1512: training loss=0.00
2024-08-05 13:57:02 Step 488/1512: training loss=0.00
2024-08-05 13:56:58 Step 487/1512: training loss=0.00
2024-08-05 13:56:57 Step 486/1512: training loss=0.00
2024-08-05 13:56:54 Step 485/1512: training loss=0.00
2024-08-05 13:56:54 Step 484/1512: training loss=0.25
2024-08-05 13:56:50 Step 483/1512: training loss=0.00
2024-08-05 13:56:49 Step 482/1512: training loss=0.87
2024-08-05 13:56:46 Step 481/1512: training loss=0.00
2024-08-05 13:56:45 Step 480/1512: training loss=0.02
2024-08-05 13:56:41 Step 479/1512: training loss=0.00
2024-08-05 13:56:40 Step 478/1512: training loss=0.00
2024-08-05 13:56:35 Step 477/1512: training loss=0.38
2024-08-05 13:56:35 Step 476/1512: training loss=0.00
2024-08-05 13:56:32 Step 475/1512: training loss=0.42
2024-08-05 13:56:31 Step 474/1512: training loss=0.00
2024-08-05 13:56:27 Step 473/1512: training loss=0.56
2024-08-05 13:56:27 Step 472/1512: training loss=0.00
2024-08-05 13:56:24 Step 471/1512: training loss=0.71
2024-08-05 13:56:21 Step 470/1512: training loss=0.39
2024-08-05 13:56:18 Step 469/1512: training loss=0.37
2024-08-05 13:56:18 Step 468/1512: training loss=0.00
2024-08-05 13:56:13 Step 467/1512: training loss=0.35
2024-08-05 13:56:10 Step 466/1512: training loss=0.33
2024-08-05 13:56:10 Step 465/1512: training loss=0.00
2024-08-05 13:56:07 Step 464/1512: training loss=0.00
2024-08-05 13:56:07 Step 463/1512: training loss=0.00
2024-08-05 13:56:07 Step 462/1512: training loss=0.00
2024-08-05 13:56:05 Step 461/1512: training loss=0.04
2024-08-05 13:55:58 Step 460/1512: training loss=0.40
2024-08-05 13:55:55 Step 459/1512: training loss=0.00
2024-08-05 13:55:55 Step 458/1512: training loss=0.00
2024-08-05 13:55:51 Step 457/1512: training loss=0.60
2024-08-05 13:55:50 Step 456/1512: training loss=0.00
2024-08-05 13:55:47 Step 455/1512: training loss=0.00
2024-08-05 13:55:47 Step 454/1512: training loss=0.04
2024-08-05 13:55:43 Step 453/1512: training loss=0.00
2024-08-05 13:55:42 Step 452/1512: training loss=0.29
2024-08-05 13:55:39 Step 451/1512: training loss=0.00
2024-08-05 13:55:38 Step 450/1512: training loss=0.32
2024-08-05 13:55:34 Step 449/1512: training loss=0.00
2024-08-05 13:55:33 Step 448/1512: training loss=0.28
2024-08-05 13:55:28 Step 447/1512: training loss=0.00
2024-08-05 13:55:28 Step 446/1512: training loss=0.00
2024-08-05 13:55:25 Step 445/1512: training loss=0.23
2024-08-05 13:55:23 Step 444/1512: training loss=0.00
2024-08-05 13:55:20 Step 443/1512: training loss=0.00
2024-08-05 13:55:20 Step 442/1512: training loss=0.02
2024-08-05 13:55:16 Step 441/1512: training loss=0.00
2024-08-05 13:55:14 Step 440/1512: training loss=0.45
2024-08-05 13:55:11 Step 439/1512: training loss=0.27
2024-08-05 13:55:11 Step 438/1512: training loss=0.00
2024-08-05 13:55:06 Step 437/1512: training loss=0.27
2024-08-05 13:55:03 Step 436/1512: training loss=0.34
2024-08-05 13:55:03 Step 435/1512: training loss=0.33
2024-08-05 13:54:59 Step 434/1512: training loss=0.81
2024-08-05 13:54:59 Step 433/1512: training loss=0.25
2024-08-05 13:54:58 Step 432/1512: training loss=0.00
2024-08-05 13:54:53 Step 431/1512: training loss=0.00
2024-08-05 13:54:52 Step 430/1512: training loss=0.00
2024-08-05 13:54:49 Step 429/1512: training loss=0.25
2024-08-05 13:54:48 Step 428/1512: training loss=0.00
2024-08-05 13:54:43 Step 427/1512: training loss=0.00
2024-08-05 13:54:43 Step 426/1512: training loss=0.42
2024-08-05 13:54:39 Step 425/1512: training loss=0.00
2024-08-05 13:54:35 Step 424/1512: training loss=0.71
2024-08-05 13:54:35 Step 423/1512: training loss=0.00
2024-08-05 13:54:35 Step 422/1512: training loss=0.34
2024-08-05 13:54:32 Step 421/1512: training loss=0.18
2024-08-05 13:54:31 Step 420/1512: training loss=0.05
2024-08-05 13:54:30 Step 419/1512: training loss=1.04
2024-08-05 13:54:24 Step 418/1512: training loss=0.43
2024-08-05 13:54:20 Step 417/1512: training loss=0.56
2024-08-05 13:54:20 Step 416/1512: training loss=0.37
2024-08-05 13:54:17 Step 415/1512: training loss=0.00
2024-08-05 13:54:16 Step 414/1512: training loss=0.00
2024-08-05 13:54:12 Step 413/1512: training loss=0.00
2024-08-05 13:54:12 Step 412/1512: training loss=0.00
2024-08-05 13:54:12 Step 411/1512: training loss=0.00
2024-08-05 13:54:07 Step 410/1512: training loss=0.38
2024-08-05 13:54:02 Step 409/1512: training loss=0.00
2024-08-05 13:54:02 Step 408/1512: training loss=0.00
2024-08-05 13:54:02 Step 407/1512: training loss=0.12
2024-08-05 13:53:59 Step 406/1512: training loss=0.00
2024-08-05 13:53:58 Step 405/1512: training loss=0.00
2024-08-05 13:53:54 Step 404/1512: training loss=0.00
2024-08-05 13:53:52 Step 403/1512: training loss=0.25
2024-08-05 13:53:48 Step 402/1512: training loss=0.04
2024-08-05 13:53:48 Step 401/1512: training loss=0.18
2024-08-05 13:53:44 Step 400/1512: training loss=0.01, validation loss=0.24
2024-08-05 13:53:43 Step 399/1512: training loss=0.56
2024-08-05 13:53:05 Step 398/1512: training loss=0.44
2024-08-05 13:53:02 Step 397/1512: training loss=0.00
2024-08-05 13:53:02 Step 396/1512: training loss=0.46
2024-08-05 13:52:57 Step 395/1512: training loss=0.44
2024-08-05 13:52:54 Step 394/1512: training loss=0.39
2024-08-05 13:52:50 Step 393/1512: training loss=0.20
2024-08-05 13:52:50 Step 392/1512: training loss=0.38
2024-08-05 13:52:49 Step 391/1512: training loss=0.73
2024-08-05 13:52:43 Step 390/1512: training loss=0.00
2024-08-05 13:52:43 Step 389/1512: training loss=0.00
2024-08-05 13:52:40 Step 388/1512: training loss=0.00
2024-08-05 13:52:39 Step 387/1512: training loss=0.00
2024-08-05 13:52:35 Step 386/1512: training loss=0.00
2024-08-05 13:52:35 Step 385/1512: training loss=0.32
2024-08-05 13:52:32 Step 384/1512: training loss=0.00
2024-08-05 13:52:31 Step 383/1512: training loss=0.27
2024-08-05 13:52:27 Step 382/1512: training loss=0.31
2024-08-05 13:52:27 Step 381/1512: training loss=0.02
2024-08-05 13:52:23 Step 380/1512: training loss=0.00
2024-08-05 13:52:22 Step 379/1512: training loss=0.00
2024-08-05 13:52:18 Step 378/1512: training loss=0.25
2024-08-05 13:52:18 Step 377/1512: training loss=0.00
2024-08-05 13:52:15 Step 376/1512: training loss=0.46
2024-08-05 13:52:15 Step 375/1512: training loss=0.23
2024-08-05 13:52:14 Step 374/1512: training loss=0.00
2024-08-05 13:52:09 Step 373/1512: training loss=0.00
2024-08-05 13:52:08 Step 372/1512: training loss=0.10
2024-08-05 13:52:04 Step 371/1512: training loss=0.00
2024-08-05 13:52:03 Step 370/1512: training loss=0.26
2024-08-05 13:51:58 Step 369/1512: training loss=0.46
2024-08-05 13:51:55 Step 368/1512: training loss=0.00
2024-08-05 13:51:55 Step 367/1512: training loss=0.00
2024-08-05 13:51:55 Step 366/1512: training loss=0.26
2024-08-05 13:51:51 Step 365/1512: training loss=0.00
2024-08-05 13:51:47 Step 364/1512: training loss=0.00
2024-08-05 13:51:47 Step 363/1512: training loss=0.08
2024-08-05 13:51:47 Step 362/1512: training loss=0.00
2024-08-05 13:51:44 Step 361/1512: training loss=0.00
2024-08-05 13:51:42 Step 360/1512: training loss=0.16
2024-08-05 13:51:36 Step 359/1512: training loss=0.27
2024-08-05 13:51:36 Step 358/1512: training loss=0.02
2024-08-05 13:51:33 Step 357/1512: training loss=0.00
2024-08-05 13:51:32 Step 356/1512: training loss=0.00
2024-08-05 13:51:28 Step 355/1512: training loss=0.28
2024-08-05 13:51:28 Step 354/1512: training loss=0.00
2024-08-05 13:51:25 Step 353/1512: training loss=0.00
2024-08-05 13:51:24 Step 352/1512: training loss=0.06
2024-08-05 13:51:20 Step 351/1512: training loss=0.27
2024-08-05 13:51:19 Step 350/1512: training loss=0.00
2024-08-05 13:51:15 Step 349/1512: training loss=0.00
2024-08-05 13:51:11 Step 348/1512: training loss=0.51
2024-08-05 13:51:11 Step 347/1512: training loss=0.36
2024-08-05 13:51:08 Step 346/1512: training loss=0.34
2024-08-05 13:51:08 Step 345/1512: training loss=0.46
2024-08-05 13:51:07 Step 344/1512: training loss=0.05
2024-08-05 13:51:02 Step 343/1512: training loss=0.10
2024-08-05 13:51:01 Step 342/1512: training loss=0.00
2024-08-05 13:50:57 Step 341/1512: training loss=0.27
2024-08-05 13:50:56 Step 340/1512: training loss=0.00
2024-08-05 13:50:53 Step 339/1512: training loss=0.00
2024-08-05 13:50:52 Step 338/1512: training loss=0.00
2024-08-05 13:50:48 Step 337/1512: training loss=0.14
2024-08-05 13:50:48 Step 336/1512: training loss=0.30
2024-08-05 13:50:44 Step 335/1512: training loss=0.00
2024-08-05 13:50:40 Step 334/1512: training loss=0.29
2024-08-05 13:50:40 Step 333/1512: training loss=0.21
2024-08-05 13:50:40 Step 332/1512: training loss=0.00
2024-08-05 13:50:37 Step 331/1512: training loss=1.11
2024-08-05 13:50:35 Step 330/1512: training loss=0.95
2024-08-05 13:50:30 Step 329/1512: training loss=0.93
2024-08-05 13:50:30 Step 328/1512: training loss=0.00
2024-08-05 13:50:26 Step 327/1512: training loss=0.09
2024-08-05 13:50:25 Step 326/1512: training loss=0.00
2024-08-05 13:50:18 Step 325/1512: training loss=0.24
2024-08-05 13:50:17 Step 324/1512: training loss=0.38
2024-08-05 13:50:14 Step 323/1512: training loss=0.00
2024-08-05 13:50:14 Step 322/1512: training loss=0.08
2024-08-05 13:50:10 Step 321/1512: training loss=0.00
2024-08-05 13:50:08 Step 320/1512: training loss=0.00
2024-08-05 13:50:05 Step 319/1512: training loss=0.34
2024-08-05 13:50:05 Step 318/1512: training loss=0.00
2024-08-05 13:50:01 Step 317/1512: training loss=0.00
2024-08-05 13:50:00 Step 316/1512: training loss=0.18
2024-08-05 13:49:55 Step 315/1512: training loss=0.00
2024-08-05 13:49:55 Step 314/1512: training loss=0.29
2024-08-05 13:49:52 Step 313/1512: training loss=0.00
2024-08-05 13:49:50 Step 312/1512: training loss=0.00
2024-08-05 13:49:47 Step 311/1512: training loss=0.00
2024-08-05 13:49:46 Step 310/1512: training loss=0.58
2024-08-05 13:49:43 Step 309/1512: training loss=0.25
2024-08-05 13:49:41 Step 308/1512: training loss=0.37
2024-08-05 13:49:38 Step 307/1512: training loss=0.00
2024-08-05 13:49:38 Step 306/1512: training loss=0.28
2024-08-05 13:49:35 Step 305/1512: training loss=0.00
2024-08-05 13:49:33 Step 304/1512: training loss=0.00
2024-08-05 13:49:30 Step 303/1512: training loss=0.10
2024-08-05 13:49:30 Step 302/1512: training loss=0.34
2024-08-05 13:49:26 Step 301/1512: training loss=0.33
2024-08-05 13:49:18 Step 300/1512: training loss=0.23, validation loss=0.00
2024-08-05 13:49:15 Step 299/1512: training loss=0.00
2024-08-05 13:49:15 Step 298/1512: training loss=0.60
2024-08-05 13:49:10 Step 297/1512: training loss=0.00
2024-08-05 13:49:07 Step 296/1512: training loss=0.37
2024-08-05 13:49:07 Step 295/1512: training loss=0.38
2024-08-05 13:49:03 Step 294/1512: training loss=0.00
2024-08-05 13:49:02 Step 293/1512: training loss=0.00
2024-08-05 13:48:59 Step 292/1512: training loss=0.35
2024-08-05 13:48:59 Step 291/1512: training loss=0.31
2024-08-05 13:48:58 Step 290/1512: training loss=0.00
2024-08-05 13:48:54 Step 289/1512: training loss=0.00
2024-08-05 13:48:53 Step 288/1512: training loss=0.34
2024-08-05 13:48:48 Step 287/1512: training loss=0.00
2024-08-05 13:48:48 Step 286/1512: training loss=0.14
2024-08-05 13:48:45 Step 285/1512: training loss=0.00
2024-08-05 13:48:44 Step 284/1512: training loss=0.00
2024-08-05 13:48:40 Step 283/1512: training loss=0.00
2024-08-05 13:48:40 Step 282/1512: training loss=0.00
2024-08-05 13:48:37 Step 281/1512: training loss=0.38
2024-08-05 13:48:35 Step 280/1512: training loss=0.01
2024-08-05 13:48:31 Step 279/1512: training loss=0.05
2024-08-05 13:48:31 Step 278/1512: training loss=0.00
2024-08-05 13:48:27 Step 277/1512: training loss=0.12
2024-08-05 13:48:23 Step 276/1512: training loss=0.00
2024-08-05 13:48:23 Step 275/1512: training loss=0.20
2024-08-05 13:48:20 Step 274/1512: training loss=0.00
2024-08-05 13:48:20 Step 273/1512: training loss=0.00
2024-08-05 13:48:20 Step 272/1512: training loss=0.00
2024-08-05 13:48:19 Step 271/1512: training loss=0.00
2024-08-05 13:48:12 Step 270/1512: training loss=0.00
2024-08-05 13:48:08 Step 269/1512: training loss=0.01
2024-08-05 13:48:08 Step 268/1512: training loss=0.05
2024-08-05 13:48:05 Step 267/1512: training loss=0.09
2024-08-05 13:48:04 Step 266/1512: training loss=0.01
2024-08-05 13:48:00 Step 265/1512: training loss=0.00
2024-08-05 13:48:00 Step 264/1512: training loss=0.15
2024-08-05 13:47:56 Step 263/1512: training loss=0.14
2024-08-05 13:47:49 Step 262/1512: training loss=0.24
2024-08-05 13:47:49 Step 261/1512: training loss=0.05
2024-08-05 13:47:44 Step 260/1512: training loss=0.02
2024-08-05 13:47:43 Step 259/1512: training loss=0.00
2024-08-05 13:47:38 Step 258/1512: training loss=0.02
2024-08-05 13:47:38 Step 257/1512: training loss=0.06
2024-08-05 13:47:35 Step 256/1512: training loss=0.21
2024-08-05 13:47:33 Step 255/1512: training loss=0.23
2024-08-05 13:47:30 Step 254/1512: training loss=0.00
2024-08-05 13:47:30 Step 253/1512: training loss=0.01
2024-08-05 13:47:27 Step 252/1512: training loss=0.02
2024-08-05 13:47:26 Step 251/1512: training loss=0.01
2024-08-05 13:47:21 Step 250/1512: training loss=0.03
2024-08-05 13:47:21 Step 249/1512: training loss=0.06
2024-08-05 13:47:17 Step 248/1512: training loss=0.01
2024-08-05 13:47:13 Step 247/1512: training loss=0.21
2024-08-05 13:47:13 Step 246/1512: training loss=0.08
2024-08-05 13:47:10 Step 245/1512: training loss=0.01
2024-08-05 13:47:10 Step 244/1512: training loss=0.15
2024-08-05 13:47:09 Step 243/1512: training loss=0.01
2024-08-05 13:47:03 Step 242/1512: training loss=0.00
2024-08-05 13:47:02 Step 241/1512: training loss=0.03
2024-08-05 13:46:58 Step 240/1512: training loss=0.01
2024-08-05 13:46:58 Step 239/1512: training loss=0.01
2024-08-05 13:46:54 Step 238/1512: training loss=0.05
2024-08-05 13:46:53 Step 237/1512: training loss=0.05
2024-08-05 13:46:50 Step 236/1512: training loss=0.09
2024-08-05 13:46:50 Step 235/1512: training loss=0.02
2024-08-05 13:46:45 Step 234/1512: training loss=0.14
2024-08-05 13:46:42 Step 233/1512: training loss=0.02
2024-08-05 13:46:42 Step 232/1512: training loss=0.05
2024-08-05 13:46:42 Step 231/1512: training loss=0.05
2024-08-05 13:46:37 Step 230/1512: training loss=0.09
2024-08-05 13:46:36 Step 229/1512: training loss=0.27
2024-08-05 13:46:31 Step 228/1512: training loss=0.00
2024-08-05 13:46:31 Step 227/1512: training loss=0.17
2024-08-05 13:46:28 Step 226/1512: training loss=0.06
2024-08-05 13:46:27 Step 225/1512: training loss=0.09
2024-08-05 13:46:23 Step 224/1512: training loss=0.01
2024-08-05 13:46:23 Step 223/1512: training loss=0.00
2024-08-05 13:46:20 Step 222/1512: training loss=0.06
2024-08-05 13:46:19 Step 221/1512: training loss=0.05
2024-08-05 13:46:14 Step 220/1512: training loss=0.19
2024-08-05 13:46:14 Step 219/1512: training loss=0.15
2024-08-05 13:46:10 Step 218/1512: training loss=0.01
2024-08-05 13:46:06 Step 217/1512: training loss=0.02
2024-08-05 13:46:06 Step 216/1512: training loss=0.08
2024-08-05 13:46:03 Step 215/1512: training loss=0.10
2024-08-05 13:46:03 Step 214/1512: training loss=0.02
2024-08-05 13:46:02 Step 213/1512: training loss=0.04
2024-08-05 13:45:57 Step 212/1512: training loss=0.14
2024-08-05 13:45:56 Step 211/1512: training loss=0.01
2024-08-05 13:45:51 Step 210/1512: training loss=0.04
2024-08-05 13:45:51 Step 209/1512: training loss=0.09
2024-08-05 13:45:48 Step 208/1512: training loss=0.04
2024-08-05 13:45:47 Step 207/1512: training loss=0.03
2024-08-05 13:45:43 Step 206/1512: training loss=0.02
2024-08-05 13:45:43 Step 205/1512: training loss=0.01
2024-08-05 13:45:40 Step 204/1512: training loss=0.08
2024-08-05 13:45:39 Step 203/1512: training loss=0.01
2024-08-05 13:45:35 Step 202/1512: training loss=0.02
2024-08-05 13:45:35 Step 201/1512: training loss=0.05
2024-08-05 13:45:31 Step 200/1512: training loss=0.05, validation loss=0.09
2024-08-05 13:45:30 Step 199/1512: training loss=0.04
2024-08-05 13:45:24 Step 198/1512: training loss=0.12
2024-08-05 13:45:24 Step 197/1512: training loss=0.09
2024-08-05 13:45:21 Step 196/1512: training loss=0.00
2024-08-05 13:45:20 Step 195/1512: training loss=0.05
2024-08-05 13:45:16 Step 194/1512: training loss=0.16
2024-08-05 13:45:16 Step 193/1512: training loss=0.06
2024-08-05 13:45:13 Step 192/1512: training loss=0.06
2024-08-05 13:45:12 Step 191/1512: training loss=0.16
2024-08-05 13:45:07 Step 190/1512: training loss=0.44
2024-08-05 13:45:07 Step 189/1512: training loss=0.21
2024-08-05 13:45:04 Step 188/1512: training loss=0.23
2024-08-05 13:45:03 Step 187/1512: training loss=0.31
2024-08-05 13:45:00 Step 186/1512: training loss=0.21
2024-08-05 13:45:00 Step 185/1512: training loss=0.00
2024-08-05 13:44:56 Step 184/1512: training loss=0.22
2024-08-05 13:44:55 Step 183/1512: training loss=0.23
2024-08-05 13:44:50 Step 182/1512: training loss=0.06
2024-08-05 13:44:49 Step 181/1512: training loss=0.24
2024-08-05 13:44:44 Step 180/1512: training loss=0.00
2024-08-05 13:44:44 Step 179/1512: training loss=0.37
2024-08-05 13:44:44 Step 178/1512: training loss=0.04
2024-08-05 13:44:41 Step 177/1512: training loss=0.00
2024-08-05 13:44:39 Step 176/1512: training loss=0.00
2024-08-05 13:44:36 Step 175/1512: training loss=0.28
2024-08-05 13:44:36 Step 174/1512: training loss=0.28
2024-08-05 13:44:32 Step 173/1512: training loss=0.04
2024-08-05 13:44:31 Step 172/1512: training loss=0.03
2024-08-05 13:44:28 Step 171/1512: training loss=0.02
2024-08-05 13:44:27 Step 170/1512: training loss=0.05
2024-08-05 13:44:23 Step 169/1512: training loss=0.09
2024-08-05 13:44:23 Step 168/1512: training loss=0.12
2024-08-05 13:44:22 Step 167/1512: training loss=0.05
2024-08-05 13:44:16 Step 166/1512: training loss=0.01
2024-08-05 13:44:12 Step 165/1512: training loss=0.03
2024-08-05 13:44:12 Step 164/1512: training loss=0.08
2024-08-05 13:44:09 Step 163/1512: training loss=0.06
2024-08-05 13:44:08 Step 162/1512: training loss=0.04
2024-08-05 13:44:04 Step 161/1512: training loss=0.07
2024-08-05 13:44:03 Step 160/1512: training loss=0.03
2024-08-05 13:44:03 Step 159/1512: training loss=0.13
2024-08-05 13:43:58 Step 158/1512: training loss=0.21
2024-08-05 13:43:55 Step 157/1512: training loss=0.18
2024-08-05 13:43:55 Step 156/1512: training loss=0.08
2024-08-05 13:43:51 Step 155/1512: training loss=0.07
2024-08-05 13:43:51 Step 154/1512: training loss=0.15
2024-08-05 13:43:50 Step 153/1512: training loss=0.08
2024-08-05 13:43:45 Step 152/1512: training loss=0.07
2024-08-05 13:43:44 Step 151/1512: training loss=0.04
2024-08-05 13:43:39 Step 150/1512: training loss=0.07
2024-08-05 13:43:39 Step 149/1512: training loss=0.17
2024-08-05 13:43:36 Step 148/1512: training loss=0.29
2024-08-05 13:43:35 Step 147/1512: training loss=0.30
2024-08-05 13:43:31 Step 146/1512: training loss=0.08
2024-08-05 13:43:31 Step 145/1512: training loss=0.12
2024-08-05 13:43:28 Step 144/1512: training loss=0.14
2024-08-05 13:43:27 Step 143/1512: training loss=0.02
2024-08-05 13:43:23 Step 142/1512: training loss=0.24
2024-08-05 13:43:23 Step 141/1512: training loss=0.05
2024-08-05 13:43:19 Step 140/1512: training loss=0.13
2024-08-05 13:43:18 Step 139/1512: training loss=0.10
2024-08-05 13:43:13 Step 138/1512: training loss=0.37
2024-08-05 13:43:13 Step 137/1512: training loss=0.19
2024-08-05 13:43:08 Step 136/1512: training loss=0.08
2024-08-05 13:43:05 Step 135/1512: training loss=0.06
2024-08-05 13:43:05 Step 134/1512: training loss=0.02
2024-08-05 13:43:01 Step 133/1512: training loss=0.22
2024-08-05 13:43:00 Step 132/1512: training loss=0.05
2024-08-05 13:42:57 Step 131/1512: training loss=0.06
2024-08-05 13:42:56 Step 130/1512: training loss=0.06
2024-08-05 13:42:52 Step 129/1512: training loss=0.07
2024-08-05 13:42:51 Step 128/1512: training loss=0.10
2024-08-05 13:42:48 Step 127/1512: training loss=0.05
2024-08-05 13:42:48 Step 126/1512: training loss=0.13
2024-08-05 13:42:44 Step 125/1512: training loss=0.12
2024-08-05 13:42:44 Step 124/1512: training loss=0.11
2024-08-05 13:42:43 Step 123/1512: training loss=0.11
2024-08-05 13:42:38 Step 122/1512: training loss=0.08
2024-08-05 13:42:37 Step 121/1512: training loss=0.12
2024-08-05 13:42:32 Step 120/1512: training loss=0.17
2024-08-05 13:42:32 Step 119/1512: training loss=0.07
2024-08-05 13:42:29 Step 118/1512: training loss=0.09
2024-08-05 13:42:28 Step 117/1512: training loss=0.20
2024-08-05 13:42:24 Step 116/1512: training loss=0.26
2024-08-05 13:42:24 Step 115/1512: training loss=0.17
2024-08-05 13:42:21 Step 114/1512: training loss=0.13
2024-08-05 13:42:20 Step 113/1512: training loss=0.31
2024-08-05 13:42:16 Step 112/1512: training loss=0.21
2024-08-05 13:42:16 Step 111/1512: training loss=0.34
2024-08-05 13:42:12 Step 110/1512: training loss=0.07
2024-08-05 13:42:12 Step 109/1512: training loss=0.19
2024-08-05 13:42:11 Step 108/1512: training loss=0.21
2024-08-05 13:42:06 Step 107/1512: training loss=0.10
2024-08-05 13:42:06 Step 106/1512: training loss=0.39
2024-08-05 13:42:01 Step 105/1512: training loss=0.44
2024-08-05 13:41:58 Step 104/1512: training loss=0.08
2024-08-05 13:41:58 Step 103/1512: training loss=0.08
2024-08-05 13:41:54 Step 102/1512: training loss=0.05
2024-08-05 13:41:53 Step 101/1512: training loss=0.06
2024-08-05 13:41:49 Step 100/1512: training loss=0.07, validation loss=0.11
2024-08-05 13:41:49 Step 99/1512: training loss=0.15
2024-08-05 13:41:45 Step 98/1512: training loss=0.08
2024-08-05 13:41:44 Step 97/1512: training loss=0.13
2024-08-05 13:41:41 Step 96/1512: training loss=0.13
2024-08-05 13:41:41 Step 95/1512: training loss=0.16
2024-08-05 13:41:37 Step 94/1512: training loss=0.10
2024-08-05 13:41:37 Step 93/1512: training loss=0.15
2024-08-05 13:41:36 Step 92/1512: training loss=0.25
2024-08-05 13:41:31 Step 91/1512: training loss=0.18
2024-08-05 13:41:29 Step 90/1512: training loss=0.20
2024-08-05 13:41:25 Step 89/1512: training loss=0.30
2024-08-05 13:41:25 Step 88/1512: training loss=0.24
2024-08-05 13:41:22 Step 87/1512: training loss=0.13
2024-08-05 13:41:21 Step 86/1512: training loss=0.24
2024-08-05 13:41:17 Step 85/1512: training loss=0.21
2024-08-05 13:41:17 Step 84/1512: training loss=0.17
2024-08-05 13:41:14 Step 83/1512: training loss=0.16
2024-08-05 13:41:13 Step 82/1512: training loss=0.26
2024-08-05 13:41:09 Step 81/1512: training loss=0.24
2024-08-05 13:41:08 Step 80/1512: training loss=0.13
2024-08-05 13:41:05 Step 79/1512: training loss=0.24
2024-08-05 13:41:04 Step 78/1512: training loss=0.14
2024-08-05 13:40:59 Step 77/1512: training loss=0.19
2024-08-05 13:40:59 Step 76/1512: training loss=0.15
2024-08-05 13:40:55 Step 75/1512: training loss=0.24
2024-08-05 13:40:54 Step 74/1512: training loss=0.20
2024-08-05 13:40:51 Step 73/1512: training loss=0.43
2024-08-05 13:40:51 Step 72/1512: training loss=0.16
2024-08-05 13:40:51 Step 71/1512: training loss=0.20
2024-08-05 13:40:45 Step 70/1512: training loss=0.20
2024-08-05 13:40:42 Step 69/1512: training loss=0.26
2024-08-05 13:40:42 Step 68/1512: training loss=0.19
2024-08-05 13:40:38 Step 67/1512: training loss=0.20
2024-08-05 13:40:37 Step 66/1512: training loss=0.19
2024-08-05 13:40:34 Step 65/1512: training loss=0.23
2024-08-05 13:40:34 Step 64/1512: training loss=0.21
2024-08-05 13:40:30 Step 63/1512: training loss=0.20
2024-08-05 13:40:30 Step 62/1512: training loss=0.22
2024-08-05 13:40:29 Step 61/1512: training loss=0.27
2024-08-05 13:40:23 Step 60/1512: training loss=0.21
2024-08-05 13:40:22 Step 59/1512: training loss=0.25
2024-08-05 13:40:18 Step 58/1512: training loss=0.17
2024-08-05 13:40:18 Step 57/1512: training loss=0.20
2024-08-05 13:40:15 Step 56/1512: training loss=0.28
2024-08-05 13:40:14 Step 55/1512: training loss=0.19
2024-08-05 13:40:10 Step 54/1512: training loss=0.22
2024-08-05 13:40:10 Step 53/1512: training loss=0.28
2024-08-05 13:40:07 Step 52/1512: training loss=0.25
2024-08-05 13:40:06 Step 51/1512: training loss=0.25
2024-08-05 13:40:01 Step 50/1512: training loss=0.24
2024-08-05 13:40:01 Step 49/1512: training loss=0.23
2024-08-05 13:39:58 Step 48/1512: training loss=0.24
2024-08-05 13:39:58 Step 47/1512: training loss=0.27
2024-08-05 13:39:57 Step 46/1512: training loss=0.22
2024-08-05 13:39:51 Step 45/1512: training loss=0.24
2024-08-05 13:39:47 Step 44/1512: training loss=0.25
2024-08-05 13:39:47 Step 43/1512: training loss=0.20
2024-08-05 13:39:47 Step 42/1512: training loss=0.19
2024-08-05 13:39:44 Step 41/1512: training loss=0.20
2024-08-05 13:39:42 Step 40/1512: training loss=0.31
2024-08-05 13:39:38 Step 39/1512: training loss=0.17
2024-08-05 13:39:38 Step 38/1512: training loss=0.22
2024-08-05 13:39:34 Step 37/1512: training loss=0.29
2024-08-05 13:39:30 Step 36/1512: training loss=0.25
2024-08-05 13:39:30 Step 35/1512: training loss=0.25
2024-08-05 13:39:27 Step 34/1512: training loss=0.36
2024-08-05 13:39:27 Step 33/1512: training loss=0.30
2024-08-05 13:39:26 Step 32/1512: training loss=0.21
2024-08-05 13:39:20 Step 31/1512: training loss=0.32
2024-08-05 13:39:19 Step 30/1512: training loss=0.45
2024-08-05 13:39:16 Step 29/1512: training loss=0.37
2024-08-05 13:39:15 Step 28/1512: training loss=0.51
2024-08-05 13:39:11 Step 27/1512: training loss=0.53
2024-08-05 13:39:11 Step 26/1512: training loss=0.59
2024-08-05 13:39:08 Step 25/1512: training loss=0.58
2024-08-05 13:39:07 Step 24/1512: training loss=0.58
2024-08-05 13:39:03 Step 23/1512: training loss=0.57
2024-08-05 13:39:03 Step 22/1512: training loss=0.72
2024-08-05 13:39:00 Step 21/1512: training loss=0.73
2024-08-05 13:38:58 Step 20/1512: training loss=1.11
2024-08-05 13:38:54 Step 19/1512: training loss=0.99
2024-08-05 13:38:54 Step 18/1512: training loss=1.33
2024-08-05 13:38:51 Step 17/1512: training loss=1.03
2024-08-05 13:38:51 Step 16/1512: training loss=1.47
2024-08-05 13:38:50 Step 15/1512: training loss=1.75
2024-08-05 13:38:44 Step 14/1512: training loss=2.39
2024-08-05 13:38:40 Step 13/1512: training loss=2.74
2024-08-05 13:38:40 Step 12/1512: training loss=3.25
2024-08-05 13:38:40 Step 11/1512: training loss=3.19
2024-08-05 13:38:36 Step 10/1512: training loss=3.86
2024-08-05 13:38:35 Step 9/1512: training loss=3.69
2024-08-05 13:38:28 Step 8/1512: training loss=3.40
2024-08-05 13:38:28 Step 7/1512: training loss=4.17
2024-08-05 13:38:23 Step 6/1512: training loss=4.89
2024-08-05 13:38:20 Step 5/1512: training loss=4.43
2024-08-05 13:38:16 Step 4/1512: training loss=5.07
2024-08-05 13:38:15 Step 3/1512: training loss=5.43
2024-08-05 13:38:09 Step 2/1512: training loss=4.27
2024-08-05 13:38:04 Step 1/1512: training loss=4.79
2024-08-05 13:35:59 Fine-tuning job started
2024-08-05 13:35:49 Files validated, moving job to queued state
2024-08-05 13:09:41 Validating training file: file-EAdqAtQfBKDbF4wRIbGLnTQy and validation file: file-gU8ESoLWUxhsUjp4lRFS1KrW
2024-08-05 13:09:41 Created fine-tuning job: ftjob-Fe0NJAlo6T5SbyJHeU21AxbL
2024-08-04 23:18:27 The job has successfully completed
2024-08-04 23:18:22 New fine-tuned model created: ft:gpt-3.5-turbo-0125:personal:xchange:9sXHxPgp
2024-08-04 23:18:22 Checkpoint created at step 1635 with Snapshot ID: ft:gpt-3.5-turbo-0125:personal:xchange:9sXHxgu4:ckpt-step-1635
2024-08-04 23:18:22 Checkpoint created at step 1090 with Snapshot ID: ft:gpt-3.5-turbo-0125:personal:xchange:9sXHxuMw:ckpt-step-1090
2024-08-04 23:18:10 Step 1637/1637: training loss=0.00
2024-08-04 23:18:10 Step 1636/1637: training loss=0.00
2024-08-04 23:18:08 Step 1635/1637: training loss=0.00, full validation loss=0.00
2024-08-04 23:17:56 Step 1634/1637: training loss=0.00
2024-08-04 23:17:54 Step 1633/1637: training loss=0.00
2024-08-04 23:17:52 Step 1632/1637: training loss=0.00
2024-08-04 23:17:50 Step 1631/1637: training loss=0.00
2024-08-04 23:17:48 Step 1630/1637: training loss=0.00
2024-08-04 23:17:46 Step 1629/1637: training loss=0.00
2024-08-04 23:17:44 Step 1628/1637: training loss=0.00
2024-08-04 23:17:42 Step 1627/1637: training loss=0.00
2024-08-04 23:17:40 Step 1626/1637: training loss=0.00
2024-08-04 23:17:38 Step 1625/1637: training loss=0.00
2024-08-04 23:17:36 Step 1624/1637: training loss=0.00
2024-08-04 23:17:34 Step 1623/1637: training loss=0.00
2024-08-04 23:17:32 Step 1622/1637: training loss=0.00
2024-08-04 23:17:30 Step 1621/1637: training loss=0.00
2024-08-04 23:17:28 Step 1620/1637: training loss=0.00
2024-08-04 23:17:25 Step 1619/1637: training loss=0.00
2024-08-04 23:17:23 Step 1618/1637: training loss=0.00
2024-08-04 23:17:21 Step 1617/1637: training loss=0.00
2024-08-04 23:17:19 Step 1616/1637: training loss=0.00
2024-08-04 23:17:17 Step 1615/1637: training loss=0.00
2024-08-04 23:17:15 Step 1614/1637: training loss=0.00
2024-08-04 23:17:13 Step 1613/1637: training loss=0.00
2024-08-04 23:17:11 Step 1612/1637: training loss=0.00
2024-08-04 23:17:09 Step 1611/1637: training loss=0.00
2024-08-04 23:17:07 Step 1610/1637: training loss=0.00
2024-08-04 23:17:05 Step 1609/1637: training loss=0.00
2024-08-04 23:17:03 Step 1608/1637: training loss=0.00
2024-08-04 23:17:01 Step 1607/1637: training loss=0.00
2024-08-04 23:16:59 Step 1606/1637: training loss=0.00
2024-08-04 23:16:57 Step 1605/1637: training loss=0.00
2024-08-04 23:16:55 Step 1604/1637: training loss=0.00
2024-08-04 23:16:53 Step 1603/1637: training loss=0.00
2024-08-04 23:16:51 Step 1602/1637: training loss=0.00
2024-08-04 23:16:49 Step 1601/1637: training loss=0.00
2024-08-04 23:16:47 Step 1600/1637: training loss=0.00, validation loss=0.00
2024-08-04 23:16:45 Step 1599/1637: training loss=0.00
2024-08-04 23:16:43 Step 1598/1637: training loss=0.00
2024-08-04 23:16:41 Step 1597/1637: training loss=0.00
2024-08-04 23:16:39 Step 1596/1637: training loss=0.00
2024-08-04 23:16:37 Step 1595/1637: training loss=0.00
2024-08-04 23:16:35 Step 1594/1637: training loss=0.00
2024-08-04 23:16:33 Step 1593/1637: training loss=0.00
2024-08-04 23:16:31 Step 1592/1637: training loss=0.00
2024-08-04 23:16:29 Step 1591/1637: training loss=0.00
2024-08-04 23:16:27 Step 1590/1637: training loss=0.00
2024-08-04 23:16:25 Step 1589/1637: training loss=0.00
2024-08-04 23:16:23 Step 1588/1637: training loss=0.00
2024-08-04 23:16:21 Step 1587/1637: training loss=0.00
2024-08-04 23:16:19 Step 1586/1637: training loss=0.00
2024-08-04 23:16:17 Step 1585/1637: training loss=0.00
2024-08-04 23:16:15 Step 1584/1637: training loss=0.00
2024-08-04 23:16:13 Step 1583/1637: training loss=0.00
2024-08-04 23:16:11 Step 1582/1637: training loss=0.00
2024-08-04 23:16:09 Step 1581/1637: training loss=0.00
2024-08-04 23:16:07 Step 1580/1637: training loss=0.00
2024-08-04 23:16:05 Step 1579/1637: training loss=0.00
2024-08-04 23:16:03 Step 1578/1637: training loss=0.00
2024-08-04 23:16:01 Step 1577/1637: training loss=0.00
2024-08-04 23:15:59 Step 1576/1637: training loss=0.00
2024-08-04 23:15:57 Step 1575/1637: training loss=0.00
2024-08-04 23:15:55 Step 1574/1637: training loss=0.00
2024-08-04 23:15:53 Step 1573/1637: training loss=0.00
2024-08-04 23:15:51 Step 1572/1637: training loss=0.00
2024-08-04 23:15:49 Step 1571/1637: training loss=0.00
2024-08-04 23:15:47 Step 1570/1637: training loss=0.00
2024-08-04 23:15:45 Step 1569/1637: training loss=0.00
2024-08-04 23:15:43 Step 1568/1637: training loss=0.00
2024-08-04 23:15:40 Step 1567/1637: training loss=0.00
2024-08-04 23:15:38 Step 1566/1637: training loss=0.00
2024-08-04 23:15:36 Step 1565/1637: training loss=0.00
2024-08-04 23:15:34 Step 1564/1637: training loss=0.00
2024-08-04 23:15:32 Step 1563/1637: training loss=0.00
2024-08-04 23:15:30 Step 1562/1637: training loss=0.00
2024-08-04 23:15:28 Step 1561/1637: training loss=0.00
2024-08-04 23:15:26 Step 1560/1637: training loss=0.00
2024-08-04 23:15:24 Step 1559/1637: training loss=0.00
2024-08-04 23:15:22 Step 1558/1637: training loss=0.00
2024-08-04 23:15:20 Step 1557/1637: training loss=0.00
2024-08-04 23:15:18 Step 1556/1637: training loss=0.00
2024-08-04 23:15:16 Step 1555/1637: training loss=0.00
2024-08-04 23:15:14 Step 1554/1637: training loss=0.00
2024-08-04 23:15:12 Step 1553/1637: training loss=0.00
2024-08-04 23:15:10 Step 1552/1637: training loss=0.00
2024-08-04 23:15:08 Step 1551/1637: training loss=0.00
2024-08-04 23:15:06 Step 1550/1637: training loss=0.00
2024-08-04 23:15:04 Step 1549/1637: training loss=0.00
2024-08-04 23:15:02 Step 1548/1637: training loss=0.00
2024-08-04 23:15:00 Step 1547/1637: training loss=0.00
2024-08-04 23:14:58 Step 1546/1637: training loss=0.00
2024-08-04 23:14:56 Step 1545/1637: training loss=0.00
2024-08-04 23:14:54 Step 1544/1637: training loss=0.00
2024-08-04 23:14:52 Step 1543/1637: training loss=0.00
2024-08-04 23:14:50 Step 1542/1637: training loss=0.00
2024-08-04 23:14:48 Step 1541/1637: training loss=0.00
2024-08-04 23:14:46 Step 1540/1637: training loss=0.00
2024-08-04 23:14:44 Step 1539/1637: training loss=0.00
2024-08-04 23:14:42 Step 1538/1637: training loss=0.00
2024-08-04 23:14:40 Step 1537/1637: training loss=0.00
2024-08-04 23:14:38 Step 1536/1637: training loss=0.00
2024-08-04 23:14:36 Step 1535/1637: training loss=0.00
2024-08-04 23:14:34 Step 1534/1637: training loss=0.00
2024-08-04 23:14:32 Step 1533/1637: training loss=0.00
2024-08-04 23:14:30 Step 1532/1637: training loss=0.00
2024-08-04 23:14:28 Step 1531/1637: training loss=0.00
2024-08-04 23:14:26 Step 1530/1637: training loss=0.00
2024-08-04 23:14:24 Step 1529/1637: training loss=0.00
2024-08-04 23:14:22 Step 1528/1637: training loss=0.00
2024-08-04 23:14:20 Step 1527/1637: training loss=0.00
2024-08-04 23:14:18 Step 1526/1637: training loss=0.00
2024-08-04 23:14:16 Step 1525/1637: training loss=0.00
2024-08-04 23:14:14 Step 1524/1637: training loss=0.00
2024-08-04 23:14:12 Step 1523/1637: training loss=0.00
2024-08-04 23:14:10 Step 1522/1637: training loss=0.00
2024-08-04 23:14:08 Step 1521/1637: training loss=0.00
2024-08-04 23:14:06 Step 1520/1637: training loss=0.00
2024-08-04 23:14:04 Step 1519/1637: training loss=0.00
2024-08-04 23:14:02 Step 1518/1637: training loss=0.00
2024-08-04 23:14:00 Step 1517/1637: training loss=0.00
2024-08-04 23:13:57 Step 1516/1637: training loss=0.00
2024-08-04 23:13:55 Step 1515/1637: training loss=0.00
2024-08-04 23:13:53 Step 1514/1637: training loss=0.00
2024-08-04 23:13:51 Step 1513/1637: training loss=0.00
2024-08-04 23:13:51 Step 1512/1637: training loss=0.00
2024-08-04 23:13:49 Step 1511/1637: training loss=0.00
2024-08-04 23:13:47 Step 1510/1637: training loss=0.00
2024-08-04 23:13:45 Step 1509/1637: training loss=0.00
2024-08-04 23:13:43 Step 1508/1637: training loss=0.00
2024-08-04 23:13:41 Step 1507/1637: training loss=0.00
2024-08-04 23:13:39 Step 1506/1637: training loss=0.00
2024-08-04 23:13:37 Step 1505/1637: training loss=0.00
2024-08-04 23:13:35 Step 1504/1637: training loss=0.00
2024-08-04 23:13:33 Step 1503/1637: training loss=0.00
2024-08-04 23:13:31 Step 1502/1637: training loss=0.00
2024-08-04 23:13:29 Step 1501/1637: training loss=0.00
2024-08-04 23:13:27 Step 1500/1637: training loss=0.00, validation loss=0.00
2024-08-04 23:13:25 Step 1499/1637: training loss=0.00
2024-08-04 23:13:23 Step 1498/1637: training loss=0.00
2024-08-04 23:13:21 Step 1497/1637: training loss=0.00
2024-08-04 23:13:19 Step 1496/1637: training loss=0.00
2024-08-04 23:13:17 Step 1495/1637: training loss=0.00
2024-08-04 23:13:15 Step 1494/1637: training loss=0.00
2024-08-04 23:13:13 Step 1493/1637: training loss=0.00
2024-08-04 23:13:11 Step 1492/1637: training loss=0.00
2024-08-04 23:13:09 Step 1491/1637: training loss=0.00
2024-08-04 23:13:07 Step 1490/1637: training loss=0.00
2024-08-04 23:13:05 Step 1489/1637: training loss=0.00
2024-08-04 23:13:03 Step 1488/1637: training loss=0.00
2024-08-04 23:13:01 Step 1487/1637: training loss=0.00
2024-08-04 23:12:59 Step 1486/1637: training loss=0.00
2024-08-04 23:12:57 Step 1485/1637: training loss=0.00
2024-08-04 23:12:55 Step 1484/1637: training loss=0.00
2024-08-04 23:12:53 Step 1483/1637: training loss=0.00
2024-08-04 23:12:51 Step 1482/1637: training loss=0.00
2024-08-04 23:12:49 Step 1481/1637: training loss=0.00
2024-08-04 23:12:47 Step 1480/1637: training loss=0.00
2024-08-04 23:12:45 Step 1479/1637: training loss=0.00
2024-08-04 23:12:43 Step 1478/1637: training loss=0.00
2024-08-04 23:12:41 Step 1477/1637: training loss=0.00
2024-08-04 23:12:39 Step 1476/1637: training loss=0.00
2024-08-04 23:12:37 Step 1475/1637: training loss=0.00
2024-08-04 23:12:33 Step 1474/1637: training loss=0.00
2024-08-04 23:12:31 Step 1473/1637: training loss=0.00
2024-08-04 23:12:29 Step 1472/1637: training loss=0.00
2024-08-04 23:12:27 Step 1471/1637: training loss=0.00
2024-08-04 23:12:25 Step 1470/1637: training loss=0.00
2024-08-04 23:12:23 Step 1469/1637: training loss=0.00
2024-08-04 23:12:21 Step 1468/1637: training loss=0.00
2024-08-04 23:12:19 Step 1467/1637: training loss=0.00
2024-08-04 23:12:17 Step 1466/1637: training loss=0.00
2024-08-04 23:12:14 Step 1465/1637: training loss=0.00
2024-08-04 23:12:12 Step 1464/1637: training loss=0.00
2024-08-04 23:12:12 Step 1463/1637: training loss=0.00
2024-08-04 23:12:10 Step 1462/1637: training loss=0.00
2024-08-04 23:12:08 Step 1461/1637: training loss=0.00
2024-08-04 23:12:06 Step 1460/1637: training loss=0.00
2024-08-04 23:12:04 Step 1459/1637: training loss=0.00
2024-08-04 23:12:02 Step 1458/1637: training loss=0.00
2024-08-04 23:12:00 Step 1457/1637: training loss=0.00
2024-08-04 23:11:58 Step 1456/1637: training loss=0.00
2024-08-04 23:11:56 Step 1455/1637: training loss=0.00
2024-08-04 23:11:54 Step 1454/1637: training loss=0.00
2024-08-04 23:11:52 Step 1453/1637: training loss=0.00
2024-08-04 23:11:50 Step 1452/1637: training loss=0.00
2024-08-04 23:11:48 Step 1451/1637: training loss=0.00
2024-08-04 23:11:46 Step 1450/1637: training loss=0.00
2024-08-04 23:11:44 Step 1449/1637: training loss=0.00
2024-08-04 23:11:42 Step 1448/1637: training loss=0.00
2024-08-04 23:11:38 Step 1447/1637: training loss=0.00
2024-08-04 23:11:36 Step 1446/1637: training loss=0.00
2024-08-04 23:11:36 Step 1445/1637: training loss=0.00
2024-08-04 23:11:34 Step 1444/1637: training loss=0.00
2024-08-04 23:11:32 Step 1443/1637: training loss=0.00
2024-08-04 23:11:30 Step 1442/1637: training loss=0.00
2024-08-04 23:11:28 Step 1441/1637: training loss=0.00
2024-08-04 23:11:26 Step 1440/1637: training loss=0.00
2024-08-04 23:11:24 Step 1439/1637: training loss=0.00
2024-08-04 23:11:22 Step 1438/1637: training loss=0.00
2024-08-04 23:11:20 Step 1437/1637: training loss=0.00
2024-08-04 23:11:18 Step 1436/1637: training loss=0.00
2024-08-04 23:11:16 Step 1435/1637: training loss=0.00
2024-08-04 23:11:14 Step 1434/1637: training loss=0.00
2024-08-04 23:11:12 Step 1433/1637: training loss=0.00
2024-08-04 23:11:10 Step 1432/1637: training loss=0.00
2024-08-04 23:11:08 Step 1431/1637: training loss=0.00
2024-08-04 23:11:06 Step 1430/1637: training loss=0.00
2024-08-04 23:11:04 Step 1429/1637: training loss=0.00
2024-08-04 23:11:02 Step 1428/1637: training loss=0.00
2024-08-04 23:11:00 Step 1427/1637: training loss=0.00
2024-08-04 23:10:56 Step 1426/1637: training loss=0.00
2024-08-04 23:10:56 Step 1425/1637: training loss=0.00
2024-08-04 23:10:54 Step 1424/1637: training loss=0.00
2024-08-04 23:10:52 Step 1423/1637: training loss=0.00
2024-08-04 23:10:50 Step 1422/1637: training loss=0.00
2024-08-04 23:10:48 Step 1421/1637: training loss=0.00
2024-08-04 23:10:46 Step 1420/1637: training loss=0.00
2024-08-04 23:10:44 Step 1419/1637: training loss=0.00
2024-08-04 23:10:42 Step 1418/1637: training loss=0.00
2024-08-04 23:10:40 Step 1417/1637: training loss=0.00
2024-08-04 23:10:38 Step 1416/1637: training loss=0.00
2024-08-04 23:10:36 Step 1415/1637: training loss=0.00
2024-08-04 23:10:33 Step 1414/1637: training loss=0.00
2024-08-04 23:10:31 Step 1413/1637: training loss=0.00
2024-08-04 23:10:29 Step 1412/1637: training loss=0.00
2024-08-04 23:10:27 Step 1411/1637: training loss=0.00
2024-08-04 23:10:25 Step 1410/1637: training loss=0.00
2024-08-04 23:10:23 Step 1409/1637: training loss=0.00
2024-08-04 23:10:21 Step 1408/1637: training loss=0.00
2024-08-04 23:10:19 Step 1407/1637: training loss=0.00
2024-08-04 23:10:17 Step 1406/1637: training loss=0.00
2024-08-04 23:10:15 Step 1405/1637: training loss=0.00
2024-08-04 23:10:13 Step 1404/1637: training loss=0.00
2024-08-04 23:10:11 Step 1403/1637: training loss=0.00
2024-08-04 23:10:09 Step 1402/1637: training loss=0.00
2024-08-04 23:10:07 Step 1401/1637: training loss=0.00
2024-08-04 23:10:05 Step 1400/1637: training loss=0.00, validation loss=0.00
2024-08-04 23:10:03 Step 1399/1637: training loss=0.00
2024-08-04 23:10:01 Step 1398/1637: training loss=0.00
2024-08-04 23:09:59 Step 1397/1637: training loss=0.00
2024-08-04 23:09:57 Step 1396/1637: training loss=0.00
2024-08-04 23:09:55 Step 1395/1637: training loss=0.00
2024-08-04 23:09:53 Step 1394/1637: training loss=0.00
2024-08-04 23:09:51 Step 1393/1637: training loss=0.00
2024-08-04 23:09:47 Step 1392/1637: training loss=0.00
2024-08-04 23:09:45 Step 1391/1637: training loss=0.00
2024-08-04 23:09:43 Step 1390/1637: training loss=0.00
2024-08-04 23:09:41 Step 1389/1637: training loss=0.00
2024-08-04 23:09:39 Step 1388/1637: training loss=0.00
2024-08-04 23:09:37 Step 1387/1637: training loss=0.00
2024-08-04 23:09:35 Step 1386/1637: training loss=0.00
2024-08-04 23:09:33 Step 1385/1637: training loss=0.00
2024-08-04 23:09:31 Step 1384/1637: training loss=0.00
2024-08-04 23:09:29 Step 1383/1637: training loss=0.00
2024-08-04 23:09:27 Step 1382/1637: training loss=0.00
2024-08-04 23:09:25 Step 1381/1637: training loss=0.00
2024-08-04 23:09:23 Step 1380/1637: training loss=0.00
2024-08-04 23:09:21 Step 1379/1637: training loss=0.00
2024-08-04 23:09:19 Step 1378/1637: training loss=0.00
2024-08-04 23:09:17 Step 1377/1637: training loss=0.00
2024-08-04 23:09:15 Step 1376/1637: training loss=0.00
2024-08-04 23:09:13 Step 1375/1637: training loss=0.00
2024-08-04 23:09:11 Step 1374/1637: training loss=0.00
2024-08-04 23:09:09 Step 1373/1637: training loss=0.00
2024-08-04 23:09:07 Step 1372/1637: training loss=0.00
2024-08-04 23:09:05 Step 1371/1637: training loss=0.00
2024-08-04 23:09:03 Step 1370/1637: training loss=0.00
2024-08-04 23:09:01 Step 1369/1637: training loss=0.00
2024-08-04 23:08:59 Step 1368/1637: training loss=0.00
2024-08-04 23:08:57 Step 1367/1637: training loss=0.00
2024-08-04 23:08:55 Step 1366/1637: training loss=0.00
2024-08-04 23:08:53 Step 1365/1637: training loss=0.00
2024-08-04 23:08:50 Step 1364/1637: training loss=0.00
2024-08-04 23:08:48 Step 1363/1637: training loss=0.00
2024-08-04 23:08:46 Step 1362/1637: training loss=0.00
2024-08-04 23:08:44 Step 1361/1637: training loss=0.00
2024-08-04 23:08:42 Step 1360/1637: training loss=0.00
2024-08-04 23:08:40 Step 1359/1637: training loss=0.00
2024-08-04 23:08:38 Step 1358/1637: training loss=0.00
2024-08-04 23:08:36 Step 1357/1637: training loss=0.00
2024-08-04 23:08:34 Step 1356/1637: training loss=0.00
2024-08-04 23:08:32 Step 1355/1637: training loss=0.00
2024-08-04 23:08:30 Step 1354/1637: training loss=0.00
2024-08-04 23:08:28 Step 1353/1637: training loss=0.00
2024-08-04 23:08:26 Step 1352/1637: training loss=0.00
2024-08-04 23:08:24 Step 1351/1637: training loss=0.00
2024-08-04 23:08:22 Step 1350/1637: training loss=0.00
2024-08-04 23:08:20 Step 1349/1637: training loss=0.00
2024-08-04 23:08:18 Step 1348/1637: training loss=0.00
2024-08-04 23:08:16 Step 1347/1637: training loss=0.00
2024-08-04 23:08:14 Step 1346/1637: training loss=0.00
2024-08-04 23:08:12 Step 1345/1637: training loss=0.00
2024-08-04 23:08:10 Step 1344/1637: training loss=0.00
2024-08-04 23:08:08 Step 1343/1637: training loss=0.00
2024-08-04 23:08:06 Step 1342/1637: training loss=0.00
2024-08-04 23:08:04 Step 1341/1637: training loss=0.00
2024-08-04 23:08:02 Step 1340/1637: training loss=0.00
2024-08-04 23:08:00 Step 1339/1637: training loss=0.00
2024-08-04 23:07:58 Step 1338/1637: training loss=0.00
2024-08-04 23:07:56 Step 1337/1637: training loss=0.00
2024-08-04 23:07:54 Step 1336/1637: training loss=0.00
2024-08-04 23:07:52 Step 1335/1637: training loss=0.00
2024-08-04 23:07:50 Step 1334/1637: training loss=0.00
2024-08-04 23:07:48 Step 1333/1637: training loss=0.00
2024-08-04 23:07:46 Step 1332/1637: training loss=0.00
2024-08-04 23:07:44 Step 1331/1637: training loss=0.00
2024-08-04 23:07:44 Step 1330/1637: training loss=0.00
2024-08-04 23:07:42 Step 1329/1637: training loss=0.00
2024-08-04 23:07:40 Step 1328/1637: training loss=0.00
2024-08-04 23:07:38 Step 1327/1637: training loss=0.00
2024-08-04 23:07:36 Step 1326/1637: training loss=0.00
2024-08-04 23:07:34 Step 1325/1637: training loss=0.00
2024-08-04 23:07:20 Step 1324/1637: training loss=0.00
2024-08-04 23:07:18 Step 1323/1637: training loss=0.00
2024-08-04 23:07:15 Step 1322/1637: training loss=0.00
2024-08-04 23:07:13 Step 1321/1637: training loss=0.00
2024-08-04 23:07:11 Step 1320/1637: training loss=0.00
2024-08-04 23:07:09 Step 1319/1637: training loss=0.00
2024-08-04 23:07:07 Step 1318/1637: training loss=0.00
2024-08-04 23:07:05 Step 1317/1637: training loss=0.00
2024-08-04 23:07:03 Step 1316/1637: training loss=0.00
2024-08-04 23:07:01 Step 1315/1637: training loss=0.00
2024-08-04 23:06:59 Step 1314/1637: training loss=0.00
2024-08-04 23:06:57 Step 1313/1637: training loss=0.00
2024-08-04 23:06:55 Step 1312/1637: training loss=0.00
2024-08-04 23:06:53 Step 1311/1637: training loss=0.00
2024-08-04 23:06:51 Step 1310/1637: training loss=0.00
2024-08-04 23:06:49 Step 1309/1637: training loss=0.00
2024-08-04 23:06:47 Step 1308/1637: training loss=0.00
2024-08-04 23:06:45 Step 1307/1637: training loss=0.00
2024-08-04 23:06:43 Step 1306/1637: training loss=0.00
2024-08-04 23:06:41 Step 1305/1637: training loss=0.00
2024-08-04 23:06:39 Step 1304/1637: training loss=0.00
2024-08-04 23:06:37 Step 1303/1637: training loss=0.00
2024-08-04 23:06:35 Step 1302/1637: training loss=0.00
2024-08-04 23:06:33 Step 1301/1637: training loss=0.00
2024-08-04 23:06:31 Step 1300/1637: training loss=0.00, validation loss=0.00
2024-08-04 23:06:29 Step 1299/1637: training loss=0.00
2024-08-04 23:06:27 Step 1298/1637: training loss=0.00
2024-08-04 23:06:25 Step 1297/1637: training loss=0.00
2024-08-04 23:06:23 Step 1296/1637: training loss=0.00
2024-08-04 23:06:21 Step 1295/1637: training loss=0.00
2024-08-04 23:06:19 Step 1294/1637: training loss=0.00
2024-08-04 23:06:17 Step 1293/1637: training loss=0.00
2024-08-04 23:06:15 Step 1292/1637: training loss=0.00
2024-08-04 23:06:13 Step 1291/1637: training loss=0.00
2024-08-04 23:06:11 Step 1290/1637: training loss=0.00
2024-08-04 23:06:09 Step 1289/1637: training loss=0.00
2024-08-04 23:06:07 Step 1288/1637: training loss=0.00
2024-08-04 23:06:05 Step 1287/1637: training loss=0.00
2024-08-04 23:06:03 Step 1286/1637: training loss=0.00
2024-08-04 23:06:01 Step 1285/1637: training loss=0.00
2024-08-04 23:05:59 Step 1284/1637: training loss=0.00
2024-08-04 23:05:57 Step 1283/1637: training loss=0.00
2024-08-04 23:05:55 Step 1282/1637: training loss=0.00
2024-08-04 23:05:53 Step 1281/1637: training loss=0.00
2024-08-04 23:05:51 Step 1280/1637: training loss=0.00
2024-08-04 23:05:49 Step 1279/1637: training loss=0.00
2024-08-04 23:05:47 Step 1278/1637: training loss=0.00
2024-08-04 23:05:44 Step 1277/1637: training loss=0.00
2024-08-04 23:05:42 Step 1276/1637: training loss=0.00
2024-08-04 23:05:40 Step 1275/1637: training loss=0.00
2024-08-04 23:05:38 Step 1274/1637: training loss=0.00
2024-08-04 23:05:36 Step 1273/1637: training loss=0.00
2024-08-04 23:05:34 Step 1272/1637: training loss=0.00
2024-08-04 23:05:32 Step 1271/1637: training loss=0.00
2024-08-04 23:05:30 Step 1270/1637: training loss=0.00
2024-08-04 23:05:28 Step 1269/1637: training loss=0.00
2024-08-04 23:05:26 Step 1268/1637: training loss=0.00
2024-08-04 23:05:24 Step 1267/1637: training loss=0.00
2024-08-04 23:05:22 Step 1266/1637: training loss=0.00
2024-08-04 23:05:20 Step 1265/1637: training loss=0.00
2024-08-04 23:05:18 Step 1264/1637: training loss=0.00
2024-08-04 23:05:16 Step 1263/1637: training loss=0.00
2024-08-04 23:05:14 Step 1262/1637: training loss=0.00
2024-08-04 23:05:12 Step 1261/1637: training loss=0.00
2024-08-04 23:05:10 Step 1260/1637: training loss=0.00
2024-08-04 23:05:08 Step 1259/1637: training loss=0.00
2024-08-04 23:05:06 Step 1258/1637: training loss=0.00
2024-08-04 23:05:04 Step 1257/1637: training loss=0.00
2024-08-04 23:05:02 Step 1256/1637: training loss=0.00
2024-08-04 23:05:00 Step 1255/1637: training loss=0.00
2024-08-04 23:04:56 Step 1254/1637: training loss=0.00
2024-08-04 23:04:54 Step 1253/1637: training loss=0.00
2024-08-04 23:04:52 Step 1252/1637: training loss=0.00
2024-08-04 23:04:50 Step 1251/1637: training loss=0.00
2024-08-04 23:04:48 Step 1250/1637: training loss=0.00
2024-08-04 23:04:46 Step 1249/1637: training loss=0.00
2024-08-04 23:04:44 Step 1248/1637: training loss=0.00
2024-08-04 23:04:42 Step 1247/1637: training loss=0.00
2024-08-04 23:04:42 Step 1246/1637: training loss=0.00
2024-08-04 23:04:40 Step 1245/1637: training loss=0.00
2024-08-04 23:04:38 Step 1244/1637: training loss=0.00
2024-08-04 23:04:36 Step 1243/1637: training loss=0.00
2024-08-04 23:04:34 Step 1242/1637: training loss=0.00
2024-08-04 23:04:32 Step 1241/1637: training loss=0.00
2024-08-04 23:04:30 Step 1240/1637: training loss=0.00
2024-08-04 23:04:28 Step 1239/1637: training loss=0.00
2024-08-04 23:04:26 Step 1238/1637: training loss=0.00
2024-08-04 23:04:24 Step 1237/1637: training loss=0.00
2024-08-04 23:04:22 Step 1236/1637: training loss=0.00
2024-08-04 23:04:20 Step 1235/1637: training loss=0.00
2024-08-04 23:04:18 Step 1234/1637: training loss=0.00
2024-08-04 23:04:16 Step 1233/1637: training loss=0.00
2024-08-04 23:04:14 Step 1232/1637: training loss=0.00
2024-08-04 23:04:10 Step 1231/1637: training loss=0.00
2024-08-04 23:04:10 Step 1230/1637: training loss=0.00
2024-08-04 23:04:06 Step 1229/1637: training loss=0.00
2024-08-04 23:04:06 Step 1228/1637: training loss=0.00
2024-08-04 23:04:04 Step 1227/1637: training loss=0.00
2024-08-04 23:04:02 Step 1226/1637: training loss=0.00
2024-08-04 23:04:00 Step 1225/1637: training loss=0.00
2024-08-04 23:03:57 Step 1224/1637: training loss=0.00
2024-08-04 23:03:55 Step 1223/1637: training loss=0.00
2024-08-04 23:03:53 Step 1222/1637: training loss=0.00
2024-08-04 23:03:51 Step 1221/1637: training loss=0.00
2024-08-04 23:03:49 Step 1220/1637: training loss=0.00
2024-08-04 23:03:47 Step 1219/1637: training loss=0.00
2024-08-04 23:03:45 Step 1218/1637: training loss=0.00
2024-08-04 23:03:41 Step 1217/1637: training loss=0.00
2024-08-04 23:03:39 Step 1216/1637: training loss=0.00
2024-08-04 23:03:37 Step 1215/1637: training loss=0.00
2024-08-04 23:03:37 Step 1214/1637: training loss=0.00
2024-08-04 23:03:35 Step 1213/1637: training loss=0.00
2024-08-04 23:03:33 Step 1212/1637: training loss=0.00
2024-08-04 23:03:31 Step 1211/1637: training loss=0.00
2024-08-04 23:03:29 Step 1210/1637: training loss=0.00
2024-08-04 23:03:27 Step 1209/1637: training loss=0.00
2024-08-04 23:03:25 Step 1208/1637: training loss=0.00
2024-08-04 23:03:23 Step 1207/1637: training loss=0.00
2024-08-04 23:03:21 Step 1206/1637: training loss=0.00
2024-08-04 23:03:19 Step 1205/1637: training loss=0.00
2024-08-04 23:03:17 Step 1204/1637: training loss=0.00
2024-08-04 23:03:15 Step 1203/1637: training loss=0.00
2024-08-04 23:03:13 Step 1202/1637: training loss=0.00
2024-08-04 23:03:11 Step 1201/1637: training loss=0.00
2024-08-04 23:03:09 Step 1200/1637: training loss=0.00, validation loss=0.00
2024-08-04 23:03:07 Step 1199/1637: training loss=0.00
2024-08-04 23:03:05 Step 1198/1637: training loss=0.00
2024-08-04 23:03:03 Step 1197/1637: training loss=0.00
2024-08-04 23:03:01 Step 1196/1637: training loss=0.00
2024-08-04 23:02:59 Step 1195/1637: training loss=0.00
2024-08-04 23:02:57 Step 1194/1637: training loss=0.00
2024-08-04 23:02:55 Step 1193/1637: training loss=0.00
2024-08-04 23:02:53 Step 1192/1637: training loss=0.00
2024-08-04 23:02:51 Step 1191/1637: training loss=0.00
2024-08-04 23:02:49 Step 1190/1637: training loss=0.00
2024-08-04 23:02:47 Step 1189/1637: training loss=0.00
2024-08-04 23:02:45 Step 1188/1637: training loss=0.00
2024-08-04 23:02:43 Step 1187/1637: training loss=0.00
2024-08-04 23:02:41 Step 1186/1637: training loss=0.00
2024-08-04 23:02:39 Step 1185/1637: training loss=0.00
2024-08-04 23:02:37 Step 1184/1637: training loss=0.00
2024-08-04 23:02:35 Step 1183/1637: training loss=0.00
2024-08-04 23:02:33 Step 1182/1637: training loss=0.00
2024-08-04 23:02:31 Step 1181/1637: training loss=0.00
2024-08-04 23:02:29 Step 1180/1637: training loss=0.00
2024-08-04 23:02:27 Step 1179/1637: training loss=0.00
2024-08-04 23:02:25 Step 1178/1637: training loss=0.00
2024-08-04 23:02:23 Step 1177/1637: training loss=0.00
2024-08-04 23:02:21 Step 1176/1637: training loss=0.00
2024-08-04 23:02:18 Step 1175/1637: training loss=0.00
2024-08-04 23:02:16 Step 1174/1637: training loss=0.00
2024-08-04 23:02:14 Step 1173/1637: training loss=0.00
2024-08-04 23:02:12 Step 1172/1637: training loss=0.00
2024-08-04 23:02:10 Step 1171/1637: training loss=0.00
2024-08-04 23:02:08 Step 1170/1637: training loss=0.00
2024-08-04 23:02:06 Step 1169/1637: training loss=0.00
2024-08-04 23:02:04 Step 1168/1637: training loss=0.00
2024-08-04 23:02:02 Step 1167/1637: training loss=0.00
2024-08-04 23:02:00 Step 1166/1637: training loss=0.00
2024-08-04 23:01:58 Step 1165/1637: training loss=0.00
2024-08-04 23:01:56 Step 1164/1637: training loss=0.00
2024-08-04 23:01:54 Step 1163/1637: training loss=0.00
2024-08-04 23:01:52 Step 1162/1637: training loss=0.00
2024-08-04 23:01:50 Step 1161/1637: training loss=0.00
2024-08-04 23:01:48 Step 1160/1637: training loss=0.00
2024-08-04 23:01:46 Step 1159/1637: training loss=0.00
2024-08-04 23:01:44 Step 1158/1637: training loss=0.00
2024-08-04 23:01:42 Step 1157/1637: training loss=0.00
2024-08-04 23:01:40 Step 1156/1637: training loss=0.00
2024-08-04 23:01:38 Step 1155/1637: training loss=0.00
2024-08-04 23:01:36 Step 1154/1637: training loss=0.00
2024-08-04 23:01:34 Step 1153/1637: training loss=0.00
2024-08-04 23:01:32 Step 1152/1637: training loss=0.00
2024-08-04 23:01:30 Step 1151/1637: training loss=0.00
2024-08-04 23:01:28 Step 1150/1637: training loss=0.00
2024-08-04 23:01:26 Step 1149/1637: training loss=0.00
2024-08-04 23:01:24 Step 1148/1637: training loss=0.00
2024-08-04 23:01:22 Step 1147/1637: training loss=0.00
2024-08-04 23:01:20 Step 1146/1637: training loss=0.00
2024-08-04 23:01:18 Step 1145/1637: training loss=0.00
2024-08-04 23:01:16 Step 1144/1637: training loss=0.00
2024-08-04 23:01:14 Step 1143/1637: training loss=0.00
2024-08-04 23:01:12 Step 1142/1637: training loss=0.00
2024-08-04 23:01:10 Step 1141/1637: training loss=0.00
2024-08-04 23:01:10 Step 1140/1637: training loss=0.00
2024-08-04 23:01:06 Step 1139/1637: training loss=0.00
2024-08-04 23:01:06 Step 1138/1637: training loss=0.00
2024-08-04 23:01:04 Step 1137/1637: training loss=0.00
2024-08-04 23:01:02 Step 1136/1637: training loss=0.00
2024-08-04 23:01:00 Step 1135/1637: training loss=0.00
2024-08-04 23:00:56 Step 1134/1637: training loss=0.00
2024-08-04 23:00:54 Step 1133/1637: training loss=0.00
2024-08-04 23:00:52 Step 1132/1637: training loss=0.00
2024-08-04 23:00:50 Step 1131/1637: training loss=0.00
2024-08-04 23:00:50 Step 1130/1637: training loss=0.00
2024-08-04 23:00:48 Step 1129/1637: training loss=0.00
2024-08-04 23:00:46 Step 1128/1637: training loss=0.00
2024-08-04 23:00:44 Step 1127/1637: training loss=0.00
2024-08-04 23:00:40 Step 1126/1637: training loss=0.00
2024-08-04 23:00:40 Step 1125/1637: training loss=0.00
2024-08-04 23:00:37 Step 1124/1637: training loss=0.00
2024-08-04 23:00:35 Step 1123/1637: training loss=0.00
2024-08-04 23:00:33 Step 1122/1637: training loss=0.00
2024-08-04 23:00:31 Step 1121/1637: training loss=0.00
2024-08-04 23:00:29 Step 1120/1637: training loss=0.00
2024-08-04 23:00:27 Step 1119/1637: training loss=0.00
2024-08-04 23:00:25 Step 1118/1637: training loss=0.00
2024-08-04 23:00:23 Step 1117/1637: training loss=0.00
2024-08-04 23:00:21 Step 1116/1637: training loss=0.00
2024-08-04 23:00:19 Step 1115/1637: training loss=0.00
2024-08-04 23:00:17 Step 1114/1637: training loss=0.00
2024-08-04 23:00:15 Step 1113/1637: training loss=0.00
2024-08-04 23:00:13 Step 1112/1637: training loss=0.00
2024-08-04 23:00:11 Step 1111/1637: training loss=0.00
2024-08-04 23:00:09 Step 1110/1637: training loss=0.00
2024-08-04 23:00:07 Step 1109/1637: training loss=0.00
2024-08-04 23:00:05 Step 1108/1637: training loss=0.00
2024-08-04 23:00:03 Step 1107/1637: training loss=0.00
2024-08-04 23:00:01 Step 1106/1637: training loss=0.00
2024-08-04 22:59:59 Step 1105/1637: training loss=0.00
2024-08-04 22:59:57 Step 1104/1637: training loss=0.00
2024-08-04 22:59:55 Step 1103/1637: training loss=0.00
2024-08-04 22:59:53 Step 1102/1637: training loss=0.00
2024-08-04 22:59:51 Step 1101/1637: training loss=0.00
2024-08-04 22:59:49 Step 1100/1637: training loss=0.00, validation loss=0.00
2024-08-04 22:59:47 Step 1099/1637: training loss=0.00
2024-08-04 22:59:45 Step 1098/1637: training loss=0.00
2024-08-04 22:59:41 Step 1097/1637: training loss=0.00
2024-08-04 22:59:39 Step 1096/1637: training loss=0.00
2024-08-04 22:59:37 Step 1095/1637: training loss=0.00
2024-08-04 22:59:35 Step 1094/1637: training loss=0.00
2024-08-04 22:59:33 Step 1093/1637: training loss=0.00
2024-08-04 22:59:31 Step 1092/1637: training loss=0.00
2024-08-04 22:59:29 Step 1091/1637: training loss=0.00
2024-08-04 22:59:27 Step 1090/1637: training loss=0.00, full validation loss=0.00
2024-08-04 22:59:17 Step 1089/1637: training loss=0.00
2024-08-04 22:59:15 Step 1088/1637: training loss=0.00
2024-08-04 22:59:13 Step 1087/1637: training loss=0.00
2024-08-04 22:59:11 Step 1086/1637: training loss=0.00
2024-08-04 22:59:09 Step 1085/1637: training loss=0.00
2024-08-04 22:59:07 Step 1084/1637: training loss=0.00
2024-08-04 22:59:05 Step 1083/1637: training loss=0.00
2024-08-04 22:59:03 Step 1082/1637: training loss=0.00
2024-08-04 22:59:00 Step 1081/1637: training loss=0.00
2024-08-04 22:58:58 Step 1080/1637: training loss=0.00
2024-08-04 22:58:56 Step 1079/1637: training loss=0.00
2024-08-04 22:58:54 Step 1078/1637: training loss=0.00
2024-08-04 22:58:52 Step 1077/1637: training loss=0.00
2024-08-04 22:58:50 Step 1076/1637: training loss=0.00
2024-08-04 22:58:48 Step 1075/1637: training loss=0.00
2024-08-04 22:58:46 Step 1074/1637: training loss=0.00
2024-08-04 22:58:44 Step 1073/1637: training loss=0.00
2024-08-04 22:58:42 Step 1072/1637: training loss=0.00
2024-08-04 22:58:40 Step 1071/1637: training loss=0.00
2024-08-04 22:58:38 Step 1070/1637: training loss=0.00
2024-08-04 22:58:36 Step 1069/1637: training loss=0.00
2024-08-04 22:58:34 Step 1068/1637: training loss=0.00
2024-08-04 22:58:32 Step 1067/1637: training loss=0.00
2024-08-04 22:58:30 Step 1066/1637: training loss=0.00
2024-08-04 22:58:28 Step 1065/1637: training loss=0.00
2024-08-04 22:58:26 Step 1064/1637: training loss=0.00
2024-08-04 22:58:24 Step 1063/1637: training loss=0.00
2024-08-04 22:58:22 Step 1062/1637: training loss=0.00
2024-08-04 22:58:20 Step 1061/1637: training loss=0.00
2024-08-04 22:58:18 Step 1060/1637: training loss=0.00
2024-08-04 22:58:16 Step 1059/1637: training loss=0.00
2024-08-04 22:58:14 Step 1058/1637: training loss=0.00
2024-08-04 22:58:12 Step 1057/1637: training loss=0.00
2024-08-04 22:58:10 Step 1056/1637: training loss=0.00
2024-08-04 22:58:08 Step 1055/1637: training loss=0.00
2024-08-04 22:58:06 Step 1054/1637: training loss=0.00
2024-08-04 22:58:04 Step 1053/1637: training loss=0.00
2024-08-04 22:58:02 Step 1052/1637: training loss=0.00
2024-08-04 22:58:00 Step 1051/1637: training loss=0.00
2024-08-04 22:57:58 Step 1050/1637: training loss=0.00
2024-08-04 22:57:56 Step 1049/1637: training loss=0.00
2024-08-04 22:57:54 Step 1048/1637: training loss=0.00
2024-08-04 22:57:52 Step 1047/1637: training loss=0.00
2024-08-04 22:57:50 Step 1046/1637: training loss=0.00
2024-08-04 22:57:48 Step 1045/1637: training loss=0.00
2024-08-04 22:57:46 Step 1044/1637: training loss=0.00
2024-08-04 22:57:44 Step 1043/1637: training loss=0.00
2024-08-04 22:57:42 Step 1042/1637: training loss=0.00
2024-08-04 22:57:40 Step 1041/1637: training loss=0.00
2024-08-04 22:57:38 Step 1040/1637: training loss=0.00
2024-08-04 22:57:36 Step 1039/1637: training loss=0.00
2024-08-04 22:57:33 Step 1038/1637: training loss=0.00
2024-08-04 22:57:31 Step 1037/1637: training loss=0.00
2024-08-04 22:57:29 Step 1036/1637: training loss=0.00
2024-08-04 22:57:27 Step 1035/1637: training loss=0.00
2024-08-04 22:57:25 Step 1034/1637: training loss=0.00
2024-08-04 22:57:23 Step 1033/1637: training loss=0.00
2024-08-04 22:57:21 Step 1032/1637: training loss=0.00
2024-08-04 22:57:19 Step 1031/1637: training loss=0.00
2024-08-04 22:57:17 Step 1030/1637: training loss=0.00
2024-08-04 22:57:15 Step 1029/1637: training loss=0.00
2024-08-04 22:57:13 Step 1028/1637: training loss=0.00
2024-08-04 22:57:11 Step 1027/1637: training loss=0.00
2024-08-04 22:57:09 Step 1026/1637: training loss=0.00
2024-08-04 22:57:07 Step 1025/1637: training loss=0.00
2024-08-04 22:57:05 Step 1024/1637: training loss=0.00
2024-08-04 22:57:03 Step 1023/1637: training loss=0.00
2024-08-04 22:57:01 Step 1022/1637: training loss=0.00
2024-08-04 22:56:59 Step 1021/1637: training loss=0.00
2024-08-04 22:56:59 Step 1020/1637: training loss=0.00
2024-08-04 22:56:57 Step 1019/1637: training loss=0.00
2024-08-04 22:56:55 Step 1018/1637: training loss=0.00
2024-08-04 22:56:53 Step 1017/1637: training loss=0.00
2024-08-04 22:56:51 Step 1016/1637: training loss=0.00
2024-08-04 22:56:49 Step 1015/1637: training loss=0.00
2024-08-04 22:56:47 Step 1014/1637: training loss=0.00
2024-08-04 22:56:45 Step 1013/1637: training loss=0.00
2024-08-04 22:56:43 Step 1012/1637: training loss=0.00
2024-08-04 22:56:41 Step 1011/1637: training loss=0.00
2024-08-04 22:56:39 Step 1010/1637: training loss=0.00
2024-08-04 22:56:37 Step 1009/1637: training loss=0.00
2024-08-04 22:56:35 Step 1008/1637: training loss=0.00
2024-08-04 22:56:33 Step 1007/1637: training loss=0.00
2024-08-04 22:56:31 Step 1006/1637: training loss=0.00
2024-08-04 22:56:29 Step 1005/1637: training loss=0.00
2024-08-04 22:56:27 Step 1004/1637: training loss=0.00
2024-08-04 22:56:25 Step 1003/1637: training loss=0.00
2024-08-04 22:56:23 Step 1002/1637: training loss=0.00
2024-08-04 22:56:21 Step 1001/1637: training loss=0.00
2024-08-04 22:56:19 Step 1000/1637: training loss=0.00, validation loss=0.00
2024-08-04 22:56:17 Step 999/1637: training loss=0.00
2024-08-04 22:56:15 Step 998/1637: training loss=0.00
2024-08-04 22:56:13 Step 997/1637: training loss=0.00
2024-08-04 22:56:11 Step 996/1637: training loss=0.00
2024-08-04 22:56:09 Step 995/1637: training loss=0.00
2024-08-04 22:56:07 Step 994/1637: training loss=0.00
2024-08-04 22:56:05 Step 993/1637: training loss=0.00
2024-08-04 22:56:03 Step 992/1637: training loss=0.00
2024-08-04 22:56:01 Step 991/1637: training loss=0.00
2024-08-04 22:55:59 Step 990/1637: training loss=0.00
2024-08-04 22:55:57 Step 989/1637: training loss=0.00
2024-08-04 22:55:55 Step 988/1637: training loss=0.00
2024-08-04 22:55:52 Step 987/1637: training loss=0.00
2024-08-04 22:55:50 Step 986/1637: training loss=0.00
2024-08-04 22:55:48 Step 985/1637: training loss=0.00
2024-08-04 22:55:46 Step 984/1637: training loss=0.00
2024-08-04 22:55:44 Step 983/1637: training loss=0.00
2024-08-04 22:55:42 Step 982/1637: training loss=0.00
2024-08-04 22:55:40 Step 981/1637: training loss=0.00
2024-08-04 22:55:38 Step 980/1637: training loss=0.00
2024-08-04 22:55:36 Step 979/1637: training loss=0.00
2024-08-04 22:55:34 Step 978/1637: training loss=0.00
2024-08-04 22:55:32 Step 977/1637: training loss=0.00
2024-08-04 22:55:30 Step 976/1637: training loss=0.00
2024-08-04 22:55:28 Step 975/1637: training loss=0.00
2024-08-04 22:55:26 Step 974/1637: training loss=0.00
2024-08-04 22:55:24 Step 973/1637: training loss=0.00
2024-08-04 22:55:22 Step 972/1637: training loss=0.00
2024-08-04 22:55:20 Step 971/1637: training loss=0.00
2024-08-04 22:55:18 Step 970/1637: training loss=0.00
2024-08-04 22:55:16 Step 969/1637: training loss=0.00
2024-08-04 22:55:14 Step 968/1637: training loss=0.00
2024-08-04 22:55:12 Step 967/1637: training loss=0.00
2024-08-04 22:55:10 Step 966/1637: training loss=0.00
2024-08-04 22:55:08 Step 965/1637: training loss=0.00
2024-08-04 22:55:06 Step 964/1637: training loss=0.00
2024-08-04 22:55:04 Step 963/1637: training loss=0.00
2024-08-04 22:55:02 Step 962/1637: training loss=0.00
2024-08-04 22:55:00 Step 961/1637: training loss=0.00
2024-08-04 22:54:58 Step 960/1637: training loss=0.00
2024-08-04 22:54:56 Step 959/1637: training loss=0.00
2024-08-04 22:54:54 Step 958/1637: training loss=0.00
2024-08-04 22:54:52 Step 957/1637: training loss=0.00
2024-08-04 22:54:50 Step 956/1637: training loss=0.00
2024-08-04 22:54:48 Step 955/1637: training loss=0.00
2024-08-04 22:54:46 Step 954/1637: training loss=0.00
2024-08-04 22:54:44 Step 953/1637: training loss=0.00
2024-08-04 22:54:42 Step 952/1637: training loss=0.00
2024-08-04 22:54:40 Step 951/1637: training loss=0.00
2024-08-04 22:54:38 Step 950/1637: training loss=0.00
2024-08-04 22:54:36 Step 949/1637: training loss=0.00
2024-08-04 22:54:34 Step 948/1637: training loss=0.00
2024-08-04 22:54:32 Step 947/1637: training loss=0.00
2024-08-04 22:54:30 Step 946/1637: training loss=0.00
2024-08-04 22:54:30 Step 945/1637: training loss=0.00
2024-08-04 22:54:28 Step 944/1637: training loss=0.00
2024-08-04 22:54:26 Step 943/1637: training loss=0.00
2024-08-04 22:54:24 Step 942/1637: training loss=0.00
2024-08-04 22:54:22 Step 941/1637: training loss=0.00
2024-08-04 22:54:20 Step 940/1637: training loss=0.00
2024-08-04 22:54:18 Step 939/1637: training loss=0.00
2024-08-04 22:54:16 Step 938/1637: training loss=0.00
2024-08-04 22:54:14 Step 937/1637: training loss=0.00
2024-08-04 22:54:12 Step 936/1637: training loss=0.00
2024-08-04 22:54:10 Step 935/1637: training loss=0.00
2024-08-04 22:54:08 Step 934/1637: training loss=0.00
2024-08-04 22:54:06 Step 933/1637: training loss=0.00
2024-08-04 22:54:03 Step 932/1637: training loss=0.00
2024-08-04 22:54:01 Step 931/1637: training loss=0.00
2024-08-04 22:53:59 Step 930/1637: training loss=0.00
2024-08-04 22:53:57 Step 929/1637: training loss=0.00
2024-08-04 22:53:55 Step 928/1637: training loss=0.00
2024-08-04 22:53:53 Step 927/1637: training loss=0.00
2024-08-04 22:53:51 Step 926/1637: training loss=0.00
2024-08-04 22:53:49 Step 925/1637: training loss=0.00
2024-08-04 22:53:47 Step 924/1637: training loss=0.00
2024-08-04 22:53:45 Step 923/1637: training loss=0.00
2024-08-04 22:53:43 Step 922/1637: training loss=0.00
2024-08-04 22:53:41 Step 921/1637: training loss=0.00
2024-08-04 22:53:39 Step 920/1637: training loss=0.00
2024-08-04 22:53:37 Step 919/1637: training loss=0.00
2024-08-04 22:53:35 Step 918/1637: training loss=0.00
2024-08-04 22:53:33 Step 917/1637: training loss=0.00
2024-08-04 22:53:31 Step 916/1637: training loss=0.00
2024-08-04 22:53:29 Step 915/1637: training loss=0.00
2024-08-04 22:53:27 Step 914/1637: training loss=0.00
2024-08-04 22:53:25 Step 913/1637: training loss=0.00
2024-08-04 22:53:23 Step 912/1637: training loss=0.00
2024-08-04 22:53:21 Step 911/1637: training loss=0.00
2024-08-04 22:53:19 Step 910/1637: training loss=0.00
2024-08-04 22:53:17 Step 909/1637: training loss=0.00
2024-08-04 22:53:15 Step 908/1637: training loss=0.00
2024-08-04 22:53:13 Step 907/1637: training loss=0.00
2024-08-04 22:53:11 Step 906/1637: training loss=0.00
2024-08-04 22:53:09 Step 905/1637: training loss=0.00
2024-08-04 22:53:07 Step 904/1637: training loss=0.00
2024-08-04 22:53:05 Step 903/1637: training loss=0.00
2024-08-04 22:53:03 Step 902/1637: training loss=0.00
2024-08-04 22:53:01 Step 901/1637: training loss=0.00
2024-08-04 22:52:59 Step 900/1637: training loss=0.00, validation loss=0.00
2024-08-04 22:52:57 Step 899/1637: training loss=0.00
2024-08-04 22:52:55 Step 898/1637: training loss=0.00
2024-08-04 22:52:53 Step 897/1637: training loss=0.00
2024-08-04 22:52:51 Step 896/1637: training loss=0.00
2024-08-04 22:52:49 Step 895/1637: training loss=0.00
2024-08-04 22:52:47 Step 894/1637: training loss=0.00
2024-08-04 22:52:45 Step 893/1637: training loss=0.00
2024-08-04 22:52:43 Step 892/1637: training loss=0.00
2024-08-04 22:52:41 Step 891/1637: training loss=0.00
2024-08-04 22:52:39 Step 890/1637: training loss=0.00
2024-08-04 22:52:37 Step 889/1637: training loss=0.00
2024-08-04 22:52:35 Step 888/1637: training loss=0.00
2024-08-04 22:52:33 Step 887/1637: training loss=0.00
2024-08-04 22:52:19 Step 886/1637: training loss=0.00
2024-08-04 22:52:16 Step 885/1637: training loss=0.00
2024-08-04 22:52:16 Step 884/1637: training loss=0.00
2024-08-04 22:52:14 Step 883/1637: training loss=0.00
2024-08-04 22:52:12 Step 882/1637: training loss=0.00
2024-08-04 22:52:10 Step 881/1637: training loss=0.00
2024-08-04 22:52:08 Step 880/1637: training loss=0.00
2024-08-04 22:52:06 Step 879/1637: training loss=0.00
2024-08-04 22:52:04 Step 878/1637: training loss=0.00
2024-08-04 22:52:02 Step 877/1637: training loss=0.00
2024-08-04 22:52:00 Step 876/1637: training loss=0.00
2024-08-04 22:51:58 Step 875/1637: training loss=0.00
2024-08-04 22:51:56 Step 874/1637: training loss=0.00
2024-08-04 22:51:54 Step 873/1637: training loss=0.00
2024-08-04 22:51:52 Step 872/1637: training loss=0.00
2024-08-04 22:51:50 Step 871/1637: training loss=0.00
2024-08-04 22:51:48 Step 870/1637: training loss=0.00
2024-08-04 22:51:46 Step 869/1637: training loss=0.00
2024-08-04 22:51:44 Step 868/1637: training loss=0.00
2024-08-04 22:51:42 Step 867/1637: training loss=0.00
2024-08-04 22:51:40 Step 866/1637: training loss=0.00
2024-08-04 22:51:38 Step 865/1637: training loss=0.00
2024-08-04 22:51:36 Step 864/1637: training loss=0.00
2024-08-04 22:51:34 Step 863/1637: training loss=0.00
2024-08-04 22:51:32 Step 862/1637: training loss=0.00
2024-08-04 22:51:30 Step 861/1637: training loss=0.00
2024-08-04 22:51:28 Step 860/1637: training loss=0.00
2024-08-04 22:51:26 Step 859/1637: training loss=0.00
2024-08-04 22:51:24 Step 858/1637: training loss=0.00
2024-08-04 22:51:22 Step 857/1637: training loss=0.00
2024-08-04 22:51:20 Step 856/1637: training loss=0.00
2024-08-04 22:51:18 Step 855/1637: training loss=0.00
2024-08-04 22:51:16 Step 854/1637: training loss=0.00
2024-08-04 22:51:14 Step 853/1637: training loss=0.00
2024-08-04 22:51:12 Step 852/1637: training loss=0.00
2024-08-04 22:51:10 Step 851/1637: training loss=0.00
2024-08-04 22:51:08 Step 850/1637: training loss=0.00
2024-08-04 22:51:06 Step 849/1637: training loss=0.00
2024-08-04 22:51:04 Step 848/1637: training loss=0.00
2024-08-04 22:51:02 Step 847/1637: training loss=0.00
2024-08-04 22:51:00 Step 846/1637: training loss=0.00
2024-08-04 22:50:58 Step 845/1637: training loss=0.00
2024-08-04 22:50:56 Step 844/1637: training loss=0.00
2024-08-04 22:50:54 Step 843/1637: training loss=0.00
2024-08-04 22:50:52 Step 842/1637: training loss=0.00
2024-08-04 22:50:50 Step 841/1637: training loss=0.00
2024-08-04 22:50:48 Step 840/1637: training loss=0.00
2024-08-04 22:50:46 Step 839/1637: training loss=0.00
2024-08-04 22:50:44 Step 838/1637: training loss=0.00
2024-08-04 22:50:42 Step 837/1637: training loss=0.00
2024-08-04 22:50:40 Step 836/1637: training loss=0.00
2024-08-04 22:50:38 Step 835/1637: training loss=0.00
2024-08-04 22:50:36 Step 834/1637: training loss=0.00
2024-08-04 22:50:33 Step 833/1637: training loss=0.00
2024-08-04 22:50:31 Step 832/1637: training loss=0.00
2024-08-04 22:50:29 Step 831/1637: training loss=0.00
2024-08-04 22:50:27 Step 830/1637: training loss=0.00
2024-08-04 22:50:25 Step 829/1637: training loss=0.00
2024-08-04 22:50:23 Step 828/1637: training loss=0.00
2024-08-04 22:50:21 Step 827/1637: training loss=0.00
2024-08-04 22:50:19 Step 826/1637: training loss=0.00
2024-08-04 22:50:17 Step 825/1637: training loss=0.00
2024-08-04 22:50:15 Step 824/1637: training loss=0.00
2024-08-04 22:50:15 Step 823/1637: training loss=0.00
2024-08-04 22:50:13 Step 822/1637: training loss=0.00
2024-08-04 22:50:11 Step 821/1637: training loss=0.00
2024-08-04 22:50:09 Step 820/1637: training loss=0.00
2024-08-04 22:50:07 Step 819/1637: training loss=0.00
2024-08-04 22:50:05 Step 818/1637: training loss=0.00
2024-08-04 22:50:03 Step 817/1637: training loss=0.00
2024-08-04 22:50:01 Step 816/1637: training loss=0.00
2024-08-04 22:49:59 Step 815/1637: training loss=0.00
2024-08-04 22:49:57 Step 814/1637: training loss=0.00
2024-08-04 22:49:55 Step 813/1637: training loss=0.00
2024-08-04 22:49:53 Step 812/1637: training loss=0.00
2024-08-04 22:49:51 Step 811/1637: training loss=0.00
2024-08-04 22:49:49 Step 810/1637: training loss=0.00
2024-08-04 22:49:47 Step 809/1637: training loss=0.00
2024-08-04 22:49:45 Step 808/1637: training loss=0.00
2024-08-04 22:49:43 Step 807/1637: training loss=0.00
2024-08-04 22:49:41 Step 806/1637: training loss=0.00
2024-08-04 22:49:39 Step 805/1637: training loss=0.00
2024-08-04 22:49:37 Step 804/1637: training loss=0.00
2024-08-04 22:49:35 Step 803/1637: training loss=0.00
2024-08-04 22:49:33 Step 802/1637: training loss=0.00
2024-08-04 22:49:31 Step 801/1637: training loss=0.00
2024-08-04 22:49:29 Step 800/1637: training loss=0.00, validation loss=0.00
2024-08-04 22:49:27 Step 799/1637: training loss=0.00
2024-08-04 22:49:25 Step 798/1637: training loss=0.00
2024-08-04 22:49:23 Step 797/1637: training loss=0.00
2024-08-04 22:49:21 Step 796/1637: training loss=0.00
2024-08-04 22:49:19 Step 795/1637: training loss=0.00
2024-08-04 22:49:17 Step 794/1637: training loss=0.00
2024-08-04 22:49:15 Step 793/1637: training loss=0.00
2024-08-04 22:49:13 Step 792/1637: training loss=0.00
2024-08-04 22:49:11 Step 791/1637: training loss=0.00
2024-08-04 22:49:09 Step 790/1637: training loss=0.00
2024-08-04 22:49:07 Step 789/1637: training loss=0.00
2024-08-04 22:49:05 Step 788/1637: training loss=0.00
2024-08-04 22:49:03 Step 787/1637: training loss=0.00
2024-08-04 22:49:01 Step 786/1637: training loss=0.00
2024-08-04 22:48:59 Step 785/1637: training loss=0.00
2024-08-04 22:48:57 Step 784/1637: training loss=0.00
2024-08-04 22:48:55 Step 783/1637: training loss=0.00
2024-08-04 22:48:53 Step 782/1637: training loss=0.00
2024-08-04 22:48:51 Step 781/1637: training loss=0.00
2024-08-04 22:48:49 Step 780/1637: training loss=0.00
2024-08-04 22:48:46 Step 779/1637: training loss=0.00
2024-08-04 22:48:44 Step 778/1637: training loss=0.00
2024-08-04 22:48:42 Step 777/1637: training loss=0.00
2024-08-04 22:48:40 Step 776/1637: training loss=0.00
2024-08-04 22:48:38 Step 775/1637: training loss=0.00
2024-08-04 22:48:36 Step 774/1637: training loss=0.00
2024-08-04 22:48:34 Step 773/1637: training loss=0.00
2024-08-04 22:48:32 Step 772/1637: training loss=0.00
2024-08-04 22:48:30 Step 771/1637: training loss=0.00
2024-08-04 22:48:28 Step 770/1637: training loss=0.00
2024-08-04 22:48:26 Step 769/1637: training loss=0.00
2024-08-04 22:48:24 Step 768/1637: training loss=0.00
2024-08-04 22:48:22 Step 767/1637: training loss=0.00
2024-08-04 22:48:20 Step 766/1637: training loss=0.00
2024-08-04 22:48:18 Step 765/1637: training loss=0.00
2024-08-04 22:48:16 Step 764/1637: training loss=0.00
2024-08-04 22:48:14 Step 763/1637: training loss=0.00
2024-08-04 22:48:12 Step 762/1637: training loss=0.00
2024-08-04 22:48:10 Step 761/1637: training loss=0.00
2024-08-04 22:48:08 Step 760/1637: training loss=0.00
2024-08-04 22:48:06 Step 759/1637: training loss=0.00
2024-08-04 22:48:04 Step 758/1637: training loss=0.00
2024-08-04 22:48:02 Step 757/1637: training loss=0.00
2024-08-04 22:48:00 Step 756/1637: training loss=0.00
2024-08-04 22:47:58 Step 755/1637: training loss=0.00
2024-08-04 22:47:56 Step 754/1637: training loss=0.00
2024-08-04 22:47:54 Step 753/1637: training loss=0.00
2024-08-04 22:47:52 Step 752/1637: training loss=0.00
2024-08-04 22:47:50 Step 751/1637: training loss=0.00
2024-08-04 22:47:48 Step 750/1637: training loss=0.00
2024-08-04 22:47:46 Step 749/1637: training loss=0.00
2024-08-04 22:47:44 Step 748/1637: training loss=0.00
2024-08-04 22:47:42 Step 747/1637: training loss=0.00
2024-08-04 22:47:40 Step 746/1637: training loss=0.00
2024-08-04 22:47:38 Step 745/1637: training loss=0.00
2024-08-04 22:47:36 Step 744/1637: training loss=0.00
2024-08-04 22:47:34 Step 743/1637: training loss=0.00
2024-08-04 22:47:32 Step 742/1637: training loss=0.00
2024-08-04 22:47:30 Step 741/1637: training loss=0.00
2024-08-04 22:47:28 Step 740/1637: training loss=0.00
2024-08-04 22:47:26 Step 739/1637: training loss=0.00
2024-08-04 22:47:24 Step 738/1637: training loss=0.00
2024-08-04 22:47:22 Step 737/1637: training loss=0.00
2024-08-04 22:47:20 Step 736/1637: training loss=0.00
2024-08-04 22:47:18 Step 735/1637: training loss=0.00
2024-08-04 22:47:16 Step 734/1637: training loss=0.00
2024-08-04 22:47:14 Step 733/1637: training loss=0.00
2024-08-04 22:47:12 Step 732/1637: training loss=0.00
2024-08-04 22:47:10 Step 731/1637: training loss=0.00
2024-08-04 22:47:07 Step 730/1637: training loss=0.00
2024-08-04 22:47:05 Step 729/1637: training loss=0.00
2024-08-04 22:47:03 Step 728/1637: training loss=0.00
2024-08-04 22:47:01 Step 727/1637: training loss=0.00
2024-08-04 22:46:59 Step 726/1637: training loss=0.00
2024-08-04 22:46:57 Step 725/1637: training loss=0.00
2024-08-04 22:46:55 Step 724/1637: training loss=0.00
2024-08-04 22:46:53 Step 723/1637: training loss=0.00
2024-08-04 22:46:51 Step 722/1637: training loss=0.00
2024-08-04 22:46:49 Step 721/1637: training loss=0.00
2024-08-04 22:46:47 Step 720/1637: training loss=0.00
2024-08-04 22:46:45 Step 719/1637: training loss=0.00
2024-08-04 22:46:43 Step 718/1637: training loss=0.00
2024-08-04 22:46:41 Step 717/1637: training loss=0.00
2024-08-04 22:46:39 Step 716/1637: training loss=0.00
2024-08-04 22:46:37 Step 715/1637: training loss=0.00
2024-08-04 22:46:35 Step 714/1637: training loss=0.00
2024-08-04 22:46:33 Step 713/1637: training loss=0.00
2024-08-04 22:46:31 Step 712/1637: training loss=0.00
2024-08-04 22:46:29 Step 711/1637: training loss=0.00
2024-08-04 22:46:27 Step 710/1637: training loss=0.00
2024-08-04 22:46:25 Step 709/1637: training loss=0.00
2024-08-04 22:46:23 Step 708/1637: training loss=0.00
2024-08-04 22:46:21 Step 707/1637: training loss=0.00
2024-08-04 22:46:19 Step 706/1637: training loss=0.00
2024-08-04 22:46:17 Step 705/1637: training loss=0.00
2024-08-04 22:46:15 Step 704/1637: training loss=0.00
2024-08-04 22:46:15 Step 703/1637: training loss=0.00
2024-08-04 22:46:13 Step 702/1637: training loss=0.00
2024-08-04 22:46:11 Step 701/1637: training loss=0.00
2024-08-04 22:46:09 Step 700/1637: training loss=0.00, validation loss=0.00
2024-08-04 22:46:07 Step 699/1637: training loss=0.00
2024-08-04 22:46:03 Step 698/1637: training loss=0.00
2024-08-04 22:46:01 Step 697/1637: training loss=0.00
2024-08-04 22:45:59 Step 696/1637: training loss=0.00
2024-08-04 22:45:57 Step 695/1637: training loss=0.00
2024-08-04 22:45:55 Step 694/1637: training loss=0.00
2024-08-04 22:45:53 Step 693/1637: training loss=0.00
2024-08-04 22:45:51 Step 692/1637: training loss=0.00
2024-08-04 22:45:49 Step 691/1637: training loss=0.00
2024-08-04 22:45:47 Step 690/1637: training loss=0.00
2024-08-04 22:45:45 Step 689/1637: training loss=0.00
2024-08-04 22:45:43 Step 688/1637: training loss=0.00
2024-08-04 22:45:41 Step 687/1637: training loss=0.00
2024-08-04 22:45:39 Step 686/1637: training loss=0.00
2024-08-04 22:45:37 Step 685/1637: training loss=0.00
2024-08-04 22:45:35 Step 684/1637: training loss=0.00
2024-08-04 22:45:33 Step 683/1637: training loss=0.00
2024-08-04 22:45:31 Step 682/1637: training loss=0.00
2024-08-04 22:45:29 Step 681/1637: training loss=0.00
2024-08-04 22:45:29 Step 680/1637: training loss=0.00
2024-08-04 22:45:27 Step 679/1637: training loss=0.00
2024-08-04 22:45:25 Step 678/1637: training loss=0.00
2024-08-04 22:45:23 Step 677/1637: training loss=0.00
2024-08-04 22:45:20 Step 676/1637: training loss=0.00
2024-08-04 22:45:18 Step 675/1637: training loss=0.00
2024-08-04 22:45:16 Step 674/1637: training loss=0.00
2024-08-04 22:45:14 Step 673/1637: training loss=0.00
2024-08-04 22:45:12 Step 672/1637: training loss=0.00
2024-08-04 22:45:10 Step 671/1637: training loss=0.00
2024-08-04 22:45:08 Step 670/1637: training loss=0.00
2024-08-04 22:45:06 Step 669/1637: training loss=0.00
2024-08-04 22:45:04 Step 668/1637: training loss=0.00
2024-08-04 22:45:02 Step 667/1637: training loss=0.00
2024-08-04 22:45:00 Step 666/1637: training loss=0.00
2024-08-04 22:44:58 Step 665/1637: training loss=0.00
2024-08-04 22:44:56 Step 664/1637: training loss=0.00
2024-08-04 22:44:54 Step 663/1637: training loss=0.00
2024-08-04 22:44:52 Step 662/1637: training loss=0.00
2024-08-04 22:44:50 Step 661/1637: training loss=0.00
2024-08-04 22:44:48 Step 660/1637: training loss=0.00
2024-08-04 22:44:46 Step 659/1637: training loss=0.00
2024-08-04 22:44:44 Step 658/1637: training loss=0.00
2024-08-04 22:44:42 Step 657/1637: training loss=0.00
2024-08-04 22:44:40 Step 656/1637: training loss=0.00
2024-08-04 22:44:38 Step 655/1637: training loss=0.00
2024-08-04 22:44:36 Step 654/1637: training loss=0.00
2024-08-04 22:44:34 Step 653/1637: training loss=0.00
2024-08-04 22:44:32 Step 652/1637: training loss=0.00
2024-08-04 22:44:30 Step 651/1637: training loss=0.00
2024-08-04 22:44:28 Step 650/1637: training loss=0.00
2024-08-04 22:44:26 Step 649/1637: training loss=0.00
2024-08-04 22:44:24 Step 648/1637: training loss=0.00
2024-08-04 22:44:22 Step 647/1637: training loss=0.00
2024-08-04 22:44:20 Step 646/1637: training loss=0.00
2024-08-04 22:44:18 Step 645/1637: training loss=0.00
2024-08-04 22:44:16 Step 644/1637: training loss=0.00
2024-08-04 22:44:14 Step 643/1637: training loss=0.00
2024-08-04 22:44:12 Step 642/1637: training loss=0.00
2024-08-04 22:44:10 Step 641/1637: training loss=0.00
2024-08-04 22:44:08 Step 640/1637: training loss=0.00
2024-08-04 22:44:06 Step 639/1637: training loss=0.00
2024-08-04 22:44:04 Step 638/1637: training loss=0.00
2024-08-04 22:44:02 Step 637/1637: training loss=0.00
2024-08-04 22:44:00 Step 636/1637: training loss=0.00
2024-08-04 22:43:58 Step 635/1637: training loss=0.00
2024-08-04 22:43:56 Step 634/1637: training loss=0.00
2024-08-04 22:43:54 Step 633/1637: training loss=0.00
2024-08-04 22:43:52 Step 632/1637: training loss=0.00
2024-08-04 22:43:50 Step 631/1637: training loss=0.00
2024-08-04 22:43:48 Step 630/1637: training loss=0.00
2024-08-04 22:43:46 Step 629/1637: training loss=0.00
2024-08-04 22:43:44 Step 628/1637: training loss=0.00
2024-08-04 22:43:42 Step 627/1637: training loss=0.00
2024-08-04 22:43:40 Step 626/1637: training loss=0.00
2024-08-04 22:43:38 Step 625/1637: training loss=0.00
2024-08-04 22:43:36 Step 624/1637: training loss=0.00
2024-08-04 22:43:33 Step 623/1637: training loss=0.00
2024-08-04 22:43:31 Step 622/1637: training loss=0.00
2024-08-04 22:43:29 Step 621/1637: training loss=0.00
2024-08-04 22:43:27 Step 620/1637: training loss=0.00
2024-08-04 22:43:27 Step 619/1637: training loss=0.00
2024-08-04 22:43:25 Step 618/1637: training loss=0.00
2024-08-04 22:43:23 Step 617/1637: training loss=0.00
2024-08-04 22:43:21 Step 616/1637: training loss=0.00
2024-08-04 22:43:19 Step 615/1637: training loss=0.00
2024-08-04 22:43:17 Step 614/1637: training loss=0.00
2024-08-04 22:43:15 Step 613/1637: training loss=0.00
2024-08-04 22:43:13 Step 612/1637: training loss=0.00
2024-08-04 22:43:11 Step 611/1637: training loss=0.00
2024-08-04 22:43:09 Step 610/1637: training loss=0.00
2024-08-04 22:43:07 Step 609/1637: training loss=0.00
2024-08-04 22:43:05 Step 608/1637: training loss=0.00
2024-08-04 22:43:03 Step 607/1637: training loss=0.00
2024-08-04 22:43:01 Step 606/1637: training loss=0.00
2024-08-04 22:42:59 Step 605/1637: training loss=0.00
2024-08-04 22:42:57 Step 604/1637: training loss=0.00
2024-08-04 22:42:55 Step 603/1637: training loss=0.00
2024-08-04 22:42:51 Step 602/1637: training loss=0.00
2024-08-04 22:42:49 Step 601/1637: training loss=0.00
2024-08-04 22:42:47 Step 600/1637: training loss=0.00, validation loss=0.00
2024-08-04 22:42:45 Step 599/1637: training loss=0.00
2024-08-04 22:42:43 Step 598/1637: training loss=0.00
2024-08-04 22:42:41 Step 597/1637: training loss=0.00
2024-08-04 22:42:39 Step 596/1637: training loss=0.00
2024-08-04 22:42:37 Step 595/1637: training loss=0.00
2024-08-04 22:42:35 Step 594/1637: training loss=0.00
2024-08-04 22:42:33 Step 593/1637: training loss=0.00
2024-08-04 22:42:31 Step 592/1637: training loss=0.00
2024-08-04 22:42:29 Step 591/1637: training loss=0.00
2024-08-04 22:42:27 Step 590/1637: training loss=0.00
2024-08-04 22:42:25 Step 589/1637: training loss=0.00
2024-08-04 22:42:23 Step 588/1637: training loss=0.00
2024-08-04 22:42:21 Step 587/1637: training loss=0.00
2024-08-04 22:42:19 Step 586/1637: training loss=0.00
2024-08-04 22:42:17 Step 585/1637: training loss=0.00
2024-08-04 22:42:15 Step 584/1637: training loss=0.00
2024-08-04 22:42:13 Step 583/1637: training loss=0.00
2024-08-04 22:42:11 Step 582/1637: training loss=0.00
2024-08-04 22:42:09 Step 581/1637: training loss=0.00
2024-08-04 22:42:07 Step 580/1637: training loss=0.00
2024-08-04 22:42:05 Step 579/1637: training loss=0.00
2024-08-04 22:42:03 Step 578/1637: training loss=0.00
2024-08-04 22:42:01 Step 577/1637: training loss=0.00
2024-08-04 22:41:57 Step 576/1637: training loss=0.00
2024-08-04 22:41:55 Step 575/1637: training loss=0.00
2024-08-04 22:41:53 Step 574/1637: training loss=0.00
2024-08-04 22:41:51 Step 573/1637: training loss=0.00
2024-08-04 22:41:49 Step 572/1637: training loss=0.00
2024-08-04 22:41:46 Step 571/1637: training loss=0.00
2024-08-04 22:41:44 Step 570/1637: training loss=0.00
2024-08-04 22:41:42 Step 569/1637: training loss=0.00
2024-08-04 22:41:40 Step 568/1637: training loss=0.00
2024-08-04 22:41:38 Step 567/1637: training loss=0.00
2024-08-04 22:41:36 Step 566/1637: training loss=0.00
2024-08-04 22:41:34 Step 565/1637: training loss=0.00
2024-08-04 22:41:32 Step 564/1637: training loss=0.00
2024-08-04 22:41:30 Step 563/1637: training loss=0.00
2024-08-04 22:41:28 Step 562/1637: training loss=0.00
2024-08-04 22:41:28 Step 561/1637: training loss=0.00
2024-08-04 22:41:26 Step 560/1637: training loss=0.00
2024-08-04 22:41:24 Step 559/1637: training loss=0.00
2024-08-04 22:41:22 Step 558/1637: training loss=0.00
2024-08-04 22:41:20 Step 557/1637: training loss=0.00
2024-08-04 22:41:18 Step 556/1637: training loss=0.00
2024-08-04 22:41:16 Step 555/1637: training loss=0.00
2024-08-04 22:41:14 Step 554/1637: training loss=0.00
2024-08-04 22:41:12 Step 553/1637: training loss=0.00
2024-08-04 22:41:10 Step 552/1637: training loss=0.00
2024-08-04 22:41:08 Step 551/1637: training loss=0.00
2024-08-04 22:41:06 Step 550/1637: training loss=0.00
2024-08-04 22:41:04 Step 549/1637: training loss=0.00
2024-08-04 22:41:02 Step 548/1637: training loss=0.00
2024-08-04 22:41:00 Step 547/1637: training loss=0.00
2024-08-04 22:40:56 Step 546/1637: training loss=0.00
2024-08-04 22:40:54 Step 545/1637: training loss=0.00, full validation loss=0.00
2024-08-04 22:40:38 Step 544/1637: training loss=0.00
2024-08-04 22:40:36 Step 543/1637: training loss=0.00
2024-08-04 22:40:34 Step 542/1637: training loss=0.00
2024-08-04 22:40:32 Step 541/1637: training loss=0.00
2024-08-04 22:40:30 Step 540/1637: training loss=0.00
2024-08-04 22:40:28 Step 539/1637: training loss=0.00
2024-08-04 22:40:26 Step 538/1637: training loss=0.00
2024-08-04 22:40:24 Step 537/1637: training loss=0.00
2024-08-04 22:40:22 Step 536/1637: training loss=0.00
2024-08-04 22:40:20 Step 535/1637: training loss=0.00
2024-08-04 22:40:18 Step 534/1637: training loss=0.00
2024-08-04 22:40:16 Step 533/1637: training loss=0.00
2024-08-04 22:40:14 Step 532/1637: training loss=0.00
2024-08-04 22:40:12 Step 531/1637: training loss=0.00
2024-08-04 22:40:10 Step 530/1637: training loss=0.00
2024-08-04 22:40:08 Step 529/1637: training loss=0.00
2024-08-04 22:40:06 Step 528/1637: training loss=0.00
2024-08-04 22:40:03 Step 527/1637: training loss=0.00
2024-08-04 22:40:01 Step 526/1637: training loss=0.00
2024-08-04 22:39:59 Step 525/1637: training loss=0.00
2024-08-04 22:39:57 Step 524/1637: training loss=0.00
2024-08-04 22:39:55 Step 523/1637: training loss=0.00
2024-08-04 22:39:53 Step 522/1637: training loss=0.00
2024-08-04 22:39:51 Step 521/1637: training loss=0.00
2024-08-04 22:39:49 Step 520/1637: training loss=0.00
2024-08-04 22:39:47 Step 519/1637: training loss=0.00
2024-08-04 22:39:45 Step 518/1637: training loss=0.00
2024-08-04 22:39:43 Step 517/1637: training loss=0.00
2024-08-04 22:39:41 Step 516/1637: training loss=0.00
2024-08-04 22:39:39 Step 515/1637: training loss=0.00
2024-08-04 22:39:37 Step 514/1637: training loss=0.00
2024-08-04 22:39:35 Step 513/1637: training loss=0.00
2024-08-04 22:39:33 Step 512/1637: training loss=0.00
2024-08-04 22:39:31 Step 511/1637: training loss=0.00
2024-08-04 22:39:29 Step 510/1637: training loss=0.00
2024-08-04 22:39:27 Step 509/1637: training loss=0.00
2024-08-04 22:39:25 Step 508/1637: training loss=0.00
2024-08-04 22:39:23 Step 507/1637: training loss=0.00
2024-08-04 22:39:21 Step 506/1637: training loss=0.00
2024-08-04 22:39:19 Step 505/1637: training loss=0.00
2024-08-04 22:39:17 Step 504/1637: training loss=0.00
2024-08-04 22:39:15 Step 503/1637: training loss=0.00
2024-08-04 22:39:13 Step 502/1637: training loss=0.00
2024-08-04 22:39:13 Step 501/1637: training loss=0.00
2024-08-04 22:39:11 Step 500/1637: training loss=0.00, validation loss=0.00
2024-08-04 22:39:09 Step 499/1637: training loss=0.00
2024-08-04 22:39:05 Step 498/1637: training loss=0.00
2024-08-04 22:39:03 Step 497/1637: training loss=0.00
2024-08-04 22:39:01 Step 496/1637: training loss=0.00
2024-08-04 22:38:59 Step 495/1637: training loss=0.00
2024-08-04 22:38:57 Step 494/1637: training loss=0.00
2024-08-04 22:38:55 Step 493/1637: training loss=0.00
2024-08-04 22:38:53 Step 492/1637: training loss=0.00
2024-08-04 22:38:53 Step 491/1637: training loss=0.00
2024-08-04 22:38:51 Step 490/1637: training loss=0.00
2024-08-04 22:38:49 Step 489/1637: training loss=0.00
2024-08-04 22:38:47 Step 488/1637: training loss=0.00
2024-08-04 22:38:45 Step 487/1637: training loss=0.00
2024-08-04 22:38:43 Step 486/1637: training loss=0.00
2024-08-04 22:38:41 Step 485/1637: training loss=0.00
2024-08-04 22:38:39 Step 484/1637: training loss=0.00
2024-08-04 22:38:37 Step 483/1637: training loss=0.00
2024-08-04 22:38:35 Step 482/1637: training loss=0.00
2024-08-04 22:38:33 Step 481/1637: training loss=0.00
2024-08-04 22:38:31 Step 480/1637: training loss=0.00
2024-08-04 22:38:29 Step 479/1637: training loss=0.00
2024-08-04 22:38:27 Step 478/1637: training loss=0.00
2024-08-04 22:38:25 Step 477/1637: training loss=0.00
2024-08-04 22:38:22 Step 476/1637: training loss=0.00
2024-08-04 22:38:20 Step 475/1637: training loss=0.00
2024-08-04 22:38:18 Step 474/1637: training loss=0.00
2024-08-04 22:38:16 Step 473/1637: training loss=0.00
2024-08-04 22:38:14 Step 472/1637: training loss=0.00
2024-08-04 22:38:12 Step 471/1637: training loss=0.00
2024-08-04 22:38:10 Step 470/1637: training loss=0.00
2024-08-04 22:38:08 Step 469/1637: training loss=0.00
2024-08-04 22:38:06 Step 468/1637: training loss=0.00
2024-08-04 22:38:04 Step 467/1637: training loss=0.00
2024-08-04 22:38:02 Step 466/1637: training loss=0.00
2024-08-04 22:38:00 Step 465/1637: training loss=0.00
2024-08-04 22:37:58 Step 464/1637: training loss=0.00
2024-08-04 22:37:56 Step 463/1637: training loss=0.00
2024-08-04 22:37:54 Step 462/1637: training loss=0.00
2024-08-04 22:37:52 Step 461/1637: training loss=0.00
2024-08-04 22:37:50 Step 460/1637: training loss=0.00
2024-08-04 22:37:48 Step 459/1637: training loss=0.00
2024-08-04 22:37:46 Step 458/1637: training loss=0.00
2024-08-04 22:37:44 Step 457/1637: training loss=0.00
2024-08-04 22:37:42 Step 456/1637: training loss=0.00
2024-08-04 22:37:40 Step 455/1637: training loss=0.00
2024-08-04 22:37:38 Step 454/1637: training loss=0.00
2024-08-04 22:37:36 Step 453/1637: training loss=0.00
2024-08-04 22:37:34 Step 452/1637: training loss=0.00
2024-08-04 22:37:20 Step 451/1637: training loss=0.00
2024-08-04 22:37:18 Step 450/1637: training loss=0.00
2024-08-04 22:37:16 Step 449/1637: training loss=0.00
2024-08-04 22:37:14 Step 448/1637: training loss=0.00
2024-08-04 22:37:12 Step 447/1637: training loss=0.00
2024-08-04 22:37:10 Step 446/1637: training loss=0.00
2024-08-04 22:37:08 Step 445/1637: training loss=0.00
2024-08-04 22:37:06 Step 444/1637: training loss=0.00
2024-08-04 22:37:04 Step 443/1637: training loss=0.00
2024-08-04 22:37:02 Step 442/1637: training loss=0.00
2024-08-04 22:37:00 Step 441/1637: training loss=0.00
2024-08-04 22:36:58 Step 440/1637: training loss=0.00
2024-08-04 22:36:56 Step 439/1637: training loss=0.00
2024-08-04 22:36:54 Step 438/1637: training loss=0.00
2024-08-04 22:36:52 Step 437/1637: training loss=0.00
2024-08-04 22:36:50 Step 436/1637: training loss=0.00
2024-08-04 22:36:48 Step 435/1637: training loss=0.00
2024-08-04 22:36:46 Step 434/1637: training loss=0.00
2024-08-04 22:36:44 Step 433/1637: training loss=0.00
2024-08-04 22:36:42 Step 432/1637: training loss=0.00
2024-08-04 22:36:40 Step 431/1637: training loss=0.00
2024-08-04 22:36:37 Step 430/1637: training loss=0.00
2024-08-04 22:36:35 Step 429/1637: training loss=0.00
2024-08-04 22:36:33 Step 428/1637: training loss=0.00
2024-08-04 22:36:31 Step 427/1637: training loss=0.00
2024-08-04 22:36:29 Step 426/1637: training loss=0.00
2024-08-04 22:36:29 Step 425/1637: training loss=0.00
2024-08-04 22:36:27 Step 424/1637: training loss=0.00
2024-08-04 22:36:25 Step 423/1637: training loss=0.00
2024-08-04 22:36:23 Step 422/1637: training loss=0.00
2024-08-04 22:36:21 Step 421/1637: training loss=0.00
2024-08-04 22:36:19 Step 420/1637: training loss=0.00
2024-08-04 22:36:17 Step 419/1637: training loss=0.00
2024-08-04 22:36:15 Step 418/1637: training loss=0.00
2024-08-04 22:36:13 Step 417/1637: training loss=0.00
2024-08-04 22:36:11 Step 416/1637: training loss=0.00
2024-08-04 22:36:09 Step 415/1637: training loss=0.00
2024-08-04 22:36:05 Step 414/1637: training loss=0.00
2024-08-04 22:36:05 Step 413/1637: training loss=0.00
2024-08-04 22:36:03 Step 412/1637: training loss=0.00
2024-08-04 22:36:01 Step 411/1637: training loss=0.00
2024-08-04 22:35:59 Step 410/1637: training loss=0.00
2024-08-04 22:35:57 Step 409/1637: training loss=0.00
2024-08-04 22:35:55 Step 408/1637: training loss=0.00
2024-08-04 22:35:53 Step 407/1637: training loss=0.00
2024-08-04 22:35:51 Step 406/1637: training loss=0.00
2024-08-04 22:35:49 Step 405/1637: training loss=0.00
2024-08-04 22:35:47 Step 404/1637: training loss=0.00
2024-08-04 22:35:45 Step 403/1637: training loss=0.00
2024-08-04 22:35:43 Step 402/1637: training loss=0.00
2024-08-04 22:35:41 Step 401/1637: training loss=0.00
2024-08-04 22:35:39 Step 400/1637: training loss=0.00, validation loss=0.00
2024-08-04 22:35:37 Step 399/1637: training loss=0.00
2024-08-04 22:35:35 Step 398/1637: training loss=0.00
2024-08-04 22:35:33 Step 397/1637: training loss=0.00
2024-08-04 22:35:31 Step 396/1637: training loss=0.00
2024-08-04 22:35:29 Step 395/1637: training loss=0.00
2024-08-04 22:35:27 Step 394/1637: training loss=0.00
2024-08-04 22:35:25 Step 393/1637: training loss=0.00
2024-08-04 22:35:23 Step 392/1637: training loss=0.00
2024-08-04 22:35:21 Step 391/1637: training loss=0.00
2024-08-04 22:35:19 Step 390/1637: training loss=0.00
2024-08-04 22:35:17 Step 389/1637: training loss=0.00
2024-08-04 22:35:15 Step 388/1637: training loss=0.00
2024-08-04 22:35:13 Step 387/1637: training loss=0.00
2024-08-04 22:35:11 Step 386/1637: training loss=0.00
2024-08-04 22:35:09 Step 385/1637: training loss=0.00
2024-08-04 22:35:07 Step 384/1637: training loss=0.00
2024-08-04 22:35:05 Step 383/1637: training loss=0.00
2024-08-04 22:35:03 Step 382/1637: training loss=0.00
2024-08-04 22:35:01 Step 381/1637: training loss=0.00
2024-08-04 22:34:59 Step 380/1637: training loss=0.00
2024-08-04 22:34:57 Step 379/1637: training loss=0.00
2024-08-04 22:34:55 Step 378/1637: training loss=0.00
2024-08-04 22:34:53 Step 377/1637: training loss=0.00
2024-08-04 22:34:50 Step 376/1637: training loss=0.00
2024-08-04 22:34:48 Step 375/1637: training loss=0.00
2024-08-04 22:34:46 Step 374/1637: training loss=0.00
2024-08-04 22:34:44 Step 373/1637: training loss=0.00
2024-08-04 22:34:42 Step 372/1637: training loss=0.00
2024-08-04 22:34:40 Step 371/1637: training loss=0.00
2024-08-04 22:34:38 Step 370/1637: training loss=0.00
2024-08-04 22:34:36 Step 369/1637: training loss=0.00
2024-08-04 22:34:32 Step 368/1637: training loss=0.00
2024-08-04 22:34:32 Step 367/1637: training loss=0.00
2024-08-04 22:34:30 Step 366/1637: training loss=0.00
2024-08-04 22:34:28 Step 365/1637: training loss=0.00
2024-08-04 22:34:26 Step 364/1637: training loss=0.00
2024-08-04 22:34:24 Step 363/1637: training loss=0.00
2024-08-04 22:34:22 Step 362/1637: training loss=0.00
2024-08-04 22:34:20 Step 361/1637: training loss=0.00
2024-08-04 22:34:18 Step 360/1637: training loss=0.00
2024-08-04 22:34:16 Step 359/1637: training loss=0.00
2024-08-04 22:34:14 Step 358/1637: training loss=0.00
2024-08-04 22:34:12 Step 357/1637: training loss=0.00
2024-08-04 22:34:10 Step 356/1637: training loss=0.00
2024-08-04 22:34:08 Step 355/1637: training loss=0.00
2024-08-04 22:34:06 Step 354/1637: training loss=0.00
2024-08-04 22:34:04 Step 353/1637: training loss=0.00
2024-08-04 22:34:02 Step 352/1637: training loss=0.00
2024-08-04 22:34:00 Step 351/1637: training loss=0.00
2024-08-04 22:33:58 Step 350/1637: training loss=0.00
2024-08-04 22:33:56 Step 349/1637: training loss=0.00
2024-08-04 22:33:54 Step 348/1637: training loss=0.00
2024-08-04 22:33:52 Step 347/1637: training loss=0.00
2024-08-04 22:33:50 Step 346/1637: training loss=0.00
2024-08-04 22:33:48 Step 345/1637: training loss=0.00
2024-08-04 22:33:46 Step 344/1637: training loss=0.00
2024-08-04 22:33:44 Step 343/1637: training loss=0.00
2024-08-04 22:33:42 Step 342/1637: training loss=0.00
2024-08-04 22:33:40 Step 341/1637: training loss=0.00
2024-08-04 22:33:38 Step 340/1637: training loss=0.00
2024-08-04 22:33:36 Step 339/1637: training loss=0.00
2024-08-04 22:33:36 Step 338/1637: training loss=0.00
2024-08-04 22:33:34 Step 337/1637: training loss=0.00
2024-08-04 22:33:32 Step 336/1637: training loss=0.00
2024-08-04 22:33:30 Step 335/1637: training loss=0.00
2024-08-04 22:33:28 Step 334/1637: training loss=0.00
2024-08-04 22:33:26 Step 333/1637: training loss=0.00
2024-08-04 22:33:24 Step 332/1637: training loss=0.00
2024-08-04 22:33:22 Step 331/1637: training loss=0.00
2024-08-04 22:33:20 Step 330/1637: training loss=0.00
2024-08-04 22:33:18 Step 329/1637: training loss=0.00
2024-08-04 22:33:16 Step 328/1637: training loss=0.00
2024-08-04 22:33:14 Step 327/1637: training loss=0.00
2024-08-04 22:33:12 Step 326/1637: training loss=0.00
2024-08-04 22:33:10 Step 325/1637: training loss=0.00
2024-08-04 22:33:07 Step 324/1637: training loss=0.00
2024-08-04 22:33:05 Step 323/1637: training loss=0.00
2024-08-04 22:33:03 Step 322/1637: training loss=0.00
2024-08-04 22:33:01 Step 321/1637: training loss=0.00
2024-08-04 22:32:59 Step 320/1637: training loss=0.00
2024-08-04 22:32:57 Step 319/1637: training loss=0.00
2024-08-04 22:32:55 Step 318/1637: training loss=0.00
2024-08-04 22:32:53 Step 317/1637: training loss=0.00
2024-08-04 22:32:51 Step 316/1637: training loss=0.00
2024-08-04 22:32:49 Step 315/1637: training loss=0.00
2024-08-04 22:32:47 Step 314/1637: training loss=0.00
2024-08-04 22:32:45 Step 313/1637: training loss=0.00
2024-08-04 22:32:43 Step 312/1637: training loss=0.00
2024-08-04 22:32:41 Step 311/1637: training loss=0.00
2024-08-04 22:32:39 Step 310/1637: training loss=0.00
2024-08-04 22:32:37 Step 309/1637: training loss=0.00
2024-08-04 22:32:35 Step 308/1637: training loss=0.00
2024-08-04 22:32:33 Step 307/1637: training loss=0.00
2024-08-04 22:32:31 Step 306/1637: training loss=0.00
2024-08-04 22:32:29 Step 305/1637: training loss=0.00
2024-08-04 22:32:27 Step 304/1637: training loss=0.00
2024-08-04 22:32:25 Step 303/1637: training loss=0.00
2024-08-04 22:32:23 Step 302/1637: training loss=0.00
2024-08-04 22:32:21 Step 301/1637: training loss=0.00
2024-08-04 22:32:21 Step 300/1637: training loss=0.00, validation loss=0.00
2024-08-04 22:32:19 Step 299/1637: training loss=0.00
2024-08-04 22:32:15 Step 298/1637: training loss=0.00
2024-08-04 22:32:13 Step 297/1637: training loss=0.00
2024-08-04 22:32:11 Step 296/1637: training loss=0.00
2024-08-04 22:32:09 Step 295/1637: training loss=0.00
2024-08-04 22:32:07 Step 294/1637: training loss=0.00
2024-08-04 22:32:05 Step 293/1637: training loss=0.00
2024-08-04 22:32:03 Step 292/1637: training loss=0.00
2024-08-04 22:32:03 Step 291/1637: training loss=0.00
2024-08-04 22:32:01 Step 290/1637: training loss=0.00
2024-08-04 22:31:59 Step 289/1637: training loss=0.00
2024-08-04 22:31:57 Step 288/1637: training loss=0.00
2024-08-04 22:31:55 Step 287/1637: training loss=0.00
2024-08-04 22:31:53 Step 286/1637: training loss=0.00
2024-08-04 22:31:51 Step 285/1637: training loss=0.00
2024-08-04 22:31:49 Step 284/1637: training loss=0.00
2024-08-04 22:31:47 Step 283/1637: training loss=0.00
2024-08-04 22:31:45 Step 282/1637: training loss=0.00
2024-08-04 22:31:43 Step 281/1637: training loss=0.00
2024-08-04 22:31:41 Step 280/1637: training loss=0.00
2024-08-04 22:31:39 Step 279/1637: training loss=0.00
2024-08-04 22:31:37 Step 278/1637: training loss=0.00
2024-08-04 22:31:35 Step 277/1637: training loss=0.00
2024-08-04 22:31:33 Step 276/1637: training loss=0.00
2024-08-04 22:31:31 Step 275/1637: training loss=0.00
2024-08-04 22:31:29 Step 274/1637: training loss=0.00
2024-08-04 22:31:27 Step 273/1637: training loss=0.00
2024-08-04 22:31:25 Step 272/1637: training loss=0.00
2024-08-04 22:31:23 Step 271/1637: training loss=0.00
2024-08-04 22:31:20 Step 270/1637: training loss=0.00
2024-08-04 22:31:18 Step 269/1637: training loss=0.00
2024-08-04 22:31:18 Step 268/1637: training loss=0.00
2024-08-04 22:31:16 Step 267/1637: training loss=0.00
2024-08-04 22:31:14 Step 266/1637: training loss=0.00
2024-08-04 22:31:12 Step 265/1637: training loss=0.00
2024-08-04 22:31:10 Step 264/1637: training loss=0.00
2024-08-04 22:31:08 Step 263/1637: training loss=0.00
2024-08-04 22:31:06 Step 262/1637: training loss=0.00
2024-08-04 22:31:04 Step 261/1637: training loss=0.00
2024-08-04 22:31:02 Step 260/1637: training loss=0.00
2024-08-04 22:31:00 Step 259/1637: training loss=0.00
2024-08-04 22:30:58 Step 258/1637: training loss=0.00
2024-08-04 22:30:56 Step 257/1637: training loss=0.00
2024-08-04 22:30:54 Step 256/1637: training loss=0.00
2024-08-04 22:30:52 Step 255/1637: training loss=0.00
2024-08-04 22:30:50 Step 254/1637: training loss=0.00
2024-08-04 22:30:48 Step 253/1637: training loss=0.00
2024-08-04 22:30:46 Step 252/1637: training loss=0.00
2024-08-04 22:30:44 Step 251/1637: training loss=0.00
2024-08-04 22:30:42 Step 250/1637: training loss=0.00
2024-08-04 22:30:40 Step 249/1637: training loss=0.00
2024-08-04 22:30:38 Step 248/1637: training loss=0.00
2024-08-04 22:30:36 Step 247/1637: training loss=0.00
2024-08-04 22:30:34 Step 246/1637: training loss=0.00
2024-08-04 22:30:32 Step 245/1637: training loss=0.00
2024-08-04 22:30:30 Step 244/1637: training loss=0.00
2024-08-04 22:30:28 Step 243/1637: training loss=0.00
2024-08-04 22:30:26 Step 242/1637: training loss=0.00
2024-08-04 22:30:24 Step 241/1637: training loss=0.00
2024-08-04 22:30:22 Step 240/1637: training loss=0.00
2024-08-04 22:30:20 Step 239/1637: training loss=0.00
2024-08-04 22:30:18 Step 238/1637: training loss=0.00
2024-08-04 22:30:16 Step 237/1637: training loss=0.00
2024-08-04 22:30:14 Step 236/1637: training loss=0.00
2024-08-04 22:30:12 Step 235/1637: training loss=0.00
2024-08-04 22:30:10 Step 234/1637: training loss=0.00
2024-08-04 22:30:08 Step 233/1637: training loss=0.00
2024-08-04 22:30:06 Step 232/1637: training loss=0.00
2024-08-04 22:30:04 Step 231/1637: training loss=0.00
2024-08-04 22:30:04 Step 230/1637: training loss=0.00
2024-08-04 22:30:02 Step 229/1637: training loss=0.00
2024-08-04 22:30:00 Step 228/1637: training loss=0.00
2024-08-04 22:29:58 Step 227/1637: training loss=0.00
2024-08-04 22:29:56 Step 226/1637: training loss=0.00
2024-08-04 22:29:54 Step 225/1637: training loss=0.00
2024-08-04 22:29:52 Step 224/1637: training loss=0.00
2024-08-04 22:29:50 Step 223/1637: training loss=0.00
2024-08-04 22:29:48 Step 222/1637: training loss=0.00
2024-08-04 22:29:46 Step 221/1637: training loss=0.00
2024-08-04 22:29:44 Step 220/1637: training loss=0.00
2024-08-04 22:29:41 Step 219/1637: training loss=0.00
2024-08-04 22:29:39 Step 218/1637: training loss=0.00
2024-08-04 22:29:37 Step 217/1637: training loss=0.00
2024-08-04 22:29:35 Step 216/1637: training loss=0.00
2024-08-04 22:29:33 Step 215/1637: training loss=0.00
2024-08-04 22:29:31 Step 214/1637: training loss=0.00
2024-08-04 22:29:29 Step 213/1637: training loss=0.00
2024-08-04 22:29:27 Step 212/1637: training loss=0.00
2024-08-04 22:29:25 Step 211/1637: training loss=0.00
2024-08-04 22:29:23 Step 210/1637: training loss=0.00
2024-08-04 22:29:21 Step 209/1637: training loss=0.00
2024-08-04 22:29:19 Step 208/1637: training loss=0.00
2024-08-04 22:29:17 Step 207/1637: training loss=0.00
2024-08-04 22:29:15 Step 206/1637: training loss=0.00
2024-08-04 22:29:15 Step 205/1637: training loss=0.00
2024-08-04 22:29:13 Step 204/1637: training loss=0.00
2024-08-04 22:29:11 Step 203/1637: training loss=0.00
2024-08-04 22:29:09 Step 202/1637: training loss=0.00
2024-08-04 22:29:07 Step 201/1637: training loss=0.00
2024-08-04 22:29:05 Step 200/1637: training loss=0.00, validation loss=0.00
2024-08-04 22:29:03 Step 199/1637: training loss=0.00
2024-08-04 22:29:01 Step 198/1637: training loss=0.00
2024-08-04 22:28:59 Step 197/1637: training loss=0.00
2024-08-04 22:28:57 Step 196/1637: training loss=0.00
2024-08-04 22:28:55 Step 195/1637: training loss=0.00
2024-08-04 22:28:53 Step 194/1637: training loss=0.00
2024-08-04 22:28:51 Step 193/1637: training loss=0.00
2024-08-04 22:28:49 Step 192/1637: training loss=0.00
2024-08-04 22:28:47 Step 191/1637: training loss=0.00
2024-08-04 22:28:45 Step 190/1637: training loss=0.00
2024-08-04 22:28:43 Step 189/1637: training loss=0.00
2024-08-04 22:28:41 Step 188/1637: training loss=0.00
2024-08-04 22:28:39 Step 187/1637: training loss=0.00
2024-08-04 22:28:37 Step 186/1637: training loss=0.00
2024-08-04 22:28:35 Step 185/1637: training loss=0.00
2024-08-04 22:28:33 Step 184/1637: training loss=0.00
2024-08-04 22:28:31 Step 183/1637: training loss=0.00
2024-08-04 22:28:29 Step 182/1637: training loss=0.00
2024-08-04 22:28:27 Step 181/1637: training loss=0.00
2024-08-04 22:28:25 Step 180/1637: training loss=0.00
2024-08-04 22:28:23 Step 179/1637: training loss=0.00
2024-08-04 22:28:21 Step 178/1637: training loss=0.00
2024-08-04 22:28:19 Step 177/1637: training loss=0.00
2024-08-04 22:28:19 Step 176/1637: training loss=0.00
2024-08-04 22:28:17 Step 175/1637: training loss=0.00
2024-08-04 22:28:15 Step 174/1637: training loss=0.00
2024-08-04 22:28:13 Step 173/1637: training loss=0.00
2024-08-04 22:28:11 Step 172/1637: training loss=0.00
2024-08-04 22:28:09 Step 171/1637: training loss=0.00
2024-08-04 22:28:07 Step 170/1637: training loss=0.00
2024-08-04 22:28:05 Step 169/1637: training loss=0.00
2024-08-04 22:28:03 Step 168/1637: training loss=0.00
2024-08-04 22:28:00 Step 167/1637: training loss=0.00
2024-08-04 22:27:58 Step 166/1637: training loss=0.00
2024-08-04 22:27:56 Step 165/1637: training loss=0.00
2024-08-04 22:27:54 Step 164/1637: training loss=0.00
2024-08-04 22:27:52 Step 163/1637: training loss=0.00
2024-08-04 22:27:50 Step 162/1637: training loss=0.00
2024-08-04 22:27:48 Step 161/1637: training loss=0.00
2024-08-04 22:27:46 Step 160/1637: training loss=0.00
2024-08-04 22:27:44 Step 159/1637: training loss=0.00
2024-08-04 22:27:42 Step 158/1637: training loss=0.00
2024-08-04 22:27:40 Step 157/1637: training loss=0.00
2024-08-04 22:27:38 Step 156/1637: training loss=0.00
2024-08-04 22:27:36 Step 155/1637: training loss=0.00
2024-08-04 22:27:34 Step 154/1637: training loss=0.00
2024-08-04 22:27:32 Step 153/1637: training loss=0.00
2024-08-04 22:27:30 Step 152/1637: training loss=0.00
2024-08-04 22:27:28 Step 151/1637: training loss=0.00
2024-08-04 22:27:26 Step 150/1637: training loss=0.00
2024-08-04 22:27:24 Step 149/1637: training loss=0.00
2024-08-04 22:27:22 Step 148/1637: training loss=0.00
2024-08-04 22:27:22 Step 147/1637: training loss=0.00
2024-08-04 22:27:20 Step 146/1637: training loss=0.00
2024-08-04 22:27:18 Step 145/1637: training loss=0.00
2024-08-04 22:27:16 Step 144/1637: training loss=0.00
2024-08-04 22:27:14 Step 143/1637: training loss=0.00
2024-08-04 22:27:12 Step 142/1637: training loss=0.00
2024-08-04 22:27:10 Step 141/1637: training loss=0.00
2024-08-04 22:27:08 Step 140/1637: training loss=0.00
2024-08-04 22:27:06 Step 139/1637: training loss=0.00
2024-08-04 22:27:04 Step 138/1637: training loss=0.00
2024-08-04 22:27:02 Step 137/1637: training loss=0.00
2024-08-04 22:27:00 Step 136/1637: training loss=0.00
2024-08-04 22:26:58 Step 135/1637: training loss=0.00
2024-08-04 22:26:56 Step 134/1637: training loss=0.00
2024-08-04 22:26:54 Step 133/1637: training loss=0.00
2024-08-04 22:26:52 Step 132/1637: training loss=0.00
2024-08-04 22:26:50 Step 131/1637: training loss=0.00
2024-08-04 22:26:48 Step 130/1637: training loss=0.00
2024-08-04 22:26:46 Step 129/1637: training loss=0.00
2024-08-04 22:26:44 Step 128/1637: training loss=0.00
2024-08-04 22:26:42 Step 127/1637: training loss=0.00
2024-08-04 22:26:40 Step 126/1637: training loss=0.00
2024-08-04 22:26:38 Step 125/1637: training loss=0.00
2024-08-04 22:26:36 Step 124/1637: training loss=0.00
2024-08-04 22:26:36 Step 123/1637: training loss=0.00
2024-08-04 22:26:34 Step 122/1637: training loss=0.00
2024-08-04 22:26:32 Step 121/1637: training loss=0.00
2024-08-04 22:26:30 Step 120/1637: training loss=0.00
2024-08-04 22:26:28 Step 119/1637: training loss=0.00
2024-08-04 22:26:26 Step 118/1637: training loss=0.00
2024-08-04 22:26:24 Step 117/1637: training loss=0.00
2024-08-04 22:26:22 Step 116/1637: training loss=0.00
2024-08-04 22:26:20 Step 115/1637: training loss=0.00
2024-08-04 22:26:18 Step 114/1637: training loss=0.00
2024-08-04 22:26:16 Step 113/1637: training loss=0.00
2024-08-04 22:26:13 Step 112/1637: training loss=0.00
2024-08-04 22:26:11 Step 111/1637: training loss=0.00
2024-08-04 22:26:09 Step 110/1637: training loss=0.00
2024-08-04 22:26:07 Step 109/1637: training loss=0.00
2024-08-04 22:26:05 Step 108/1637: training loss=0.00
2024-08-04 22:26:03 Step 107/1637: training loss=0.00
2024-08-04 22:26:01 Step 106/1637: training loss=0.00
2024-08-04 22:25:59 Step 105/1637: training loss=0.00
2024-08-04 22:25:57 Step 104/1637: training loss=0.00
2024-08-04 22:25:55 Step 103/1637: training loss=0.00
2024-08-04 22:25:55 Step 102/1637: training loss=0.00
2024-08-04 22:25:53 Step 101/1637: training loss=0.00
2024-08-04 22:25:51 Step 100/1637: training loss=0.00, validation loss=0.00
2024-08-04 22:25:49 Step 99/1637: training loss=0.00
2024-08-04 22:25:45 Step 98/1637: training loss=0.00
2024-08-04 22:25:43 Step 97/1637: training loss=0.00
2024-08-04 22:25:41 Step 96/1637: training loss=0.00
2024-08-04 22:25:39 Step 95/1637: training loss=0.00
2024-08-04 22:25:39 Step 94/1637: training loss=0.00
2024-08-04 22:25:37 Step 93/1637: training loss=0.00
2024-08-04 22:25:35 Step 92/1637: training loss=0.00
2024-08-04 22:25:33 Step 91/1637: training loss=0.00
2024-08-04 22:25:31 Step 90/1637: training loss=0.00
2024-08-04 22:25:29 Step 89/1637: training loss=0.00
2024-08-04 22:25:27 Step 88/1637: training loss=0.00
2024-08-04 22:25:25 Step 87/1637: training loss=0.00
2024-08-04 22:25:23 Step 86/1637: training loss=0.00
2024-08-04 22:25:21 Step 85/1637: training loss=0.00
2024-08-04 22:25:19 Step 84/1637: training loss=0.00
2024-08-04 22:25:17 Step 83/1637: training loss=0.00
2024-08-04 22:25:15 Step 82/1637: training loss=0.00
2024-08-04 22:25:13 Step 81/1637: training loss=0.00
2024-08-04 22:25:11 Step 80/1637: training loss=0.00
2024-08-04 22:25:09 Step 79/1637: training loss=0.00
2024-08-04 22:25:07 Step 78/1637: training loss=0.00
2024-08-04 22:25:05 Step 77/1637: training loss=0.00
2024-08-04 22:25:03 Step 76/1637: training loss=0.00
2024-08-04 22:25:01 Step 75/1637: training loss=0.00
2024-08-04 22:24:59 Step 74/1637: training loss=0.00
2024-08-04 22:24:57 Step 73/1637: training loss=0.00
2024-08-04 22:24:55 Step 72/1637: training loss=0.00
2024-08-04 22:24:53 Step 71/1637: training loss=0.00
2024-08-04 22:24:51 Step 70/1637: training loss=0.00
2024-08-04 22:24:49 Step 69/1637: training loss=0.00
2024-08-04 22:24:47 Step 68/1637: training loss=0.00
2024-08-04 22:24:45 Step 67/1637: training loss=0.00
2024-08-04 22:24:43 Step 66/1637: training loss=0.00
2024-08-04 22:24:41 Step 65/1637: training loss=0.00
2024-08-04 22:24:41 Step 64/1637: training loss=0.00
2024-08-04 22:24:39 Step 63/1637: training loss=0.00
2024-08-04 22:24:37 Step 62/1637: training loss=0.00
2024-08-04 22:24:35 Step 61/1637: training loss=0.00
2024-08-04 22:24:33 Step 60/1637: training loss=0.00
2024-08-04 22:24:30 Step 59/1637: training loss=0.00
2024-08-04 22:24:28 Step 58/1637: training loss=0.00
2024-08-04 22:24:26 Step 57/1637: training loss=0.00
2024-08-04 22:24:24 Step 56/1637: training loss=0.00
2024-08-04 22:24:22 Step 55/1637: training loss=0.00
2024-08-04 22:24:20 Step 54/1637: training loss=0.00
2024-08-04 22:24:18 Step 53/1637: training loss=0.00
2024-08-04 22:24:16 Step 52/1637: training loss=0.00
2024-08-04 22:24:14 Step 51/1637: training loss=0.00
2024-08-04 22:24:12 Step 50/1637: training loss=0.00
2024-08-04 22:24:10 Step 49/1637: training loss=0.00
2024-08-04 22:24:08 Step 48/1637: training loss=0.00
2024-08-04 22:24:06 Step 47/1637: training loss=0.00
2024-08-04 22:24:04 Step 46/1637: training loss=0.00
2024-08-04 22:24:02 Step 45/1637: training loss=0.00
2024-08-04 22:24:02 Step 44/1637: training loss=0.00
2024-08-04 22:24:00 Step 43/1637: training loss=0.00
2024-08-04 22:23:58 Step 42/1637: training loss=0.00
2024-08-04 22:23:56 Step 41/1637: training loss=0.00
2024-08-04 22:23:54 Step 40/1637: training loss=0.00
2024-08-04 22:23:52 Step 39/1637: training loss=0.00
2024-08-04 22:23:50 Step 38/1637: training loss=0.00
2024-08-04 22:23:48 Step 37/1637: training loss=0.00
2024-08-04 22:23:46 Step 36/1637: training loss=0.00
2024-08-04 22:23:44 Step 35/1637: training loss=0.01
2024-08-04 22:23:42 Step 34/1637: training loss=0.01
2024-08-04 22:23:40 Step 33/1637: training loss=0.02
2024-08-04 22:23:38 Step 32/1637: training loss=0.05
2024-08-04 22:23:36 Step 31/1637: training loss=0.24
2024-08-04 22:23:34 Step 30/1637: training loss=0.23
2024-08-04 22:23:32 Step 29/1637: training loss=0.43
2024-08-04 22:23:30 Step 28/1637: training loss=0.45
2024-08-04 22:23:28 Step 27/1637: training loss=0.51
2024-08-04 22:23:26 Step 26/1637: training loss=0.53
2024-08-04 22:23:24 Step 25/1637: training loss=0.69
2024-08-04 22:23:22 Step 24/1637: training loss=0.69
2024-08-04 22:23:20 Step 23/1637: training loss=0.80
2024-08-04 22:23:18 Step 22/1637: training loss=0.77
2024-08-04 22:23:16 Step 21/1637: training loss=0.93
2024-08-04 22:23:14 Step 20/1637: training loss=1.21
2024-08-04 22:23:12 Step 19/1637: training loss=1.86
2024-08-04 22:23:10 Step 18/1637: training loss=1.50
2024-08-04 22:23:08 Step 17/1637: training loss=2.09
2024-08-04 22:23:06 Step 16/1637: training loss=2.70
2024-08-04 22:23:04 Step 15/1637: training loss=2.60
2024-08-04 22:22:58 Step 14/1637: training loss=2.81
2024-08-04 22:22:56 Step 13/1637: training loss=3.29
2024-08-04 22:22:54 Step 12/1637: training loss=3.54
2024-08-04 22:22:52 Step 11/1637: training loss=4.04
2024-08-04 22:22:50 Step 10/1637: training loss=3.83
2024-08-04 22:22:48 Step 9/1637: training loss=5.03
2024-08-04 22:22:44 Step 8/1637: training loss=4.47
2024-08-04 22:22:41 Step 7/1637: training loss=4.83
2024-08-04 22:22:37 Step 6/1637: training loss=4.39
2024-08-04 22:22:35 Step 5/1637: training loss=4.81
2024-08-04 22:22:31 Step 4/1637: training loss=5.06
2024-08-04 22:22:29 Step 3/1637: training loss=5.06
2024-08-04 22:22:25 Step 2/1637: training loss=5.28
2024-08-04 22:22:21 Step 1/1637: training loss=4.76
2024-08-04 22:20:30 Fine-tuning job started
2024-08-04 22:20:29 Files validated, moving job to queued state
2024-08-04 21:58:39 Validating training file: file-U7xJ24TI02W7MBqh204F8sQD and validation file: file-U7APMWgF4CHKXhvWq0rca8z5
2024-08-04 21:58:39 Created fine-tuning job: ftjob-Vcc7mJGwfRrYcbSElpjyG2n7
